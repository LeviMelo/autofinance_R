Project structure for '/c/Users/Galaxy/LEVI/Projetos R/autofinance_R':
===============================================================================
  .gitignore
  autofinance_backtest_core.R
  autofinance_config.R
  autofinance_db_core.R
  autofinance_fiscal_trading.R
  autofinance_ingest_b3.R
  autofinance_ingest_corporate.R
  autofinance_ingest_macro.R
  autofinance_ingest_splits.R
  autofinance_panel.R
  autofinance_portfolio_engine.R
  autofinance_R.Rproj
  autofinance_risk_models.R
  autofinance_screener.R



###############################################################################
### FILE: .gitignore
###############################################################################
.Rproj.user
.Rhistory
.RData
.Ruserdata
data/autofinance.sqlite
codebase_dump_autofinance_R.txt
plans
data


###############################################################################
### FILE: autofinance_R.Rproj
###############################################################################
Version: 1.0

RestoreWorkspace: Default
SaveWorkspace: Default
AlwaysSaveHistory: Default

EnableCodeIndexing: Yes
UseSpacesForTab: Yes
NumSpacesForTab: 2
Encoding: UTF-8

RnwWeave: Sweave
LaTeX: pdfLaTeX



###############################################################################
### FILE: autofinance_backtest_core.R
###############################################################################
############################################################
# autofinance_backtest_core.R
# Time-series backtest: screener + risk + portfolio
############################################################

if (!exists("af_attach_packages")) {
  if (file.exists("autofinance_config.R")) {
    source("autofinance_config.R")
  } else {
    stop("autofinance_config.R not found; please source it before using backtest.")
  }
}

af_attach_packages(c("data.table", "lubridate", "zoo"))

if (!exists("af_run_screener")) {
  if (file.exists("autofinance_screener.R")) {
    source("autofinance_screener.R")
  } else {
    stop("autofinance_screener.R not found; required for backtest.")
  }
}

if (!exists("af_risk_build")) {
  if (file.exists("autofinance_risk_models.R")) {
    source("autofinance_risk_models.R")
  } else {
    stop("autofinance_risk_models.R not found; required for backtest.")
  }
}

if (!exists("af_build_portfolio")) {
  if (file.exists("autofinance_portfolio_engine.R")) {
    source("autofinance_portfolio_engine.R")
  } else {
    stop("autofinance_portfolio_engine.R not found; required for backtest.")
  }
}


# Compute rebalance dates (e.g. last trading day of each month)
af_bt_compute_rebalance_dates <- function(panel,
                                          start_date,
                                          end_date,
                                          rebalance_freq = "monthly",
                                          lookback_years = 3L) {
  stopifnot("refdate" %in% names(panel))
  dt <- data.table::copy(panel)
  dt[, refdate := as.Date(refdate)]

  dates <- sort(unique(dt$refdate))
  dates <- dates[dates >= start_date & dates <= end_date]
  if (!length(dates)) stop("No trading dates in panel for given backtest range.")

  dt <- data.table::data.table(refdate = dates)

  if (rebalance_freq == "monthly") {
    dt[, `:=`(
      year  = lubridate::year(refdate),
      month = lubridate::month(refdate)
    )]
    reb <- dt[, .(reb_date = max(refdate)), by = .(year, month)][order(reb_date), reb_date]
  } else if (rebalance_freq == "quarterly") {
    dt[, `:=`(
      year    = lubridate::year(refdate),
      quarter = lubridate::quarter(refdate)
    )]
    reb <- dt[, .(reb_date = max(refdate)), by = .(year, quarter)][order(reb_date), reb_date]
  } else if (rebalance_freq == "weekly") {
    dt[, `:=`(
      year = lubridate::year(refdate),
      week = lubridate::isoweek(refdate)
    )]
    reb <- dt[, .(reb_date = max(refdate)), by = .(year, week)][order(reb_date), reb_date]
  } else {
    stop("Unsupported rebalance_freq: ", rebalance_freq)
  }

  min_reb_date <- start_date %m+% lubridate::years(lookback_years)
  reb <- reb[reb >= min_reb_date & reb <= end_date]
  reb
}

# Select symbols from screener result according to config
af_bt_select_symbols <- function(screener_res, screener_config) {
  # Accept either a data.table or the full table from af_run_screener
  if (is.null(screener_res)) return(character(0))
  if (is.list(screener_res) && "full" %in% names(screener_res)) {
    screener_res <- screener_res$full
  }
  if (!nrow(screener_res)) return(character(0))
  if (!"score" %in% names(screener_res)) {
    stop("screener_res must have a 'score' column.")
  }

  res <- data.table::copy(screener_res)
  data.table::setorder(res, -score)

  # Per-type selection if requested and asset_type available
  top_by_type <- screener_config$top_n_by_type
  if (!is.null(top_by_type) && "asset_type" %in% names(res)) {
    sel <- character(0)
    for (tp in names(top_by_type)) {
      k <- as.integer(top_by_type[[tp]])
      if (is.na(k) || k <= 0) next
      tmp <- res[asset_type == tp][1:k, symbol]
      sel <- c(sel, tmp)
    }
    return(unique(sel))
  }

  # Simple Top-N
  top_n <- screener_config$top_n
  if (is.null(top_n) || top_n <= 0) {
    top_n <- min(20L, nrow(res))
  } else {
    top_n <- min(as.integer(top_n), nrow(res))
  }

  res[1:top_n, symbol]
}

# Compute portfolio-level performance statistics
af_bt_compute_stats <- function(equity_dt, returns_dt) {
  eq    <- equity_dt$equity
  dates <- equity_dt$refdate
  if (length(eq) < 2L) {
    return(list())
  }

  # Prefer the logged portfolio returns if available
  r <- returns_dt$port_ret
  r <- r[!is.na(r)]
  if (length(r) < 2L) {
    # fallback: derive from equity
    r <- diff(eq) / head(eq, -1L)
  }

  n_days <- length(r)
  if (n_days < 2L) {
    return(list())
  }

  horizon_years <- as.numeric(difftime(tail(dates, 1L),
                                       head(dates, 1L),
                                       units = "days")) / 365.25
  horizon_years <- max(horizon_years, 1e-9)

  # CAGR from equity
  cagr <- (tail(eq, 1L) / head(eq, 1L))^(1 / horizon_years) - 1

  # Annualized mean/vol (assuming daily freq)
  mean_daily <- mean(r, na.rm = TRUE)
  sd_daily   <- stats::sd(r, na.rm = TRUE)
  ann_return <- mean_daily * 252
  ann_vol    <- sd_daily * sqrt(252)
  sharpe     <- if (ann_vol > 0) ann_return / ann_vol else NA_real_

  # Drawdown
  cummax_eq <- cummax(eq)
  dd <- eq / cummax_eq - 1
  max_dd <- min(dd, na.rm = TRUE)

  # Ulcer index (using fractional drawdown)
  ulcer <- sqrt(mean((dd)^2, na.rm = TRUE))

  list(
    start_date    = head(dates, 1L),
    end_date      = tail(dates, 1L),
    cagr          = cagr,
    ann_return    = ann_return,
    ann_vol       = ann_vol,
    sharpe        = sharpe,
    max_drawdown  = max_dd,
    ulcer_index   = ulcer
  )
}

# Main backtest function
af_backtest <- function(panel,
                        screener_config,
                        risk_config,
                        port_config,
                        rebalance_freq = "monthly",
                        lookback_years = 3L,
                        start_date = NULL,
                        end_date   = NULL) {
  stopifnot("symbol"  %in% names(panel),
            "refdate" %in% names(panel))

  dt <- data.table::copy(panel)
  dt[, refdate := as.Date(refdate)]

  # --- FIX: Dynamic column selection ---
  if ("excess_ret_simple" %in% names(dt)) {
    ret_col <- "excess_ret_simple"
  } else if ("ret_simple" %in% names(dt)) {
    ret_col <- "ret_simple"
  } else {
    stop("Panel must contain 'excess_ret_simple' or 'ret_simple'.")
  }

  all_dates <- sort(unique(dt$refdate))
  if (is.null(start_date)) start_date <- min(all_dates)
  if (is.null(end_date))   end_date   <- max(all_dates)
  start_date <- as.Date(start_date)
  end_date   <- as.Date(end_date)

  # Keep enough history for initial lookback
  dt <- dt[refdate >= (start_date - lubridate::years(lookback_years)) &
           refdate <= end_date]

  # Dates actually used for equity curve
  dates_bt <- sort(unique(dt[refdate >= start_date & refdate <= end_date, refdate]))
  nD <- length(dates_bt)
  if (nD < 2L) {
    stop("Not enough dates in backtest window.")
  }

  reb_dates <- af_bt_compute_rebalance_dates(
    panel         = dt,
    start_date    = start_date,
    end_date      = end_date,
    rebalance_freq = rebalance_freq,
    lookback_years = lookback_years
  )
  if (!length(reb_dates)) {
    stop("No rebalance dates found. Check lookback_years and date range.")
  }

  # Initialize equity and logs
  equity <- rep(NA_real_, nD)
  names(equity) <- as.character(dates_bt)
  equity[1L] <- 1

  returns_log <- data.table::data.table(
    refdate = dates_bt,
    port_ret = NA_real_
  )
  weights_log <- list()

  current_weights <- NULL

  for (k in seq_along(reb_dates)) {
    t_reb <- reb_dates[k]

    # Lookback window for screener/risk
    window_start <- t_reb %m-% lubridate::years(lookback_years)
    panel_window <- dt[refdate >= window_start & refdate <= t_reb]

    # 1) Screener on full universe in the window
    scr_t <- af_run_screener(
      panel      = panel_window,
      config     = screener_config,
      as_of_date = t_reb
    )

    scr_table <- if (is.list(scr_t) && "full" %in% names(scr_t)) scr_t$full else scr_t
    selected <- af_bt_select_symbols(scr_table, screener_config)
    if (!length(selected)) {
      warning(sprintf("No symbols selected at rebalance %s. Keeping previous weights.",
                      as.character(t_reb)))
      if (is.null(current_weights)) next
    } else {
      # 2) Risk model on selected subset
      extra_args <- risk_config$extra_args
      if (is.null(extra_args)) extra_args <- list()
      risk_t <- do.call(
        af_risk_build,
        c(
          list(
            panel        = panel_window,
            symbols      = selected,
            end_date     = t_reb,
            window_years = risk_config$window_years,
            cov_method   = risk_config$cov_method,
            mu_method    = risk_config$mu_method
          ),
          extra_args
        )
      )

      # 3) Portfolio optimization
      port_t <- af_build_portfolio(
        mu     = risk_t$mu,
        Sigma  = risk_t$Sigma,
        config = port_config
      )
      current_weights <- port_t$weights

      weights_log[[as.character(t_reb)]] <- data.table::data.table(
        refdate = t_reb,
        symbol  = names(current_weights),
        weight  = as.numeric(current_weights)
      )
    }

    # 4) Apply these weights from next day until next rebalance
    idx_reb <- which(dates_bt == t_reb)
    if (!length(idx_reb)) next  # e.g. t_reb not an actual trading date

    idx_start <- idx_reb + 1L
    if (k < length(reb_dates)) {
      idx_end <- which(dates_bt == reb_dates[k + 1L])
    } else {
      idx_end <- nD
    }
    if (idx_start > idx_end) next
    if (is.null(current_weights)) next  # no portfolio yet

    for (i in idx_start:idx_end) {
      d <- dates_bt[i]
      day_ret <- dt[refdate == d & symbol %in% names(current_weights),
                    .(symbol, ret = get(ret_col))]

      if (nrow(day_ret) == 0L) {
        port_ret_d <- 0
      } else {
        data.table::setkey(day_ret, symbol)
        w_vec   <- current_weights[day_ret$symbol]
        ret_vec <- day_ret$ret
        port_ret_d <- sum(w_vec * ret_vec, na.rm = TRUE)
      }

      returns_log[refdate == d, port_ret := port_ret_d]

      if (i == 1L) {
        equity[i] <- 1 * (1 + port_ret_d)
      } else {
        if (is.na(equity[i - 1L])) {
          equity[i - 1L] <- equity[i - 2L]
        }
        equity[i] <- equity[i - 1L] * (1 + port_ret_d)
      }
    }
  }

  # Fill any remaining NAs in equity curve (e.g. before first rebalance)
  equity <- zoo::na.locf(equity, fromLast = FALSE, na.rm = FALSE)
  equity_dt <- data.table::data.table(
    refdate = dates_bt,
    equity  = equity
  )

  weights_dt <- if (length(weights_log)) {
    data.table::rbindlist(weights_log, use.names = TRUE, fill = TRUE)
  } else {
    data.table::data.table(refdate = as.Date(NA),
                           symbol  = NA_character_,
                           weight  = NA_real_)
  }

  stats <- af_bt_compute_stats(equity_dt, returns_log)

  list(
    equity_curve    = equity_dt,
    returns         = returns_log,
    weights         = weights_dt,
    rebalance_dates = reb_dates,
    stats           = stats
  )
}



###############################################################################
### FILE: autofinance_config.R
###############################################################################
############################################################
# autofinance_config.R
# Global config: DB path, package management
############################################################

# ---- 1. DB PATH ----

af_default_db_path <- "data/autofinance.sqlite"

af_get_db_path <- function() {
  # Ensure ./data exists
  if (!dir.exists("data")) dir.create("data", recursive = TRUE)
  af_default_db_path
}

# Constant used by all other modules
AF_DB_PATH <- af_get_db_path()

# ---- 2. DEFAULT PACKAGES ----
# This is "everything we conceptually care about" for the project.
# Not all of them are required by every script, but af_attach_packages()
# will be called with specific subsets where needed.

af_default_packages <- c(
  # Core infra
  "data.table",
  "DBI",
  "RSQLite",

  # Time series & finance
  "xts",
  "zoo",
  "quantmod",
  "TTR",

  # Utils
  "httr",
  "jsonlite",
  "lubridate",

  # Optimization
  "quadprog",

  # Risk-model packages (we DO care about them)
  # These may be heavy; they will be installed on demand.
  "rugarch",
  "rmgarch",
  "vars"
)

# ---- 3. PACKAGE ATTACH / INSTALL LOGIC ----

af_attach_packages <- function(pkgs = af_default_packages,
                               auto_install = TRUE) {
  pkgs <- unique(pkgs)

  # Ensure we have a CRAN repo set (needed for install.packages)
  if (auto_install) {
    repos <- getOption("repos")
    if (is.null(repos) || identical(repos["CRAN"], "@CRAN@") || is.na(repos["CRAN"])) {
      options(repos = c(CRAN = "https://cloud.r-project.org"))
    }
  }

  for (p in pkgs) {
    if (!requireNamespace(p, quietly = TRUE)) {
      if (auto_install) {
        message("Package '", p, "' not found. Installing from CRAN...")
        utils::install.packages(p)
      }
      # Try again
      if (!requireNamespace(p, quietly = TRUE)) {
        stop(
          sprintf("Package '%s' is required but could not be loaded/installed.", p),
          call. = FALSE
        )
      }
    }
    # Attach so you can inspect stuff interactively if you want
    suppressPackageStartupMessages(
      library(p, character.only = TRUE)
    )
  }

  invisible(TRUE)
}



###############################################################################
### FILE: autofinance_db_core.R
###############################################################################
############################################################
# autofinance_db_core.R
############################################################

af_db_connect <- function(db_path = AF_DB_PATH) {
  af_attach_packages(c("DBI", "RSQLite"))
  con <- RSQLite::dbConnect(RSQLite::SQLite(), db_path)
  DBI::dbExecute(con, "PRAGMA journal_mode = WAL;")
  DBI::dbExecute(con, "PRAGMA synchronous = NORMAL;")
  DBI::dbExecute(con, "PRAGMA foreign_keys = ON;")
  con
}

af_db_disconnect <- function(con) {
  if (is.null(con)) return(invisible(TRUE))
  ok <- tryCatch(DBI::dbIsValid(con), error = function(...) FALSE)
  if (isTRUE(ok)) {
    DBI::dbDisconnect(con)
  }
  invisible(TRUE)
}


af_db_init <- function(con = NULL) {
  af_attach_packages("DBI")

  own_con <- is.null(con)
  if (own_con) {
    con <- af_db_connect()
    on.exit(af_db_disconnect(con), add = TRUE)
  }

  # assets_meta
  DBI::dbExecute(con, "
    CREATE TABLE IF NOT EXISTS assets_meta (
      symbol TEXT PRIMARY KEY,
      asset_type TEXT,
      sector TEXT,
      active INTEGER,
      last_update_splits TEXT,
      last_update_divs TEXT
    )
  ")

  # prices_raw = fita B3
  DBI::dbExecute(con, "
    CREATE TABLE IF NOT EXISTS prices_raw (
      symbol TEXT,
      refdate TEXT,
      open REAL,
      high REAL,
      low REAL,
      close REAL,
      vol_fin REAL,
      qty REAL,
      PRIMARY KEY (symbol, refdate)
    ) WITHOUT ROWID
  ")

  # adjustments = corporate actions da Yahoo
  DBI::dbExecute(con, "
    CREATE TABLE IF NOT EXISTS adjustments (
      symbol TEXT,
      date TEXT,
      type TEXT,   -- 'SPLIT' ou 'DIVIDEND'
      value REAL,
      PRIMARY KEY (symbol, date, type)
    ) WITHOUT ROWID
  ")

  # macro_series = SGS / IBOV / USD etc.
  DBI::dbExecute(con, "
    CREATE TABLE IF NOT EXISTS macro_series (
      series_id TEXT,
      refdate   TEXT,
      value     REAL,
      PRIMARY KEY (series_id, refdate)
    ) WITHOUT ROWID
  ")

  invisible(TRUE)
}

af_db_insert_prices_raw <- function(con, dt) {
  af_attach_packages(c("DBI", "data.table"))
  dt <- data.table::as.data.table(dt)
  if (!nrow(dt)) return(invisible(TRUE))

  # Normalizar colunas
  if (!"refdate" %in% names(dt)) {
    stop("af_db_insert_prices_raw: 'refdate' column missing.")
  }
  dt[, refdate := as.character(as.Date(refdate))]

  cols <- c("symbol", "refdate", "open", "high", "low", "close", "vol_fin", "qty")
  missing <- setdiff(cols, names(dt))
  if (length(missing) > 0L) {
    stop("af_db_insert_prices_raw: missing columns: ", paste(missing, collapse = ", "))
  }

  sql <- "
    INSERT OR REPLACE INTO prices_raw
    (symbol, refdate, open, high, low, close, vol_fin, qty)
    VALUES (:symbol, :refdate, :open, :high, :low, :close, :vol_fin, :qty)
  "

  DBI::dbBegin(con)
  DBI::dbExecute(con, sql, params = dt[, ..cols])
  DBI::dbCommit(con)
  invisible(TRUE)
}

af_db_insert_adjustments <- function(con, dt) {
  af_attach_packages(c("DBI", "data.table"))
  dt <- data.table::as.data.table(dt)
  if (!nrow(dt)) return(invisible(TRUE))

  required <- c("symbol", "date", "type", "value")
  missing  <- setdiff(required, names(dt))
  if (length(missing) > 0L) {
    stop("af_db_insert_adjustments: missing columns: ", paste(missing, collapse = ", "))
  }

  dt[, date := as.character(as.Date(date))]

  sql <- "
    INSERT OR REPLACE INTO adjustments
    (symbol, date, type, value)
    VALUES (:symbol, :date, :type, :value)
  "

  DBI::dbBegin(con)
  DBI::dbExecute(con, sql, params = dt[, ..required])
  DBI::dbCommit(con)
  invisible(TRUE)
}

af_db_insert_macro_series <- function(con, dt) {
  af_attach_packages(c("DBI", "data.table"))
  dt <- data.table::as.data.table(dt)
  if (!nrow(dt)) return(invisible(TRUE))

  required <- c("series_id", "refdate", "value")
  missing  <- setdiff(required, names(dt))
  if (length(missing) > 0L) {
    stop("af_db_insert_macro_series: missing columns: ", paste(missing, collapse = ", "))
  }

  dt[, refdate := as.character(as.Date(refdate))]

  sql <- "
    INSERT OR REPLACE INTO macro_series
    (series_id, refdate, value)
    VALUES (:series_id, :refdate, :value)
  "

  DBI::dbBegin(con)
  DBI::dbExecute(con, sql, params = dt[, ..required])
  DBI::dbCommit(con)
  invisible(TRUE)
}

af_db_upsert_assets_meta <- function(con, dt) {
  af_attach_packages(c("DBI", "data.table"))
  dt <- data.table::as.data.table(dt)
  if (!nrow(dt)) return(invisible(TRUE))

  cols <- c("symbol", "asset_type", "sector", "active",
            "last_update_splits", "last_update_divs")
  missing <- setdiff(cols, names(dt))
  if (length(missing) > 0L) {
    stop("af_db_upsert_assets_meta: missing columns: ", paste(missing, collapse = ", "))
  }

  sql <- "
    INSERT OR REPLACE INTO assets_meta
    (symbol, asset_type, sector, active, last_update_splits, last_update_divs)
    VALUES (:symbol, :asset_type, :sector, :active, :last_update_splits, :last_update_divs)
  "

  DBI::dbBegin(con)
  DBI::dbExecute(con, sql, params = dt[, ..cols])
  DBI::dbCommit(con)
  invisible(TRUE)
}

af_db_get_symbols <- function(con) {
  af_attach_packages(c("DBI", "data.table"))
  res <- DBI::dbGetQuery(con, "SELECT DISTINCT symbol FROM prices_raw")
  data.table::as.data.table(res)$symbol
}



###############################################################################
### FILE: autofinance_fiscal_trading.R
###############################################################################
############################################################
# autofinance_fiscal_trading.R
# Impostos e custos sobre trades/posições (camada net-of-tax)
############################################################

# AQUI é extremamente simplificado e serve como esqueleto.
# Você vai precisar ajustar para refletir as regras exatas BR (20k isenção, etc).

af_fiscal_rules_default <- list(
  tax_rate_equity = 0.15,   # ganho de capital
  tax_rate_bdr    = 0.15,
  tax_rate_fii    = 0.20,   # GC 20% (exemplo)
  trade_cost_bp   = 0.0005  # custo proporcional (0.05%)
)

af_apply_fiscal_trading <- function(trades,
                                    prices_panel,
                                    assets_meta,
                                    rules = af_fiscal_rules_default) {
  af_attach_packages("data.table")
  tr <- data.table::as.data.table(trades)
  pr <- data.table::as.data.table(prices_panel)
  am <- data.table::as.data.table(assets_meta)

  # Simplificação: supõe que trades$weight é peso alvo; converte para valor nominal
  # com base num patrimônio hipotético inicial de 1.
  # Você pode reimplementar para trabalhar com quantidades reais e preços.

  # Aqui, apenas calculamos custo de transação aproximado:
  # custo = sum(|Δw|) * equity * trade_cost_bp ao longo do tempo.
  # Imposto: placeholder sem cálculo detalhado de GC.

  tr <- am[tr, on = .(symbol), nomatch = 0L]

  # custo por trade: weight * trade_cost_bp
  tr[, trade_cost := abs(weight) * rules$trade_cost_bp]

  total_trade_cost <- sum(tr$trade_cost, na.rm = TRUE)

  list(
    total_trade_cost = total_trade_cost,
    # espaço para somar imposto de GC real:
    total_tax = NA_real_
  )
}



###############################################################################
### FILE: autofinance_ingest_b3.R
###############################################################################
############################################################
# autofinance_ingest_b3.R
# Sincronização COTAHIST -> prices_raw (rb3)
############################################################

if (!exists("af_attach_packages")) {
  if (file.exists("autofinance_config.R")) {
    source("autofinance_config.R")
  } else {
    stop("autofinance_config.R not found; please source it before using ingest.")
  }
}

if (!exists("af_db_connect")) {
  if (file.exists("autofinance_db_core.R")) {
    source("autofinance_db_core.R")
  } else {
    stop("autofinance_db_core.R not found; required for ingest DB access.")
  }
}

af_attach_packages(c("rb3", "data.table", "dplyr", "lubridate"))

af_is_valid_db_con <- function(con) {
  if (is.null(con)) return(FALSE)
  ok_class <- inherits(con, "DBIConnection") || inherits(con, "SQLiteConnection")
  if (!ok_class) return(FALSE)
  ok_valid <- tryCatch(DBI::dbIsValid(con), error = function(...) FALSE)
  isTRUE(ok_valid)
}


# ----------------------------------------------------------------------
# rb3 bootstrap + cache dir
# ----------------------------------------------------------------------

af_rb3_init <- function(cache_dir = "data/rb3_cache", verbose = TRUE) {
  if (!dir.exists(cache_dir)) dir.create(cache_dir, recursive = TRUE)
  # rb3 uses this option for local cache
  options(rb3.cachedir = normalizePath(cache_dir, winslash = "/", mustWork = FALSE))

  # Bootstrap templates DB (safe no-op if already done)
  tryCatch({
    rb3::rb3_bootstrap()
    if (verbose) message("rb3 bootstrap OK; cache dir = ", getOption("rb3.cachedir"))
  }, error = function(e) {
    if (verbose) message("rb3 bootstrap warning: ", conditionMessage(e))
  })

  invisible(TRUE)
}

# ----------------------------------------------------------------------
# Fetch + normalize one year
# ----------------------------------------------------------------------

af_fetch_cotahist_year <- function(year,
                                   asset_filter = c("equity", "etf", "fii", "all"),
                                   verbose = TRUE) {
  asset_filter <- match.arg(asset_filter)
  af_rb3_init(verbose = verbose)

  if (verbose) message(sprintf("COTAHIST yearly: preparing %s...", year))

  # 1) Prefer fetch_marketdata (download + read + stage)
  ok_fetch <- TRUE
  tryCatch({
    rb3::fetch_marketdata(
      "b3-cotahist-yearly",
      year = year,
      throttle = TRUE
    )
  }, error = function(e) {
    ok_fetch <<- FALSE
    if (verbose) message("fetch_marketdata failed: ", conditionMessage(e))
  })

  # 2) Fallback to explicit download/read if needed
  if (!ok_fetch) {
    tryCatch({
      meta <- rb3::download_marketdata("b3-cotahist-yearly", year = year)
      rb3::read_marketdata(meta)
    }, error = function(e) {
      warning("rb3 download/read fallback failed for ", year, ": ", conditionMessage(e))
      return(data.table::data.table())
    })
  }

  # 3) Access lazy dataset
  df_raw <- tryCatch({
    rb3::cotahist_get("yearly")
  }, error = function(e) {
    warning("cotahist_get('yearly') failed: ", conditionMessage(e))
    return(NULL)
  })

  if (is.null(df_raw)) return(data.table::data.table())

  # 4) Filter year
  df_year <- df_raw |>
    dplyr::filter(lubridate::year(.data$refdate) == year)

  # 5) Optional asset-class filters (rb3 helpers)
  if (asset_filter == "equity") {
    df_year <- rb3::cotahist_filter_equity(df_year)
  } else if (asset_filter == "etf") {
    df_year <- rb3::cotahist_filter_etf(df_year)
  } else if (asset_filter == "fii") {
    df_year <- rb3::cotahist_filter_fii(df_year)
  }

  df_year <- dplyr::collect(df_year)
  if (!nrow(df_year)) return(data.table::data.table())

  dt <- data.table::as.data.table(df_year)

  # Normalize symbol
  if ("symbol" %in% names(dt)) dt[, symbol := trimws(symbol)]

  # Defensive column picker
  col_pick <- function(alts) {
    cand <- intersect(alts, names(dt))
    if (length(cand)) dt[[cand[1L]]] else NA_real_
  }

  dt_out <- data.table::data.table(
    symbol  = dt[["symbol"]],
    refdate = as.Date(dt[["refdate"]]),
    open    = as.numeric(col_pick(c("open", "price.open", "preco_abertura"))),
    high    = as.numeric(col_pick(c("high", "price.high", "preco_maximo"))),
    low     = as.numeric(col_pick(c("low", "price.low", "preco_minimo"))),
    close   = as.numeric(col_pick(c("close", "price.close", "preco_ultimo"))),
    vol_fin = as.numeric(col_pick(c("financial_volume", "volume", "volume_total"))),
    qty     = as.numeric(col_pick(c("trade_quantity", "quantity", "number_trades", "quantidade_negociada")))
  )

  dt_out <- dt_out[!is.na(symbol) & !is.na(refdate) & !is.na(close)]
  dt_out
}

# ----------------------------------------------------------------------
# Heuristic classifier (kept simple; better metadata can be added later)
# ----------------------------------------------------------------------

af_classify_symbol <- function(symbol_chr) {
  sym <- toupper(trimws(symbol_chr))
  investable <- TRUE
  asset_type <- "OTHER"

  if (grepl("F$", sym) || grepl("[^A-Z0-9]", sym) || nchar(sym) > 8) {
    investable <- FALSE
  }

  if (grepl("(32|33|34|35|36|39)$", sym)) {
    asset_type <- "BDR"
  } else if (grepl("11$", sym)) {
    asset_type <- "ETF_FII"
  } else if (grepl("[0-9]{1,2}$", sym)) {
    asset_type <- "EQUITY"
  }

  if (!investable) asset_type <- "OTHER"

  list(asset_type = asset_type, active = as.integer(investable))
}

# ----------------------------------------------------------------------
# Sync driver
# ----------------------------------------------------------------------

af_sync_b3 <- function(con = NULL,
                       years = NULL,
                       verbose = TRUE) {
  af_attach_packages(c("DBI", "RSQLite", "data.table"))

  own_con <- is.null(con)
  if (own_con) {
    con <- af_db_connect()
    on.exit(af_db_disconnect(con), add = TRUE)
  }

  if (!af_is_valid_db_con(con)) {
    stop("af_sync_b3: 'con' is not a valid DBI connection.")
  }

  af_db_init(con)

  if (is.null(years)) {
    max_date_str <- tryCatch({
      DBI::dbGetQuery(con, "SELECT MAX(refdate) as d FROM prices_raw")$d
    }, error = function(e) NA)

    current_year <- as.integer(format(Sys.Date(), "%Y"))

    if (is.na(max_date_str) || is.null(max_date_str)) {
      years <- 2015:current_year
    } else {
      last_year <- as.integer(substr(max_date_str, 1, 4))
      years <- last_year:current_year
    }
  }

  years <- sort(unique(as.integer(years)))

  for (y in years) {
    if (verbose) message("af_sync_b3: processing year ", y)

    dt <- af_fetch_cotahist_year(y, asset_filter = "all", verbose = verbose)

    if (nrow(dt) > 0) {
      if (verbose) message("  inserting ", nrow(dt), " rows...")
      af_db_insert_prices_raw(con, dt)

      # Seed assets_meta for corporate actions sync
      syms <- unique(dt$symbol)
      if (length(syms) > 0L) {
        classified <- lapply(syms, af_classify_symbol)
        meta_dt <- data.table::data.table(
          symbol             = syms,
          asset_type         = vapply(classified, `[[`, "", "asset_type"),
          sector             = NA_character_,
          active             = vapply(classified, `[[`, integer(1), "active"),
          last_update_splits = NA_character_,
          last_update_divs   = NA_character_
        )
        af_db_upsert_assets_meta(con, meta_dt)
      }
    } else {
      if (verbose) message("  no data found for ", y)
    }
  }

  invisible(TRUE)
}



###############################################################################
### FILE: autofinance_ingest_corporate.R
###############################################################################
############################################################
# autofinance_ingest_corporate.R
# Splits & dividendos via quantmod -> adjustments
############################################################

af_is_empty_series <- function(x) {
  if (is.null(x)) return(TRUE)

  nx <- tryCatch(NROW(x), error = function(...) NA_integer_)
  if (is.na(nx) || nx == 0L) return(TRUE)

  vals <- suppressWarnings(as.numeric(x))
  if (length(vals) == 0L || all(is.na(vals))) return(TRUE)

  FALSE
}

af_symbol_to_yahoo <- function(symbol) {
  paste0(symbol, ".SA")
}

af_yahoo_to_symbol <- function(yahoo_symbol) {
  sub("\\.SA$", "", yahoo_symbol)
}

af_sync_yahoo_splits <- function(con = NULL,
                                 symbols = NULL,
                                 from_default = as.Date("2000-01-01"),
                                 verbose = TRUE) {
  own_con <- is.null(con)
  if (own_con) {
    con <- af_db_connect()
    on.exit(af_db_disconnect(con), add = TRUE)
  }
  if (!inherits(con, "DBIConnection") || !DBI::dbIsValid(con)) {
    stop("af_sync_yahoo_splits: 'con' is not a valid DBI connection.")
  }

  af_attach_packages(c("DBI", "data.table", "quantmod"))

  af_db_init(con)

  meta <- data.table::as.data.table(
    DBI::dbGetQuery(con, "SELECT symbol, last_update_splits FROM assets_meta")
  )

  if (!is.null(symbols)) {
    meta <- meta[symbol %in% symbols]
  }

  if (!nrow(meta)) {
    stop("af_sync_yahoo_splits: no symbols in assets_meta.")
  }

  results <- list()

  for (i in seq_len(nrow(meta))) {
    sym <- meta$symbol[i]
    last_upd <- meta$last_update_splits[i]
    ysym <- af_symbol_to_yahoo(sym)

    from_date <- if (is.na(last_upd) || last_upd == "" || is.null(last_upd)) {
      from_default
    } else {
      as.Date(last_upd) - 5L  # pequena folga
    }

    if (verbose) message("Splits: ", sym, " (", ysym, ") from ", from_date, "...")

    sp <- tryCatch(
      quantmod::getSplits(ysym, from = from_date, auto.assign = FALSE),
      error = function(e) {
        if (verbose) message("  error fetching splits for ", sym, ": ", conditionMessage(e))
        NULL
      }
    )

    if (af_is_empty_series(sp)) {
      # mesmo sem splits, atualizamos last_update_splits
      new_last <- format(Sys.Date(), "%Y-%m-%d")
      DBI::dbExecute(
        con,
        "UPDATE assets_meta SET last_update_splits = ? WHERE symbol = ?",
        params = list(new_last, sym)
      )
      next
    }

    dt_sp <- data.table::data.table(
      symbol = sym,
      date   = as.Date(index(sp)),
      type   = "SPLIT",
      value  = as.numeric(sp[, 1])
    )
    results[[sym]] <- dt_sp

    new_last <- format(max(dt_sp$date), "%Y-%m-%d")
    DBI::dbExecute(
      con,
      "UPDATE assets_meta SET last_update_splits = ? WHERE symbol = ?",
      params = list(new_last, sym)
    )
  }

  if (length(results) > 0L) {
    dt_all <- data.table::rbindlist(results, fill = TRUE)
    af_db_insert_adjustments(con, dt_all)
  }

  invisible(TRUE)
}

af_sync_yahoo_dividends <- function(con = NULL,
                                    symbols = NULL,
                                    from_default = as.Date("2000-01-01"),
                                    verbose = TRUE) {
  own_con <- is.null(con)
  if (own_con) {
    con <- af_db_connect()
    on.exit(af_db_disconnect(con), add = TRUE)
  }
  af_attach_packages(c("DBI", "data.table", "quantmod"))

  af_db_init(con)

  meta <- data.table::as.data.table(
    DBI::dbGetQuery(con, "SELECT symbol, last_update_divs FROM assets_meta")
  )

  if (!is.null(symbols)) {
    meta <- meta[symbol %in% symbols]
  }

  if (!nrow(meta)) {
    stop("af_sync_yahoo_dividends: no symbols in assets_meta.")
  }

  results <- list()

  for (i in seq_len(nrow(meta))) {
    sym <- meta$symbol[i]
    last_upd <- meta$last_update_divs[i]
    ysym <- af_symbol_to_yahoo(sym)

    from_date <- if (is.na(last_upd) || last_upd == "" || is.null(last_upd)) {
      from_default
    } else {
      as.Date(last_upd) - 5L
    }

    if (verbose) message("Dividends: ", sym, " (", ysym, ") from ", from_date, "...")

    dv <- tryCatch(
      quantmod::getDividends(ysym, from = from_date),
      error = function(e) NULL
    )
    if (af_is_empty_series(dv)) {
      new_last <- format(Sys.Date(), "%Y-%m-%d")
      DBI::dbExecute(
        con,
        "UPDATE assets_meta SET last_update_divs = ? WHERE symbol = ?",
        params = list(new_last, sym)
      )
      next
    }

    dt_dv <- data.table::data.table(
      symbol = sym,
      date   = as.Date(index(dv)),
      type   = "DIVIDEND",
      value  = as.numeric(dv[, 1])
    )
    results[[sym]] <- dt_dv

    new_last <- format(max(dt_dv$date), "%Y-%m-%d")
    DBI::dbExecute(
      con,
      "UPDATE assets_meta SET last_update_divs = ? WHERE symbol = ?",
      params = list(new_last, sym)
    )
  }

  if (length(results) > 0L) {
    dt_all <- data.table::rbindlist(results, fill = TRUE)
    af_db_insert_adjustments(con, dt_all)
  }

  invisible(TRUE)
}



###############################################################################
### FILE: autofinance_ingest_macro.R
###############################################################################
############################################################
# autofinance_ingest_macro.R
# BCB SGS -> macro_series
############################################################

# PATCH for autofinance_ingest_macro.R

af_fetch_sgs_series <- function(series_id, start_date, end_date) {
  af_attach_packages(c("httr", "jsonlite", "data.table"))

  start_str <- format(as.Date(start_date), "%d/%m/%Y")
  end_str   <- format(as.Date(end_date),   "%d/%m/%Y")

  # BCB API requires numeric ID
  url <- sprintf(
    "https://api.bcb.gov.br/dados/serie/bcdata.sgs.%d/dados?formato=json&dataInicial=%s&dataFinal=%s",
    as.integer(series_id), start_str, end_str
  )

  resp <- httr::GET(url)
  if (httr::http_error(resp)) {
    warning("HTTP error for series ", series_id)
    return(data.table::data.table())
  }

  txt <- httr::content(resp, as = "text", encoding = "UTF-8")
  js  <- jsonlite::fromJSON(txt, simplifyDataFrame = TRUE)
  dt  <- data.table::as.data.table(js)
  
  if (!nrow(dt)) return(data.table::data.table())

  dt[, refdate := as.Date(data, format = "%d/%m/%Y")]
  dt[, value   := as.numeric(gsub(",", ".", valor))]
  
  # Return without series_id col, we add it in sync function
  dt[, .(refdate, value)]
}

af_sync_macro_series <- function(con = NULL,
                                 series_map, # Named vector: c("CDI"=12, "USD"=1)
                                 start_date,
                                 end_date,
                                 verbose = TRUE) {
  own_con <- is.null(con)
  if (own_con) {
    con <- af_db_connect()
    on.exit(af_db_disconnect(con), add = TRUE)
  }
  if (!inherits(con, "DBIConnection") || !DBI::dbIsValid(con)) {
    stop("af_sync_macro_series: 'con' is not a valid DBI connection.")
  }
  af_db_init(con)
  af_attach_packages(c("DBI", "data.table"))

  # Iterate over the named vector to map ID -> Name
  for (name in names(series_map)) {
    numeric_id <- series_map[[name]]
    if (verbose) message("SGS: Fetching ", name, " (ID ", numeric_id, ")...")
    
    dt <- af_fetch_sgs_series(numeric_id, start_date, end_date)
    
    if (nrow(dt) > 0) {
      # Inject the TEXT ID expected by Screener/Risk
      dt[, series_id := name]
      af_db_insert_macro_series(con, dt)
    }
  }
  invisible(TRUE)
}

af_get_macro_series <- function(con,
                                series_ids,
                                start_date,
                                end_date) {
  af_attach_packages(c("DBI", "data.table"))
  series_ids <- unique(as.character(series_ids))

  q <- sprintf("
    SELECT series_id, refdate, value
    FROM macro_series
    WHERE series_id IN (%s)
      AND refdate >= '%s'
      AND refdate <= '%s'
  ",
    paste(sprintf("'%s'", series_ids), collapse = ","),
    format(as.Date(start_date), "%Y-%m-%d"),
    format(as.Date(end_date),   "%Y-%m-%d")
  )

  dt <- data.table::as.data.table(DBI::dbGetQuery(con, q))
  if (!nrow(dt)) return(dt)
  dt[, refdate := as.Date(refdate)]
  dt
}



###############################################################################
### FILE: autofinance_ingest_splits.R
###############################################################################
############################################################
# autofinance_ingest_splits.R
# Sincronização de splits (e futuramente dividendos) via quantmod
############################################################

af_sync_splits <- function(con = NULL,
                           symbols = NULL,
                           max_age_days = 7L,
                           force = FALSE,
                           verbose = TRUE,
                           investable_only = TRUE,
                           mode = c("investable", "all", "suspects"),
                           suspect_threshold = 0.2) {
  own_con <- is.null(con)
  if (own_con) {
    con <- af_db_connect()
    on.exit(af_db_disconnect(con), add = TRUE)
  }
  if (!inherits(con, "DBIConnection") || !DBI::dbIsValid(con)) {
    stop("af_sync_splits: 'con' is not a valid DBI connection.")
  }
  mode <- match.arg(mode)
  af_attach_packages(c("data.table", "quantmod"))
  dt_assets <- data.table::as.data.table(
    DBI::dbGetQuery(con, "SELECT symbol, active, last_update_splits FROM assets_meta")
  )

  if (!is.null(symbols)) {
    dt_assets <- dt_assets[symbol %in% symbols]
  } else {
    if (mode == "investable") {
      dt_assets <- dt_assets[active == 1L]
    } else if (mode == "suspects") {
      # Heuristic: recent unadjusted big moves
      lookback_start <- Sys.Date() - 365
      px <- data.table::as.data.table(DBI::dbGetQuery(
        con,
        sprintf("
          SELECT symbol, refdate, close
          FROM prices_raw
          WHERE refdate >= '%s'
        ", format(lookback_start, "%Y-%m-%d"))
      ))
      if (nrow(px)) {
        px[, refdate := as.Date(refdate)]
        data.table::setorder(px, symbol, refdate)
        px[, ret := close / data.table::shift(close) - 1, by = symbol]
        diag_dt <- px[, .(max_abs_ret = max(abs(ret), na.rm = TRUE)), by = symbol]
        suspects <- diag_dt[max_abs_ret >= suspect_threshold, symbol]
        dt_assets <- dt_assets[symbol %in% suspects]
      } else {
        dt_assets <- dt_assets[0]
      }
    } else {
      # mode == "all"
      dt_assets <- dt_assets
    }
    if (investable_only) {
      dt_assets <- dt_assets[active == 1L]
    }
  }

  today <- Sys.Date()
  dt_assets[, last_date := as.Date(last_update_splits)]
  if (!force) {
    dt_assets <- dt_assets[is.na(last_date) | (today - last_date) > max_age_days]
  }

  if (nrow(dt_assets) == 0L) {
    if (verbose) message("af_sync_splits: nothing to update.")
    return(invisible(TRUE))
  }

  all_symbols_checked <- character(0)

  for (sym in dt_assets$symbol) {
    ysym <- paste0(sym, ".SA")
    if (verbose) message("af_sync_splits: ", sym, " (", ysym, ")")
    splits_xts <- NULL
    # basic backoff for Yahoo 429/tempo issues
    fetch_splits <- function() {
      tryCatch({
        suppressWarnings(
          quantmod::getSplits(ysym, auto.assign = FALSE)
        )
      }, error = function(e) {
        msg <- conditionMessage(e)
        if (grepl("429|Too Many Requests", msg, ignore.case = TRUE)) {
          if (verbose) message("  Yahoo rate limit, sleeping 60s before retry...")
          Sys.sleep(60)
          tryCatch({
            suppressWarnings(
              quantmod::getSplits(ysym, auto.assign = FALSE)
            )
          }, error = function(e2) {
            if (verbose) message("  retry failed for ", sym, ": ", conditionMessage(e2))
            NULL
          })
        } else {
          if (verbose) message("  error fetching splits for ", sym, ": ", msg)
          NULL
        }
      })
    }
    splits_xts <- fetch_splits()

    if (!is.null(splits_xts) && NROW(splits_xts) > 0) {
      dt_s <- data.table::data.table(
        symbol = sym,
        date   = as.Date(zoo::index(splits_xts)),
        type   = "SPLIT",
        value  = as.numeric(splits_xts[, 1])
      )
      # FIX: Changed from af_db_insert_corporate_actions to matches db_core
      af_db_insert_adjustments(con, dt_s)
    } else {
      if (verbose) message("  no splits found for ", sym, " (using unadjusted prices).")
    }

    # Atualiza metadata para não ficar rechecando (User Logic Preserved)
    DBI::dbExecute(
      con,
      "INSERT OR REPLACE INTO assets_meta
       (symbol, asset_type, sector, active, last_update_splits, last_update_divs)
       VALUES (
         :symbol,
         COALESCE((SELECT asset_type FROM assets_meta WHERE symbol = :symbol), NULL),
         COALESCE((SELECT sector     FROM assets_meta WHERE symbol = :symbol), NULL),
         COALESCE((SELECT active     FROM assets_meta WHERE symbol = :symbol), 1),
         :last_update_splits,
         COALESCE((SELECT last_update_divs FROM assets_meta WHERE symbol = :symbol), NULL)
       )",
      params = list(
        symbol = sym,
        last_update_splits = as.character(today)
      )
    )

    all_symbols_checked <- c(all_symbols_checked, sym)
    Sys.sleep(0.2) # educado com Yahoo
  }

  invisible(all_symbols_checked)
}



###############################################################################
### FILE: autofinance_panel.R
###############################################################################
############################################################
# autofinance_panel.R
#
# Painel de preços ajustados + retornos
#
# Depende de:
#   - autofinance_config.R (AF_DB_PATH, af_attach_packages)
#   - Banco SQLite com:
#       prices_raw(symbol, refdate, open, high, low, close, vol_fin, qty)
#       adjustments(symbol, date, type, value)  -- pelo menos type == "SPLIT"
#
# Principais funções:
#   - af_load_prices_raw()
#   - af_load_adjustments()
#   - af_build_adjusted_panel()
#   - af_compute_returns()
############################################################

if (!exists("af_attach_packages")) {
  if (file.exists("autofinance_config.R")) {
    source("autofinance_config.R")
  } else {
    stop("autofinance_config.R not found; please source it before using panel.")
  }
}

if (!exists("af_db_connect")) {
  if (file.exists("autofinance_db_core.R")) {
    source("autofinance_db_core.R")
  } else {
    stop("autofinance_db_core.R not found; required for panel DB access.")
  }
}

af_attach_packages(c("data.table", "DBI", "RSQLite", "quantmod", "xts", "TTR"))

# ----------------------------------------------------------------------
# Helper: small internal connection helper (optional)
# Você pode continuar usando seu próprio af_db_connect(), se já existir.
# Aqui deixo um helper leve para casos em que você só tem AF_DB_PATH.
# ----------------------------------------------------------------------

af_panel_db_connect <- function(db_path = AF_DB_PATH) {
  RSQLite::dbConnect(RSQLite::SQLite(), db_path)
}

# ----------------------------------------------------------------------
# 1) Carregar preços crus (prices_raw) do DB
# ----------------------------------------------------------------------

# Retorna data.table:
#   symbol, refdate(Date), open, high, low, close, vol_fin, qty
af_load_prices_raw <- function(con = NULL,
                               symbols    = NULL,
                               start_date = NULL,
                               end_date   = NULL) {
  own_con <- is.null(con)
  if (own_con) {
    con <- af_db_connect()
    on.exit(af_db_disconnect(con), add = TRUE)
  }
  if (!inherits(con, "DBIConnection") || !DBI::dbIsValid(con)) {
    stop("af_load_prices_raw: 'con' is not a valid DBI connection.")
  }

  where_clauses <- c()

  if (!is.null(symbols) && length(symbols) > 0) {
    syms_sql <- paste(DBI::dbQuoteString(con, symbols), collapse = ",")
    where_clauses <- c(where_clauses, sprintf("symbol IN (%s)", syms_sql))
  }

  if (!is.null(start_date)) {
    start_date <- as.character(as.Date(start_date))
    where_clauses <- c(where_clauses, sprintf("refdate >= '%s'", start_date))
  }

  if (!is.null(end_date)) {
    end_date <- as.character(as.Date(end_date))
    where_clauses <- c(where_clauses, sprintf("refdate <= '%s'", end_date))
  }

  where_sql <- if (length(where_clauses) > 0) {
    paste("WHERE", paste(where_clauses, collapse = " AND "))
  } else {
    ""
  }

  sql <- sprintf("
    SELECT symbol, refdate, open, high, low, close, vol_fin, qty
    FROM prices_raw
    %s
    ORDER BY symbol, refdate
  ", where_sql)

  dt <- data.table::as.data.table(DBI::dbGetQuery(con, sql))
  if (nrow(dt) == 0L) {
    warning("af_load_prices_raw: no rows returned for given filters.")
    return(dt)
  }

  dt[, refdate := as.Date(refdate)]
  dt[]
}

# ----------------------------------------------------------------------
# 2) Carregar ajustes (splits/dividends) do DB
# ----------------------------------------------------------------------

# Retorna data.table:
#   symbol, date(Date), type, value
af_load_adjustments <- function(con = NULL,
                                symbols    = NULL,
                                start_date = NULL,
                                end_date   = NULL,
                                types      = c("SPLIT")) {
  own_con <- is.null(con)
  if (own_con) {
    con <- af_db_connect()
    on.exit(af_db_disconnect(con), add = TRUE)
  }
  if (!inherits(con, "DBIConnection") || !DBI::dbIsValid(con)) {
    stop("af_load_adjustments: 'con' is not a valid DBI connection.")
  }

  where_clauses <- c()

  if (!is.null(symbols) && length(symbols) > 0) {
    syms_sql <- paste(DBI::dbQuoteString(con, symbols), collapse = ",")
    where_clauses <- c(where_clauses, sprintf("symbol IN (%s)", syms_sql))
  }

  if (!is.null(start_date)) {
    start_date <- as.character(as.Date(start_date))
    where_clauses <- c(where_clauses, sprintf("date >= '%s'", start_date))
  }

  if (!is.null(end_date)) {
    end_date <- as.character(as.Date(end_date))
    where_clauses <- c(where_clauses, sprintf("date <= '%s'", end_date))
  }

  if (!is.null(types) && length(types) > 0) {
    tps_sql <- paste(DBI::dbQuoteString(con, types), collapse = ",")
    where_clauses <- c(where_clauses, sprintf("type IN (%s)", tps_sql))
  }

  where_sql <- if (length(where_clauses) > 0) {
    paste("WHERE", paste(where_clauses, collapse = " AND "))
  } else {
    ""
  }

  sql <- sprintf("
    SELECT symbol, date, type, value
    FROM adjustments
    %s
    ORDER BY symbol, date
  ", where_sql)

  dt <- data.table::as.data.table(DBI::dbGetQuery(con, sql))
  if (nrow(dt) == 0L) {
    # não é erro: pode simplesmente não haver splits no período
    dt[, date := as.Date(character())]
    return(dt)
  }

  dt[, date := as.Date(date)]
  dt[]
}

# ----------------------------------------------------------------------
# 3) Aplicar splits via quantmod::adjustOHLC (por símbolo)
# ----------------------------------------------------------------------

# prices_dt: data.table para UM símbolo:
#   refdate, open, high, low, close
# splits_dt: data.table para UM símbolo:
#   date, value (type=="SPLIT")
#
# Retorna data.table com colunas:
#   refdate, open_adj, high_adj, low_adj, close_adj
af_apply_splits_one_symbol <- function(prices_dt,
                                       splits_dt    = NULL,
                                       dividends_dt = NULL,
                                       use_dividends = FALSE) {
  if (nrow(prices_dt) == 0L) return(NULL)
  data.table::setorder(prices_dt, refdate)

  ohlc_mat <- as.matrix(prices_dt[, .(open, high, low, close)])
  colnames(ohlc_mat) <- c("Open", "High", "Low", "Close")
  ohlc_xts <- xts::xts(ohlc_mat, order.by = prices_dt$refdate)

  split_xts <- NULL
  if (!is.null(splits_dt) && nrow(splits_dt) > 0L) {
    split_xts <- xts::xts(x = splits_dt$value, order.by = splits_dt$date)
  }

  div_xts <- NULL
  if (isTRUE(use_dividends) && !is.null(dividends_dt) && nrow(dividends_dt) > 0L) {
    div_xts <- xts::xts(x = dividends_dt$value, order.by = dividends_dt$date)
  }

  if (!is.null(split_xts) || !is.null(div_xts)) {
    ratios <- TTR::adjRatios(
      splits    = split_xts,
      dividends = div_xts,
      close     = quantmod::Cl(ohlc_xts)
    )

    ratio_xts <- if (isTRUE(use_dividends) && !is.null(div_xts)) {
      # Total-return style ratio
      ratios[, "Ratio"]
    } else {
      ratios[, "Split"]
    }

    ohlc_adj <- quantmod::adjustOHLC(
      ohlc_xts,
      use.Adjusted = FALSE,
      ratio        = ratio_xts
    )
  } else {
    ohlc_adj <- ohlc_xts
  }

  data.table::data.table(
    refdate   = as.Date(zoo::index(ohlc_adj)),
    open_adj  = as.numeric(ohlc_adj[, "Open"]),
    high_adj  = as.numeric(ohlc_adj[, "High"]),
    low_adj   = as.numeric(ohlc_adj[, "Low"]),
    close_adj = as.numeric(ohlc_adj[, "Close"])
  )
}


# ----------------------------------------------------------------------
# 4) Construir painel ajustado para vários símbolos
# ----------------------------------------------------------------------

# Retorna data.table:
#   symbol, refdate, open_adj, high_adj, low_adj, close_adj,
#   vol_fin, qty
#
# Nota: vol_fin e qty vêm do prices_raw sem ajuste (o padrão mesmo).
#       Se quiser "volume ajustado", dá pra derivar depois.
af_build_adjusted_panel <- function(con = NULL,
                                    symbols    = NULL,
                                    start_date = NULL,
                                    end_date   = NULL,
                                    adjust_dividends = FALSE) {
  own_con <- is.null(con)
  if (own_con) {
    con <- af_db_connect()
    on.exit(af_db_disconnect(con), add = TRUE)
  }
  # 1) Carregar preços crus
  prices <- af_load_prices_raw(
    con        = con,
    symbols    = symbols,
    start_date = start_date,
    end_date   = end_date
  )
  if (nrow(prices) == 0L) {
    stop("af_build_adjusted_panel: no raw prices found for given filters.")
  }

  # 2) Carregar splits
  #    Usamos um buffer para garantir que splits anteriores à janela não sejam perdidos.
  start_adj <- if (!is.null(start_date)) as.Date(start_date) - 365L else NULL
  types_needed <- if (isTRUE(adjust_dividends)) c("SPLIT", "DIVIDEND") else c("SPLIT")

  adj <- af_load_adjustments(
    con        = con,
    symbols    = unique(prices$symbol),
    start_date = start_adj,
    end_date   = end_date,
    types      = types_needed
  )

  # 3) Aplicar por símbolo
  out_list <- list()
  syms <- sort(unique(prices$symbol))

  for (sym in syms) {
    p_sym <- prices[symbol == sym]
    s_sym <- if (nrow(adj) > 0L) adj[symbol == sym & type == "SPLIT"] else NULL
    d_sym <- if (nrow(adj) > 0L && isTRUE(adjust_dividends)) adj[symbol == sym & type == "DIVIDEND"] else NULL

    adj_sym <- af_apply_splits_one_symbol(
      prices_dt     = p_sym[, .(refdate, open, high, low, close)],
      splits_dt     = if (!is.null(s_sym) && nrow(s_sym) > 0L) s_sym[, .(date, value)] else NULL,
      dividends_dt  = if (!is.null(d_sym) && nrow(d_sym) > 0L) d_sym[, .(date, value)] else NULL,
      use_dividends = adjust_dividends
    )

    if (!is.null(adj_sym) && nrow(adj_sym) > 0L) {
      # Juntar vol_fin e qty
      merged <- merge(
        p_sym[, .(refdate, vol_fin, qty)],
        adj_sym,
        by = "refdate",
        all.y = TRUE
      )

      merged[, symbol := sym]
      data.table::setcolorder(merged,
                              c("symbol", "refdate",
                                "open_adj", "high_adj", "low_adj", "close_adj",
                                "vol_fin", "qty"))

      out_list[[sym]] <- merged[]
    }
  }

  panel_adj <- data.table::rbindlist(out_list, use.names = TRUE, fill = TRUE)
  data.table::setorder(panel_adj, symbol, refdate)

  panel_adj[]
}

# ----------------------------------------------------------------------
# 5) Calcular retornos (simples e excessos)
# ----------------------------------------------------------------------

# panel_adj: data.table com:
#   symbol, refdate, close_adj (e, opcionalmente, outras colunas)
#
# rf_daily_dt (opcional): data.table com:
#   refdate, rf_daily  (taxa diária em decimal, ex: 0.00025 ~ 0.025%/dia)
#
# Retorna painel com colunas extras:
#   ret_simple, excess_ret_simple (se RF fornecido)
af_compute_returns <- function(panel_adj,
                               rf_daily_dt = NULL,
                               rf_col      = "rf_daily") {
  dt <- data.table::as.data.table(panel_adj)
  if (!all(c("symbol", "refdate", "close_adj") %in% names(dt))) {
    stop("af_compute_returns: panel_adj must contain 'symbol', 'refdate', 'close_adj'.")
  }

  data.table::setorder(dt, symbol, refdate)

  # Retorno simples por ativo
  dt[, close_lag := data.table::shift(close_adj, n = 1L, type = "lag"),
     by = symbol]

  dt[, ret_simple := ifelse(
    !is.na(close_lag) & close_lag != 0,
    (close_adj / close_lag) - 1,
    NA_real_
  )]

  dt[, close_lag := NULL]

  # Se RF fornecido, calcular excesso
  if (!is.null(rf_daily_dt)) {
    rf <- data.table::as.data.table(rf_daily_dt)
    if (!("refdate" %in% names(rf))) {
      stop("rf_daily_dt must contain 'refdate' column.")
    }
    if (!(rf_col %in% names(rf))) {
      stop(sprintf("rf_daily_dt must contain column '%s'.", rf_col))
    }
    rf[, refdate := as.Date(refdate)]

    # merge por data (mesma RF para todos ativos naquele dia)
    dt <- merge(
      dt,
      rf[, .(refdate, rf_daily = get(rf_col))],
      by = "refdate",
      all.x = TRUE
    )

    dt[, excess_ret_simple := ifelse(
      !is.na(ret_simple) & !is.na(rf_daily),
      ret_simple - rf_daily,
      NA_real_
    )]
  }

  dt[]
}



###############################################################################
### FILE: autofinance_portfolio_engine.R
###############################################################################
############################################################
# autofinance_portfolio_engine.R
#
# Pure portfolio construction layer:
#   Input : mu (expected returns), Sigma (covariance matrix),
#           port_config (constraints / mode)
#   Output: weights vector + some metadata
#
# Modes:
#   - "equal"     : equal weight
#   - "inv_vol"   : 1/σ weighting
#   - "min_var"   : minimum-variance QP
#   - "mean_var"  : Markowitz (risk aversion)
#   - "max_sharpe": approximated via QP on (mu - rf)
############################################################

if (!exists("af_attach_packages")) {
  if (file.exists("autofinance_config.R")) {
    source("autofinance_config.R")
  } else {
    stop("autofinance_config.R not found; please source it before portfolio engine.")
  }
}

# Precisamos ao menos de quadprog para os problemas quadráticos
af_attach_packages(c("quadprog"))

# -------------------------------------------------------------------
# Config default
# -------------------------------------------------------------------

af_port_default_config <- list(
  mode         = "min_var",  # "equal", "inv_vol", "min_var", "mean_var", "max_sharpe"
  long_only    = TRUE,
  w_max        = 0.20,       # máx 20% por ativo
  leverage_max = 1.0,        # sum(w) = 1; sem alavancagem
  risk_aversion = 5,         # para mean_var / max_sharpe (λ)
  rf_daily      = 0          # taxa livre de risco diária (pode vir do CDI / SELIC)
)

# -------------------------------------------------------------------
# Utilitários básicos de pesos
# -------------------------------------------------------------------

af_port_equal_weights <- function(symbols) {
  n <- length(symbols)
  if (n == 0L) stop("af_port_equal_weights: empty symbol set.")
  rep(1 / n, n)
}

af_port_inv_vol <- function(Sigma) {
  if (!is.matrix(Sigma)) stop("af_port_inv_vol: Sigma must be a matrix.")
  sig <- sqrt(diag(Sigma))
  inv <- 1 / sig
  inv[!is.finite(inv)] <- 0
  if (sum(inv) <= 0) {
    # Fallback: equal weights
    n <- length(sig)
    return(rep(1 / n, n))
  }
  inv / sum(inv)
}

# -------------------------------------------------------------------
# Resolver QP com quadprog (min_var / mean_var / max_sharpe)
# -------------------------------------------------------------------

af_quadprog_solve <- function(Sigma,
                              mu           = NULL,
                              mode         = c("min_var", "mean_var", "max_sharpe"),
                              long_only    = TRUE,
                              w_max        = 1,
                              leverage_max = 1,
                              risk_aversion = 5,
                              rf_daily     = 0) {
  mode <- match.arg(mode)

  if (!is.matrix(Sigma)) stop("af_quadprog_solve: Sigma must be a matrix.")
  N <- nrow(Sigma)
  if (N != ncol(Sigma)) stop("af_quadprog_solve: Sigma must be square.")

  # Defensive PD ridge (quadprog is sensitive to near-singular Σ)
  Sigma_pd <- Sigma
  diag(Sigma_pd) <- diag(Sigma_pd) + 1e-10

  # Objective: min 1/2 w' D w - d' w
  if (mode == "min_var") {
    Dmat <- 2 * Sigma_pd
    dvec <- rep(0, N)
  } else {
    if (is.null(mu) || length(mu) != N) {
      stop("af_quadprog_solve: mu must be length N for mean_var / max_sharpe.")
    }
    mu <- as.numeric(mu)

    if (mode == "mean_var") {
      # max (w'μ - λ w'Σw) -> min (λ w'Σw - w'μ)
      Dmat <- 2 * risk_aversion * Sigma_pd
      dvec <- mu
    } else { # max_sharpe
      mu_tilde <- mu - rf_daily
      Dmat <- 2 * risk_aversion * Sigma_pd
      dvec <- mu_tilde
    }
  }

  # Constraints:
  # 1) sum(w) = 1  (equality)
  Amat <- matrix(1, nrow = N, ncol = 1)
  bvec <- 1

  # 2) w_i >= 0 if long_only
  if (isTRUE(long_only)) {
    Amat <- cbind(Amat, diag(N))
    bvec <- c(bvec, rep(0, N))
  }

  # 3) w_i <= w_max  ->  -w_i >= -w_max
  if (!is.null(w_max) && is.finite(w_max) && w_max < 1) {
    Amat <- cbind(Amat, -diag(N))
    bvec <- c(bvec, rep(-w_max, N))
  }

  # Note:
  # With long_only + sum(w)=1, leverage_max is already implicitly 1.
  # If you later allow shorts, you'll need explicit leverage constraints.

  res <- quadprog::solve.QP(
    Dmat = Dmat,
    dvec = dvec,
    Amat = Amat,
    bvec = bvec,
    meq  = 1
  )

  w <- as.numeric(res$solution)
  names(w) <- rownames(Sigma)
  w
}


# -------------------------------------------------------------------
# Função principal: mu, Sigma -> pesos
# -------------------------------------------------------------------

af_build_portfolio <- function(mu,
                               Sigma,
                               config = af_port_default_config) {

  if (is.null(Sigma) || !is.matrix(Sigma)) {
    stop("af_build_portfolio: Sigma must be a covariance matrix.")
  }

  # Se mu for NULL e o modo precisar de mu, erro informativo
  mode <- match.arg(config$mode,
                    c("equal", "inv_vol", "min_var", "mean_var", "max_sharpe"))

  symbols <- colnames(Sigma)
  if (is.null(symbols)) {
    symbols <- paste0("Asset", seq_len(nrow(Sigma)))
    colnames(Sigma) <- rownames(Sigma) <- symbols
  }

  # Para equal / inv_vol, mu pode ser NULL
  if (!is.null(mu)) {
    if (length(mu) != nrow(Sigma)) {
      stop("af_build_portfolio: length(mu) must equal nrow(Sigma).")
    }
    names(mu) <- symbols
  }

  if (mode == "equal") {
    w <- af_port_equal_weights(symbols)
  } else if (mode == "inv_vol") {
    w <- af_port_inv_vol(Sigma)
  } else {
    w <- af_quadprog_solve(
      Sigma         = Sigma,
      mu            = mu,
      mode          = mode,
      long_only     = config$long_only,
      w_max         = config$w_max,
      leverage_max  = config$leverage_max,
      risk_aversion = config$risk_aversion,
      rf_daily      = config$rf_daily
    )
  }

  # Se long_only, garante w_i >= 0 numérica
  if (config$long_only) {
    w[w < 0] <- 0
  }

  # Normaliza para somar 1
  if (sum(w) > 0) {
    w <- w / sum(w)
  } else {
    # fallback defensivo: equal weights
    w <- af_port_equal_weights(symbols)
  }

  names(w) <- symbols

  list(
    weights = w,
    Sigma   = Sigma,
    mu      = mu,
    config  = config
  )
}



###############################################################################
### FILE: autofinance_risk_models.R
###############################################################################
############################################################
# autofinance_risk_models.R
#
# Risk model layer: Σ (covariance) and μ (expected returns)
# Methods:
#   Covariance:
#     - "sample"      : sample covariance matrix
#     - "shrinkage"   : simple shrink-to-diagonal
#     - "garch_dcc"   : GARCH(1,1) + DCC covariance at t_end
#
#   Expected returns:
#     - "hist_mean"   : historical average daily return
#     - "momentum"    : last-H-days average return
#     - "var"         : VAR-based 1-step-ahead forecast
#
# All returns here are DAILY. No annualization inside this module.
############################################################

# --- Config / packages -----------------------------------------------------

if (!exists("af_attach_packages")) {
  if (file.exists("autofinance_config.R")) {
    source("autofinance_config.R")
  } else {
    stop("autofinance_config.R not found; please source it before using risk models.")
  }
}

af_attach_packages(c("data.table"))

# --- Utility: prepare wide return matrix -----------------------------------

# panel: data.table with at least columns: symbol, refdate, ret_simple,
#        optionally excess_ret_simple.
#
# symbols: optional character vector of tickers to include.
# end_date: optional Date or "YYYY-MM-DD"; if NULL use max(panel$refdate).
# window_years: how many years back from end_date to include.
# use_excess: if TRUE and column 'excess_ret_simple' exists, use it; otherwise 'ret_simple'.
# min_obs_ratio: minimum fraction of non-NA observations required per asset.
#
# Returns:
#   list(
#     returns    : matrix (T x N) of daily returns,
#     dates      : Date vector (length T),
#     symbols    : character vector of N symbols (columns of matrix),
#     start_date : Date (min date used),
#     end_date   : Date (max date used)
#   )

af_risk_prepare_returns <- function(panel,
                                   symbols       = NULL,
                                   end_date      = NULL,
                                   window_years  = 3,
                                   use_excess    = TRUE,
                                   min_obs_ratio = 0.7) {

  panel <- data.table::as.data.table(panel)

  if (!all(c("symbol", "refdate") %in% names(panel))) {
    stop("panel must contain at least 'symbol' and 'refdate' columns.")
  }

  # Choose returns column
  col_ret <- NULL
  if (use_excess && "excess_ret_simple" %in% names(panel)) {
    col_ret <- "excess_ret_simple"
  } else if ("ret_simple" %in% names(panel)) {
    col_ret <- "ret_simple"
  } else {
    stop("panel must contain 'ret_simple' or 'excess_ret_simple'.")
  }

  # Filter symbols
  if (!is.null(symbols)) {
    panel <- panel[symbol %in% symbols]
  }

  if (nrow(panel) == 0) {
    stop("No rows in panel after symbol filter.")
  }

  # Normalize refdate to Date
  panel[, refdate := as.Date(refdate)]

  # Determine end_date
  if (is.null(end_date)) {
    end_date <- max(panel$refdate, na.rm = TRUE)
  } else {
    end_date <- as.Date(end_date)
  }

  # Determine start_date from window_years
  # Simple approximation: 365 * years. If you want trading days adjust later.
  start_date <- end_date - as.integer(365 * window_years)

  panel <- panel[refdate >= start_date & refdate <= end_date]

  if (nrow(panel) == 0) {
    stop("No data in panel for the requested window.")
  }

  # Wide matrix: rows = dates, cols = symbols, values = returns
  wide <- data.table::dcast(
    panel,
    refdate ~ symbol,
    value.var      = col_ret,
    fun.aggregate  = mean,
    fill           = NA_real_
  )

  dates <- as.Date(wide$refdate)
  R_mat <- as.matrix(wide[, -1, with = FALSE])
  colnames(R_mat) <- names(wide)[-1]

  # Drop assets with too many NAs
  n_obs <- length(dates)
  non_na_counts <- colSums(!is.na(R_mat))
  base_min <- ceiling(min_obs_ratio * n_obs)
  max_obs  <- max(non_na_counts, na.rm = TRUE)
  eff_min  <- min(base_min, floor(max_obs * 0.8))

  keep <- non_na_counts >= eff_min

  if (!any(keep)) {
    # fallback: try a looser threshold before erroring
    eff_min2 <- floor(max_obs * 0.5)
    keep <- non_na_counts >= eff_min2
    if (!any(keep)) {
      warning(sprintf(
        "risk_prepare_returns: dropping all assets (n_obs=%s, base_min=%s, max_obs=%s, eff_min=%s, eff_min2=%s)",
        n_obs, base_min, max_obs, eff_min, eff_min2
      ))
      stop("All assets dropped by min_obs_ratio filter; relax constraints or extend window.")
    }
  }

  drops <- setdiff(colnames(R_mat), colnames(R_mat)[keep])
  if (length(drops) > 0) {
    message("Dropping ", length(drops), " assets due to insufficient data: ",
            paste(drops, collapse = ", "))
  }

  R_mat <- R_mat[, keep, drop = FALSE]

  list(
    returns    = R_mat,
    dates      = dates,
    symbols    = colnames(R_mat),
    start_date = min(dates),
    end_date   = max(dates)
  )
}

# --- Covariance estimation --------------------------------------------------

# returns_mat: numeric matrix (T x N) of daily returns (already filtered).
# method:
#   - "sample"
#   - "shrinkage"
#   - "garch_dcc"
#
# shrink_lambda: weight for shrinkage to diagonal (0=no shrink, 1=only diagonal).
# shrink_target: "diagonal" or "identity"
#
# For garch_dcc:
#   - if garch_spec/dcc_spec are NULL, default specs are created inside.

af_cov_estimate <- function(returns_mat,
                            method         = c("sample", "shrinkage", "garch_dcc"),
                            shrink_lambda  = 0.1,
                            shrink_target  = c("diagonal", "identity"),
                            garch_spec     = NULL,
                            dcc_spec       = NULL) {

  method        <- match.arg(method)
  shrink_target <- match.arg(shrink_target)

  if (!is.matrix(returns_mat)) {
    stop("returns_mat must be a numeric matrix.")
  }

  if (ncol(returns_mat) < 2L) {
    stop("Need at least 2 assets to estimate covariance.")
  }

  # Remove rows that are all NA
  all_na_rows <- apply(returns_mat, 1L, function(x) all(is.na(x)))
  returns_mat <- returns_mat[!all_na_rows, , drop = FALSE]

  if (nrow(returns_mat) < 10L) {
    stop("Too few observations after removing NA rows for covariance estimation.")
  }

  if (method == "sample") {
    Sigma <- stats::cov(returns_mat, use = "pairwise.complete.obs")
    return(list(
      Sigma  = Sigma,
      method = "sample",
      meta   = list(
        n_obs    = nrow(returns_mat),
        n_assets = ncol(returns_mat)
      )
    ))
  }

  if (method == "shrinkage") {
    S <- stats::cov(returns_mat, use = "pairwise.complete.obs")
    p <- ncol(S)

    if (shrink_target == "diagonal") {
      F <- diag(diag(S), nrow = p, ncol = p)
    } else {
      avg_var <- mean(diag(S), na.rm = TRUE)
      F <- diag(avg_var, nrow = p, ncol = p)
    }

    lambda <- max(min(shrink_lambda, 1), 0)
    Sigma  <- (1 - lambda) * S + lambda * F

    return(list(
      Sigma  = Sigma,
      method = "shrinkage",
      meta   = list(
        n_obs         = nrow(returns_mat),
        n_assets      = p,
        shrink_lambda = lambda,
        shrink_target = shrink_target
      )
    ))
  }

  if (method == "garch_dcc") {
    af_attach_packages(c("rugarch", "rmgarch"))

    # DCC cannot handle NAs; drop rows with any NA
    complete_rows <- stats::complete.cases(returns_mat)
    R_cc <- returns_mat[complete_rows, , drop = FALSE]

    if (nrow(R_cc) < 30L) {
      stop("Too few complete observations for GARCH-DCC estimation.")
    }

    N <- ncol(R_cc)

    # Default univariate GARCH(1,1) spec if not provided
    if (is.null(garch_spec)) {
      garch_spec <- rugarch::ugarchspec(
        variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
        mean.model     = list(armaOrder = c(0, 0), include.mean = TRUE),
        distribution.model = "norm"
      )
    }

    # Multivariate spec
    uspec  <- rmgarch::multispec(replicate(N, garch_spec))
    if (is.null(dcc_spec)) {
      dcc_spec <- rmgarch::dccspec(
        uspec     = uspec,
        dccOrder  = c(1, 1),
        distribution = "mvnorm"
      )
    }

    dcc_fit <- rmgarch::dccfit(
      spec = dcc_spec,
      data = R_cc
    )

    rcov_arr <- rmgarch::rcov(dcc_fit)  # array (N x N x T)
    t_last   <- dim(rcov_arr)[3L]
    Sigma    <- rcov_arr[, , t_last, drop = TRUE]

    dimnames(Sigma) <- list(colnames(R_cc), colnames(R_cc))

    return(list(
      Sigma  = Sigma,
      method = "garch_dcc",
      meta   = list(
        n_obs          = nrow(R_cc),
        n_assets       = N,
        convergence    = dcc_fit@mfit$convergence,
        last_index_row = t_last
      )
    ))
  }

  stop("Unknown covariance method: ", method)
}

# --- Expected returns estimation -------------------------------------------

# returns_mat: numeric matrix (T x N) of daily returns.
# method:
#   - "hist_mean" : μ_j = mean(r_j)
#   - "momentum"  : μ_j = mean of last 'momentum_window' observations
#   - "var"       : μ_j = 1-step-ahead forecast from VAR(p)
#
# macro_xts: placeholder for future factor-based VAR; currently optional/unused.
#
# Returns:
#   list(mu = numeric vector length N, method=..., meta=list(...))

af_mu_estimate <- function(returns_mat,
                           method          = c("hist_mean", "momentum", "var"),
                           momentum_window = 63L,
                           var_lag         = 1L,
                           macro_xts       = NULL) {

  method <- match.arg(method)

  if (!is.matrix(returns_mat)) {
    stop("returns_mat must be a numeric matrix.")
  }

  N <- ncol(returns_mat)
  if (N < 1L) {
    stop("No assets in returns_mat.")
  }

  # Remove rows that are all NA
  all_na_rows <- apply(returns_mat, 1L, function(x) all(is.na(x)))
  R <- returns_mat[!all_na_rows, , drop = FALSE]

  if (nrow(R) < 10L) {
    stop("Too few observations after removing all-NA rows for μ estimation.")
  }

  # Helper: per-column last non-NA index
  last_non_na_idx <- function(x) {
    idx <- which(!is.na(x))
    if (length(idx) == 0L) return(NA_integer_)
    tail(idx, 1L)
  }

  if (method == "hist_mean") {
    mu <- colMeans(R, na.rm = TRUE)
    return(list(
      mu     = as.numeric(mu),
      method = "hist_mean",
      meta   = list(
        n_obs    = nrow(R),
        n_assets = N
      )
    ))
  }

  if (method == "momentum") {
    w <- max(1L, as.integer(momentum_window))
    Tn <- nrow(R)

    mu <- numeric(N)
    names(mu) <- colnames(R)

    for (j in seq_len(N)) {
      x <- R[, j]
      idx_last <- last_non_na_idx(x)
      if (is.na(idx_last)) {
        mu[j] <- NA_real_
      } else {
        idx_start <- max(1L, idx_last - w + 1L)
        window_vals <- x[idx_start:idx_last]
        mu[j] <- mean(window_vals, na.rm = TRUE)
      }
    }

    return(list(
      mu     = mu,
      method = "momentum",
      meta   = list(
        n_obs            = nrow(R),
        n_assets         = N,
        momentum_window  = w
      )
    ))
  }

  if (method == "var") {
    af_attach_packages("vars")

    # VAR cannot handle NAs; drop rows with any NA
    R_cc <- R[stats::complete.cases(R), , drop = FALSE]

    if (nrow(R_cc) < (var_lag + 5L)) {
      stop("Too few complete observations for VAR with lag = ", var_lag)
    }

    # Fit VAR(p)
    var_fit <- vars::VAR(
      R_cc,
      p    = var_lag,
      type = "const"
    )

    # 1-step-ahead forecast
    fcst <- stats::predict(var_fit, n.ahead = 1L)

    # fcst$fcst is a list, one element per series
    mu <- numeric(N)
    names(mu) <- colnames(R_cc)

    for (j in seq_len(N)) {
      series_name <- colnames(R_cc)[j]
      comp <- fcst$fcst[[series_name]]
      mu[j] <- comp[1L, "fcst"]
    }

    return(list(
      mu     = mu,
      method = "var",
      meta   = list(
        n_obs      = nrow(R_cc),
        n_assets   = N,
        var_lag    = var_lag,
        var_call   = var_fit$call
      )
    ))
  }

  stop("Unknown μ method: ", method)
}

# --- High-level wrapper: af_risk_build -------------------------------------

# This is the main entry point the portfolio/backtest engine will call.
#
# panel: data.table with symbol, refdate, ret_simple / excess_ret_simple.
# symbols: optional subset.
# end_date, window_years, use_excess, min_obs_ratio: same semantics as prepare_returns.
#
# cov_method: "sample", "shrinkage", "garch_dcc"
# mu_method : "hist_mean", "momentum", "var"
#
# Extra args are forwarded to af_cov_estimate / af_mu_estimate via ...,
# so you can pass shrink_lambda, momentum_window, var_lag, etc.
#
# Returns:
#   list(
#     mu        : numeric vector (N),
#     Sigma     : matrix (N x N),
#     symbols   : character (N),
#     start_date: Date,
#     end_date  : Date,
#     cov_meta  : list(...),
#     mu_meta   : list(...)
#   )

af_risk_build <- function(panel,
                          symbols       = NULL,
                          end_date      = NULL,
                          window_years  = 3,
                          use_excess    = TRUE,
                          min_obs_ratio = 0.7,
                          cov_method    = c("sample", "shrinkage", "garch_dcc"),
                          mu_method     = c("hist_mean", "momentum", "var"),
                          ...) {

  cov_method <- match.arg(cov_method)
  mu_method  <- match.arg(mu_method)

  prep <- af_risk_prepare_returns(
    panel          = panel,
    symbols        = symbols,
    end_date       = end_date,
    window_years   = window_years,
    use_excess     = use_excess,
    min_obs_ratio  = min_obs_ratio
  )

  R_mat   <- prep$returns
  sym_ret <- prep$symbols

  # Covariance
  cov_res <- af_cov_estimate(
    returns_mat    = R_mat,
    method         = cov_method,
    ...
  )

  # Expected returns
  mu_res <- af_mu_estimate(
    returns_mat    = R_mat,
    method         = mu_method,
    ...
  )

  # Align dimensions
  if (length(mu_res$mu) != ncol(cov_res$Sigma)) {
    stop("Dimension mismatch between μ and Σ; check returns matrix handling.")
  }

  names(mu_res$mu) <- sym_ret
  dimnames(cov_res$Sigma) <- list(sym_ret, sym_ret)

  list(
    mu         = mu_res$mu,
    Sigma      = cov_res$Sigma,
    symbols    = sym_ret,
    start_date = prep$start_date,
    end_date   = prep$end_date,
    cov_meta   = cov_res$meta,
    mu_meta    = mu_res$meta,
    cov_method = cov_method,
    mu_method  = mu_method
  )
}

# --- Optional config + convenience wrapper ---------------------------------
# Isto NÃO muda nenhuma lógica já existente. Só oferece uma forma
# de passar um config-list em vez de um monte de argumentos soltos.

af_risk_config_default <- list(
  window_years    = 2,
  use_excess      = TRUE,
  min_obs_ratio   = 0.5,
  cov_method      = "sample",     # "sample", "shrinkage", "garch_dcc"
  mu_method       = "hist_mean",  # "hist_mean", "momentum", "var"
  shrink_lambda   = 0.1,
  shrink_target   = "diagonal",
  momentum_window = 63L,
  var_lag         = 1L
)

af_risk_estimate <- function(panel_returns,
                             symbols = NULL,
                             end_date = NULL,
                             config = af_risk_config_default,
                             ...) {
  af_risk_build(
    panel          = panel_returns,
    symbols        = symbols,
    end_date       = end_date,
    window_years   = config$window_years,
    use_excess     = config$use_excess,
    min_obs_ratio  = config$min_obs_ratio,
    cov_method     = config$cov_method,
    mu_method      = config$mu_method,
    shrink_lambda  = config$shrink_lambda,
    shrink_target  = config$shrink_target,
    momentum_window = config$momentum_window,
    var_lag         = config$var_lag,
    ...
  )
}




###############################################################################
### FILE: autofinance_screener.R
###############################################################################
############################################################
# autofinance_screener.R  (VERSÃO ATUALIZADA)
# Métricas cross-section + ranking por classe
############################################################

af_screener_config_default <- list(
  lookback_days   = 252L,
  horizons_days   = c(21L, 63L, 126L, 252L),
  min_liquidity   = 5e5,
  min_days_traded = 0.8,        # 80% dos dias com negócio
  ibov_series_id  = "IBOV",     # se você salvar IBOV em macro_series
  usd_series_id   = "USD_BR",   # idem
  # Peso alto em momentum médio/longo; curto com peso menor.
  # Penalização forte de drawdown/ulcer; moderada de vol, beta, liquidez ruim.
  score_weights   = list(
    # Momentum (quanto maior melhor)
    ret_21d        = +0.3,
    ret_63d        = +0.6,
    ret_126d       = +0.9,
    ret_252d       = +1.0,

    # Risco / estabilidade (quanto menor melhor)
    vol_21d        = -0.4,
    vol_252d       = -0.7,
    max_dd         = -0.7,
    ulcer_index    = -0.8,
    avg_time_underwater = -0.3,

    # Liquidez (Amihud alto = pior, então peso negativo)
    amihud         = -0.5,

    # Sistema (se disponível)
    beta_ibov      = -0.2,  # penaliza beta de mercado muito alto
    beta_usd       = +0.1   # leve prêmio para hedge em dólar (opcional)
    # Se quiser incluir skew/kurt/var/cvar: adicione aqui, mas pense na direção.
  )
)

if (!exists("af_db_connect")) {
  if (file.exists("autofinance_db_core.R")) {
    source("autofinance_db_core.R")
  }
}
if (!exists("af_build_adjusted_panel")) {
  if (file.exists("autofinance_panel.R")) {
    source("autofinance_panel.R")
  }
}

############################################################
# Filtro de liquidez em cima de prices_raw
############################################################

af_compute_basic_liquidity_filter <- function(con = NULL,
                                              min_liquidity,
                                              min_days_traded,
                                              lookback_start,
                                              ref_date) {
  af_attach_packages("data.table")
  own_con <- is.null(con)
  if (own_con) {
    con <- af_db_connect()
    on.exit(af_db_disconnect(con), add = TRUE)
  }
  if (!inherits(con, "DBIConnection") || !DBI::dbIsValid(con)) {
    stop("af_compute_basic_liquidity_filter: 'con' is not a valid DBI connection.")
  }
  q <- sprintf("
    SELECT symbol, refdate, vol_fin, qty
    FROM prices_raw
    WHERE refdate >= '%s' AND refdate <= '%s'
  ", lookback_start, ref_date)
  dt <- data.table::as.data.table(DBI::dbGetQuery(con, q))
  if (nrow(dt) == 0L) return(data.table::data.table(symbol = character(0)))

  dt[, refdate := as.Date(refdate)]
  data.table::setorder(dt, symbol, refdate)

  liq <- dt[, .(
    median_vol_fin    = stats::median(vol_fin, na.rm = TRUE),
    days_traded_ratio = mean(qty > 0, na.rm = TRUE)
  ), by = symbol]

  liq[is.na(median_vol_fin),    median_vol_fin := 0]
  liq[is.na(days_traded_ratio), days_traded_ratio := 0]

  liq_filtered <- liq[
    median_vol_fin    >= min_liquidity &
      days_traded_ratio >= min_days_traded
  ]

  liq_filtered
}

# Liquidity filter for in-memory panel path (panel already has ret_simple/vol_fin)
af_compute_basic_liquidity_from_panel <- function(panel_ret,
                                                  min_liquidity,
                                                  min_days_traded) {
  af_attach_packages("data.table")
  dt <- data.table::as.data.table(panel_ret)
  if (!("ret_simple" %in% names(dt))) {
    stop("panel_ret must contain ret_simple for liquidity filter.")
  }
  dt[, traded_flag := !is.na(ret_simple)]
  liq <- dt[, .(
    median_vol_fin    = stats::median(vol_fin, na.rm = TRUE),
    days_traded_ratio = mean(traded_flag, na.rm = TRUE)
  ), by = symbol]

  liq[is.na(median_vol_fin),    median_vol_fin := 0]
  liq[is.na(days_traded_ratio), days_traded_ratio := 0]

  liq[
    median_vol_fin    >= min_liquidity &
      days_traded_ratio >= min_days_traded
  ]
}

############################################################
# Métricas por ativo (multi-horizonte + risco completo)
############################################################

af_compute_symbol_metrics <- function(dt_sym,
                                      horizons_days,
                                      factor_returns = NULL) {
  # dt_sym: data.table(date, close_adj, ret_simple, excess_ret_simple, vol_fin, qty)
  # horizons_days: vetor de janelas (em nº de observações)
  # factor_returns: list com vetores alinhados: ibov, usd, etc. (opcional)

  n <- nrow(dt_sym)
  if (n < 20L) return(NULL)  # pouco dado

  last_idx <- n
  metrics <- list(symbol = dt_sym$symbol[1])

  # -------------------------
  # 1) Retornos / Momentum
  # -------------------------
  for (h in horizons_days) {
    if (h <= n) {
      idx <- (last_idx - h + 1):last_idx
      ret_window <- prod(1 + dt_sym$excess_ret_simple[idx], na.rm = TRUE) - 1
      metrics[[paste0("ret_", h, "d")]] <- ret_window
      vol_window <- stats::sd(dt_sym$excess_ret_simple[idx], na.rm = TRUE) * sqrt(252)
      metrics[[paste0("vol_", h, "d")]] <- vol_window
    }
  }

  # -------------------------
  # 2) Drawdown, Ulcer, underwater
  # -------------------------
  prices <- dt_sym$close_adj
  cummax_p <- cummax(prices)
  dd <- prices / cummax_p - 1
  max_dd <- min(dd, na.rm = TRUE)

  ui <- sqrt(mean((dd * 100)^2, na.rm = TRUE))  # Ulcer Index em pontos percentuais

  underwater <- dd < 0
  if (any(underwater, na.rm = TRUE)) {
    rleid <- data.table::rleid(underwater)
    seg <- data.table::data.table(
      rleid = rleid,
      underwater = underwater
    )[, .N, by = .(rleid, underwater)]
    lengths <- seg[underwater == TRUE]$N
    avg_underwater <- mean(lengths, na.rm = TRUE)
  } else {
    avg_underwater <- 0
  }

  metrics$max_dd              <- max_dd
  metrics$ulcer_index         <- ui
  metrics$avg_time_underwater <- avg_underwater

  # -------------------------
  # 3) Liquidez Amihud
  # -------------------------
  valid <- dt_sym$vol_fin > 0 & !is.na(dt_sym$ret_simple)
  if (any(valid)) {
    amihud <- mean(abs(dt_sym$ret_simple[valid]) / dt_sym$vol_fin[valid], na.rm = TRUE)
  } else {
    amihud <- NA_real_
  }
  metrics$amihud <- amihud

  # -------------------------
  # 4) Skew, Kurt, VaR, CVaR
  # -------------------------
  x <- dt_sym$excess_ret_simple
  x <- x[is.finite(x)]
  if (length(x) > 20L) {
    m <- mean(x, na.rm = TRUE)
    s <- stats::sd(x, na.rm = TRUE)
    if (s > 0) {
      skew <- mean(((x - m) / s)^3, na.rm = TRUE)
      kurt <- mean(((x - m) / s)^4, na.rm = TRUE)
    } else {
      skew <- NA_real_; kurt <- NA_real_
    }
    q <- stats::quantile(x, 0.05, na.rm = TRUE)
    var_95  <- q
    cvar_95 <- mean(x[x <= q], na.rm = TRUE)
  } else {
    skew <- kurt <- NA_real_
    var_95 <- cvar_95 <- NA_real_
  }
  metrics$skew    <- skew
  metrics$kurt    <- kurt
  metrics$var_95  <- var_95
  metrics$cvar_95 <- cvar_95

  # -------------------------
  # 5) Betas / correlações vs fatores se fornecidos
  # -------------------------
  if (!is.null(factor_returns)) {
    fr <- factor_returns
    safe_beta <- function(a, b) {
      ok <- is.finite(a) & is.finite(b)
      if (sum(ok) < 20L) return(NA_real_)
      v <- stats::var(b[ok])
      if (v <= 0) return(NA_real_)
      stats::cov(a[ok], b[ok]) / v
    }
    safe_corr <- function(a, b) {
      ok <- is.finite(a) & is.finite(b)
      if (sum(ok) < 20L) return(NA_real_)
      stats::cor(a[ok], b[ok])
    }
    if (!is.null(fr$ibov)) {
      metrics$beta_ibov <- safe_beta(dt_sym$excess_ret_simple, fr$ibov)
      metrics$corr_ibov <- safe_corr(dt_sym$excess_ret_simple, fr$ibov)
    }
    if (!is.null(fr$usd)) {
      metrics$beta_usd <- safe_beta(dt_sym$excess_ret_simple, fr$usd)
      metrics$corr_usd <- safe_corr(dt_sym$excess_ret_simple, fr$usd)
    }
  }

  data.table::as.data.table(metrics)
}

############################################################
# Função principal: af_run_screener()
############################################################

af_run_screener <- function(panel = NULL,
                            ref_date = Sys.Date(),
                            as_of_date = NULL,
                            config = af_screener_config_default,
                            con = NULL) {
  # If a panel is provided, operate purely in-memory (Option A).
  # Otherwise, pull from DB (legacy path).
  af_attach_packages("data.table")

  db_mode <- is.null(panel)  # <<< FIXED semantic flag
  own_con <- FALSE

  if (db_mode) {
    if (is.null(con)) {
      con <- af_db_connect()
      own_con <- TRUE
    }
    if (!inherits(con, "DBIConnection") || !DBI::dbIsValid(con)) {
      stop("af_run_screener: 'con' is not a valid DBI connection.")
    }
    if (own_con) on.exit(af_db_disconnect(con), add = TRUE)
  }

  ref_date <- as.Date(if (is.null(as_of_date)) ref_date else as_of_date)
  lookback_days <- config$lookback_days
  lookback_start <- ref_date - lookback_days * 2

  if (is.null(panel)) {
    # 1) filtro de liquidez com prices_raw
    liq <- af_compute_basic_liquidity_filter(
      con             = con,
      min_liquidity   = config$min_liquidity,
      min_days_traded = config$min_days_traded,
      lookback_start  = lookback_start,
      ref_date        = ref_date
    )
    if (nrow(liq) == 0L) {
      stop("af_run_screener: no liquid symbols found.")
    }
    symbols_liq <- liq$symbol

    # 2) painel ajustado + retornos
    panel <- af_build_adjusted_panel(con, symbols_liq, lookback_start, ref_date)
    panel_ret <- af_compute_returns(panel)
  } else {
    panel_ret <- data.table::as.data.table(panel)
    if (!all(c("symbol", "refdate") %in% names(panel_ret))) {
      stop("panel must contain symbol/refdate columns.")
    }
    panel_ret[, refdate := as.Date(refdate)]
    panel_ret <- panel_ret[refdate >= lookback_start & refdate <= ref_date]
    # ensure returns exist
    if (!("ret_simple" %in% names(panel_ret))) {
      panel_ret <- af_compute_returns(panel_ret)
    }
    # Apply liquidity filter in panel-first mode as well
    liq <- af_compute_basic_liquidity_from_panel(
      panel_ret,
      min_liquidity   = config$min_liquidity,
      min_days_traded = config$min_days_traded
    )
    if (nrow(liq) == 0L) {
      stop("af_run_screener: no liquid symbols in provided panel.")
    }
    panel_ret <- panel_ret[symbol %in% liq$symbol]
  }

  # 3) fatores macro (ex: IBOV, USD) - DB path only
  macro_needed <- unique(c(config$ibov_series_id, config$usd_series_id))
  macro_needed <- macro_needed[!is.na(macro_needed)]

  macro <- if (length(macro_needed) > 0 && db_mode) {
    af_get_macro_series(con, macro_needed, lookback_start, ref_date)
  } else {
    data.table::data.table()
  }

  factor_returns <- list()
  if (nrow(macro) > 0L) {
    macro_wide <- data.table::dcast(macro, refdate ~ series_id, value.var = "value")
    macro_wide <- macro_wide[order(refdate)]
    # convert levels to returns (pct change) if possible
    for (sid in macro_needed) {
      if (sid %in% names(macro_wide)) {
        vals <- macro_wide[[sid]]
        rts <- c(NA_real_, diff(vals) / head(vals, -1))
        nm <- if (grepl("IBOV", sid, ignore.case = TRUE)) {
          "ibov"
        } else if (grepl("USD", sid, ignore.case = TRUE)) {
          "usd"
        } else {
          tolower(sid)
        }
        factor_returns[[nm]] <- rts
      }
    }
  }

  # 4) limitar para última janela exata de lookback_days por símbolo
  data.table::setorder(panel_ret, symbol, refdate)
  metrics_list <- list()
  for (sym in unique(panel_ret$symbol)) {
    dt_sym <- panel_ret[symbol == sym]
    # pega últimos lookback_days observações (ou todas se < lookback_days)
    if (nrow(dt_sym) > lookback_days) {
      dt_sym <- dt_sym[(.N - lookback_days + 1):.N]
    }
    # fall back to ret_simple if excess not available
    if (!("excess_ret_simple" %in% names(dt_sym))) {
      dt_sym[, excess_ret_simple := ret_simple]
    }
    fr_sym <- NULL
    if (length(factor_returns) > 0L) {
      fr_sym <- lapply(factor_returns, function(x) {
        if (length(x) >= nrow(dt_sym)) tail(x, nrow(dt_sym)) else rep(NA_real_, nrow(dt_sym))
      })
    }
    m <- af_compute_symbol_metrics(
      dt_sym,
      horizons_days  = config$horizons_days,
      factor_returns = fr_sym
    )
    if (!is.null(m)) metrics_list[[sym]] <- m
  }

  metrics <- data.table::rbindlist(metrics_list, fill = TRUE)

  # 5) anexar asset_type da assets_meta (se existir, DB path)
  if (db_mode) {
    meta <- data.table::as.data.table(
      DBI::dbGetQuery(con, "SELECT symbol, asset_type FROM assets_meta")
    )
    metrics <- meta[metrics, on = .(symbol)]
  }

  # 6) escore com z-score por métrica
  w <- config$score_weights
  # Flip sign: use magnitude so bigger drawdown -> bigger penalty with negative weight
  if ("max_dd" %in% names(metrics)) {
    metrics[, max_dd := -max_dd]
  }
  metrics[, score := 0]

  for (nm in names(w)) {
    if (!nm %in% names(metrics)) next
    x <- metrics[[nm]]
    if (all(is.na(x))) next
    mu <- mean(x, na.rm = TRUE)
    s  <- stats::sd(x, na.rm = TRUE)
    if (is.na(s) || s == 0) next
    z <- (x - mu) / s
    metrics[, score := score + w[[nm]] * z]
  }

  # 7) ranking geral e por tipo
  metrics[, rank_overall := rank(-score, ties.method = "first")]
  if ("asset_type" %in% names(metrics)) {
    metrics[, rank_type := rank(-score, ties.method = "first"), by = asset_type]
  } else {
    metrics[, rank_type := NA_integer_]
  }

  list(
    full    = metrics[order(rank_overall)],
    by_type = if ("asset_type" %in% names(metrics)) split(metrics[order(asset_type, rank_type)], metrics$asset_type) else NULL
  )
}



