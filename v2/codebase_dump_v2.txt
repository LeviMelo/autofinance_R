Project structure for '/c/Users/Galaxy/LEVI/Projetos R/autofinance_R/v2':
===============================================================================
  contracts/adjustments.md
  contracts/panel_adj.md
  contracts/screener_input.md
  contracts/screener_output.md
  modules/00_core/R/config.R
  modules/00_core/R/logging.R
  modules/00_core/R/utils.R
  modules/00_core/README.md
  modules/01_b3_universe/R/build_universe.R
  modules/01_b3_universe/R/fetch_daily.R
  modules/01_b3_universe/R/fetch_yearly.R
  modules/01_b3_universe/R/filter_by_type_rb3.R
  modules/01_b3_universe/R/rb3_init.R
  modules/01_b3_universe/R/select_min_cols.R
  modules/01_b3_universe/R/unify_liquidity.R
  modules/01_b3_universe/R/validate_types.R
  modules/01_b3_universe/R/zzz_depends.R
  modules/01_b3_universe/README.md
  modules/02_diagnostics/R/diag_symbol.R
  modules/02_diagnostics/README.md
  modules/03_corporate_actions/codebase_dump_03_corporate_actions.txt
  modules/03_corporate_actions/R/build_registry.R
  modules/03_corporate_actions/R/fetch_dividends_quantmod.R
  modules/03_corporate_actions/R/fetch_events_yahoo_chart.R
  modules/03_corporate_actions/R/fetch_splits_quantmod.R
  modules/03_corporate_actions/R/select_candidates.R
  modules/03_corporate_actions/R/yahoo_retry.R
  modules/03_corporate_actions/R/yahoo_symbol_map.R
  modules/03_corporate_actions/R/zzz_depends.R
  modules/03_corporate_actions/README.md
  modules/04_adjuster/R/apply_adjustments.R
  modules/04_adjuster/R/build_adjustments.R
  modules/04_adjuster/R/build_panel_adj.R
  modules/04_adjuster/R/build_panel_adj_selective.R
  modules/04_adjuster/R/validate_panel_adj.R
  modules/04_adjuster/R/zzz_depends.R
  modules/04_adjuster/README.md
  modules/05_screener/R/compute_metrics.R
  modules/05_screener/R/liquidity_filter.R
  modules/05_screener/R/run_screener.R
  modules/05_screener/R/score_rank.R
  modules/05_screener/R/screener_config.R
  modules/05_screener/R/validate_screener_input.R
  modules/05_screener/README.md
  README.md
  tests/diagnose_adjuster.R
  tests/investigate_corrections.R
  tests/test_data_layer_v2.R
  tests/vis_check.R



###############################################################################
### FILE: README.md
###############################################################################
# autofinance_R v2

Principles:
- In-memory first
- Contract-first
- Fixtures-first
- Screener cannot fetch or adjust data
- Adjuster is the single owner of history mutation



###############################################################################
### FILE: contracts/adjustments.md
###############################################################################
# adjustments.md

## Purpose
`adjustments` is the per-symbol daily adjustment timeline produced by Module 04.
It serves as the audit trail for *why* `panel_adj` differs from `universe_raw`.

## Table contract (schema)

### Keys
- `(symbol, refdate)` unique within this table.

### Required columns
| column           | type      | required | semantics |
|------------------|-----------|----------|----------|
| symbol           | character | yes      | uppercase ticker |
| refdate          | Date      | yes      | trading date |
| split_value      | numeric   | yes      | same-day split price-factor (1 means none). Multiple splits on same day are multiplied. |
| div_cash         | numeric   | yes      | same-day cash dividend amount (0 means none). Multiple dividends summed. |
| split_factor_cum | numeric   | yes      | cumulative split factor applied to *this date* (exclusive: events with refdate > date) |
| div_factor_event | numeric   | yes      | per-day dividend factor (normally 1; <1 on dividend date when computable) |
| div_factor_cum   | numeric   | yes      | cumulative dividend factor applied to *this date* (exclusive) |
| adj_factor_final | numeric   | yes      | `split_factor_cum * div_factor_cum` |
| source_mask      | character | yes      | provenance summary (e.g., `yahoo`, `manual`, `chart`, `yahoo+manual`) |
| has_manual       | logical   | yes      | TRUE if any manual event contributed that day |
| issue_div        | logical   | yes      | TRUE when dividend factor could not be computed safely (e.g. Div >= Price) |

## Dividend issue policy (V2 behavior)
On a day where `div_cash > 0`:
- `div_factor_event = (close_prev - div_cash) / close_prev`
- If `close_prev` is missing/non-finite, `close_prev <= 0`, or `div_cash >= close_prev`:
  - `issue_div = TRUE`
  - `div_factor_event = 1` (adjustment skipped for safety)

This conservative policy prevents negative prices and exploding factors.

## Guarantees
- `split_value > 0`
- `div_cash >= 0`
- `split_factor_cum > 0`
- `div_factor_cum >= 0`
- `adj_factor_final >= 0`


###############################################################################
### FILE: contracts/panel_adj.md
###############################################################################
# panel_adj.md

## Purpose
`panel_adj` is the adjusted daily panel produced by Module 04 (Adjuster).
It contains raw OHLC, split-adjusted OHLC, and final adjusted OHLC (Split + Dividend).
It is the only input accepted by the Screener (Module 05).

## Table contract (schema)

### Keys
- **Primary key:** `(symbol, refdate)` must be **unique**.

### Required columns (minimum)
| column           | type      | required | semantics |
|------------------|-----------|----------|----------|
| symbol           | character | yes      | uppercase ticker |
| refdate          | Date      | yes      | trading date |
| asset_type       | character | yes      | `equity` / `fii` / `etf` / `bdr` |
| close_adj_final  | numeric   | yes      | final adjusted close (splits + dividends) |
| adjustment_state | character | yes      | see below |
| turnover         | numeric   | yes* | liquidity volume in BRL (or `vol_fin`) |
| qty              | numeric   | yes      | liquidity quantity proxy |

\* Either `turnover` OR `vol_fin` must exist. Downstream modules normalize to `turnover`.

### Standard Columns (V2 Production)
Raw aliases:
- `open_raw, high_raw, low_raw, close_raw`

Split-adjusted (intermediate):
- `open_adj_split, high_adj_split, low_adj_split, close_adj_split`

Final adjusted (split + dividend):
- `open_adj_final, high_adj_final, low_adj_final, close_adj_final`

### adjustment_state semantics
- `ok` : no split/dividend events in-range
- `dividend_only` : dividend events applied, no splits
- `split_only` : split events applied, no dividends
- `split_dividend` : both applied
- `manual_override` : at least one manual event present for the symbol
- `suspect_unresolved` : 
    1. Dividend adjustment had computation issue (`issue_div == TRUE`)
    2. **Residual Jump Safety Net:** `close_adj_final` still contains a 1-day log-return > threshold (defaults to 1.0)

### Invariants / Guarantees
- `(symbol, refdate)` uniqueness guaranteed.
- If `adjustment_state == suspect_unresolved`, downstream consumers (Screener) **MUST** exclude the symbol by default.

## Relationship to other outputs
Module 04 also returns:
- `residual_jump_audit`: Table flagging symbols that failed the safety net check.


###############################################################################
### FILE: contracts/screener_input.md
###############################################################################
# screener_input.md

## Purpose
Defines what Module 05 (Screener / Feature builder) accepts.

## Input: panel_adj (from Module 04)

### Keys
- `(symbol, refdate)` must be unique.

### Required columns
- `symbol` (character)
- `refdate` (Date)
- `asset_type` (character)
- `close_adj_final` (numeric)
- `adjustment_state` (character)
- liquidity: either `turnover` or `vol_fin` must exist

### Recommended columns (for OHLC-based features)
- `open_adj_final`, `high_adj_final`, `low_adj_final`

## Policy: Unresolved Suspects (The Safety Valve)
If any rows have `adjustment_state == "suspect_unresolved"` (due to dividend errors or residual jumps):
- **Default behavior:** The Screener **STOP** or **DROP** these symbols immediately.
- **Override:** Allow only if caller explicitly sets `allow_unresolved = TRUE`.

This protects the ranking engine from being poisoned by broken data (e.g. +1900% fake returns).


###############################################################################
### FILE: contracts/screener_output.md
###############################################################################
# screener_output.md

## Purpose
Defines the **feature vector** output produced by Module 05.
This output is intended to be consumed by **separate ranking/scoring logic** (or Alpha Model).

## Output object
`features` (data.table), **one row per symbol**.

## Required identifier/meta columns
| column            | type | meaning |
|-------------------|------|---------|
| symbol            | chr  | ticker |
| asset_type        | chr  | equity/fii/etf/bdr |
| end_refdate       | Date | last date used for features |
| n_obs             | int  | number of rows used in the feature window |
| days_traded_ratio | dbl  | fraction of non-NA `close_adj_final` in window |

## Core price/return features (V2 Standard)
For each horizon `h` in config (e.g., 21, 63, 126, 252):
- `ret_{h}d` : Geometric return over horizon (`p_end / p_start - 1`)
- `vol_{h}d` : Annualized close-to-close volatility (`sd(log_ret) * sqrt(252)`)

## OHLC-based risk features (Optional/Recommended)
For each horizon `h` (when OHLC columns exist):
- `vol_pk_{h}d` : Parkinson volatility (High/Low)
- `vol_gk_{h}d` : Garman-Klass volatility (OHLC)
- `range_mean_{h}d` : Mean daily range fraction
- `gap_vol_{h}d` : Volatility of overnight gaps

## Path-dependence / drawdown features
- `max_dd` : Maximum drawdown in the lookback window
- `ulcer_index` : RMS drawdown metric

## Liquidity features
- `median_turnover` : Median daily financial volume
- `amihud` : Illiquidity proxy (`mean(|ret| / volume)`)

## NA policy
- Features may be `NA` if insufficient data exists for a symbol/horizon.
- The table shape (column set) must remain stable across runs for the same config.


###############################################################################
### FILE: modules/00_core/R/config.R
###############################################################################
# v2/modules/00_core/R/config.R
# ---- bootstrap safety: config.R must not depend on load order ----
if (!exists("%||%", mode = "function")) {
  `%||%` <- function(x, y) if (!is.null(x)) x else y
}

af2_config_default <- list(
  # Universe scope (used later)
  # Dev default: keep it small and fast.
  # Override explicitly for full rebuild.
  years = {
    y <- as.integer(format(Sys.Date(), "%Y"))
    (y-1L):y
  },
  include_types = c("equity", "fii", "etf", "bdr"),

  # Screener liquidity
  min_turnover = 5e5,
  min_days_traded_ratio = 0.8,

  # Corporate actions toggles (used later)
  enable_splits = TRUE,
  enable_manual_events = TRUE,

  # Paths
  cache_dir  = "v2/data/cache",
  raw_dir    = "v2/data/raw",
  fixtures_dir = "v2/data/fixtures",
  manual_dir = "v2/data/manual",
  logs_dir   = "v2/logs",

  # Safety
  allow_unresolved_in_screener = FALSE,

  # Adjuster residual jump safety net (log-return tolerance).
  # 1.0 means any 1-day move >= e^1 (~2.718x) flags suspect_unresolved.
  adj_residual_jump_tol_log = 1.0,

  # -------------------------------
  # Selective corporate-actions policy (the "trick")
  # -------------------------------
  enable_selective_actions = TRUE,

  # Cache strategy for corp actions:
  # - "batch" keeps current behavior (hash by symbol set)
  # - "by_symbol" enables incremental caching per ticker
  ca_cache_mode = "batch",

  # Corporate actions fetch mode:
  # - "chart"   = Yahoo chart endpoint (splits+dividends in one call)
  # - "quantmod"= legacy quantmod calls (getSplits + getDividends)
  ca_fetch_mode = "chart",

  # Candidate prefilter: detect reverse-split-like jumps using abs(log(close/lag)).
  # 1.0 ~ e^1 = 2.718x jump threshold.
  ca_prefilter_jump_log_thr = 1.0,

  # Prefilter heuristics (B3-only)
  ca_prefilter_recent_days   = 252L,
  ca_prefilter_top_n_overall = 200L,
  ca_prefilter_top_n_by_type = 50L,
  ca_prefilter_max_candidates = 300L,

  # One-day gap thresholds by type (very cheap anomaly filter)
  ca_prefilter_gap_equity = -0.20,
  ca_prefilter_gap_fii    = -0.12,
  ca_prefilter_gap_etf    = -0.15,
  ca_prefilter_gap_bdr    = -0.20,

  # Activeness / recency guards for selective CA
  ca_prefilter_active_days = 10L,

  # Use a shorter window for liquidity scoring (robust to old junk)
  ca_prefilter_liq_window_days = 63L,

  # -------------------------------
  # Split sanity gates (debug + safety)
  # Values are PRICE FACTORS after normalization.
  # Typical forward splits: 0.5, 0.333..., 0.2
  # Typical reverse splits: 2, 5, 10 (rare)
  # -------------------------------
  enable_split_plausibility_gate = FALSE,
  split_gate_min = 0.05,  # conservative, allows 20:1
  split_gate_max = 10.0,  # conservative, allows 1:10 reverse

  # Split-gap validation against raw
  enable_split_gap_validation = TRUE,
  split_gap_tol_log = 0.35,

  # NEW: how far forward we allow snapping Yahoo split dates
  # to the next B3 trading day (for weekend/holiday/vendor-date mismatches)
  split_gap_max_forward_days = 5L,

  # How far BACK we allow snapping Yahoo vendor split dates
  # (vendor date can be 1-3 days off vs B3 effective trading day).
  split_gap_max_back_days = 3L,

  # NEW: prefer using post-day OPEN when available (splits are effective at market open);
  # fallback to CLOSE if OPEN missing.
  split_gap_use_open = TRUE

)

af2_get_config <- function(config = NULL) {
  cfg <- af2_config_default
  if (!is.null(config)) {
    # shallow override for now (keep simple)
    for (nm in names(config)) cfg[[nm]] <- config[[nm]]
  }
  # ensure dirs exist
  dir.create(cfg$cache_dir, recursive = TRUE, showWarnings = FALSE)
  dir.create(cfg$raw_dir, recursive = TRUE, showWarnings = FALSE)
  dir.create(cfg$fixtures_dir, recursive = TRUE, showWarnings = FALSE)
  dir.create(cfg$manual_dir, recursive = TRUE, showWarnings = FALSE)
  dir.create(cfg$logs_dir, recursive = TRUE, showWarnings = FALSE)

  # -------------------------------
  # Validation of sensitive knobs
  # -------------------------------
  if (!is.null(cfg$ca_cache_mode) &&
      !cfg$ca_cache_mode %in% c("batch", "by_symbol", "none")) {
    stop("Invalid ca_cache_mode: ", cfg$ca_cache_mode,
         ". Allowed: batch, by_symbol, none", call. = FALSE)
  }

  cfg$ca_prefilter_recent_days <- as.integer(cfg$ca_prefilter_recent_days %||% 252L)
  cfg$ca_prefilter_top_n_overall <- as.integer(cfg$ca_prefilter_top_n_overall %||% 200L)
  cfg$ca_prefilter_top_n_by_type <- as.integer(cfg$ca_prefilter_top_n_by_type %||% 50L)
  cfg$ca_prefilter_max_candidates <- as.integer(cfg$ca_prefilter_max_candidates %||% 300L)

  cfg$enable_split_gap_validation <- isTRUE(cfg$enable_split_gap_validation)
  cfg$split_gap_tol_log <- as.numeric(cfg$split_gap_tol_log %||% 0.35)

  cfg$split_gap_max_forward_days <- as.integer(cfg$split_gap_max_forward_days %||% 5L)
  if (!is.finite(cfg$split_gap_max_forward_days) || cfg$split_gap_max_forward_days < 0L) {
    cfg$split_gap_max_forward_days <- 5L
  }

  cfg$split_gap_use_open <- isTRUE(cfg$split_gap_use_open)

  # -------------------------------
  # Normalize newer knobs
  # -------------------------------
  cfg$ca_fetch_mode <- tolower(trimws(cfg$ca_fetch_mode %||% "chart"))
  if (!cfg$ca_fetch_mode %in% c("chart", "quantmod")) {
    cfg$ca_fetch_mode <- "chart"
  }

  cfg$ca_prefilter_jump_log_thr <- as.numeric(cfg$ca_prefilter_jump_log_thr %||% 1.0)
  if (!is.finite(cfg$ca_prefilter_jump_log_thr) || cfg$ca_prefilter_jump_log_thr < 0.5) {
    cfg$ca_prefilter_jump_log_thr <- 1.0
  }

  cfg$adj_residual_jump_tol_log <- as.numeric(cfg$adj_residual_jump_tol_log %||% 1.0)
  if (!is.finite(cfg$adj_residual_jump_tol_log) || cfg$adj_residual_jump_tol_log <= 0) {
    cfg$adj_residual_jump_tol_log <- 1.0
  }

  cfg$split_gap_max_back_days <- as.integer(cfg$split_gap_max_back_days %||% 3L)
  if (!is.finite(cfg$split_gap_max_back_days) || cfg$split_gap_max_back_days < 0L) {
    cfg$split_gap_max_back_days <- 3L
  }

  cfg
}



###############################################################################
### FILE: modules/00_core/R/logging.R
###############################################################################
# v2/modules/00_core/R/logging.R

af2_log <- function(prefix, ...) {
  msg <- paste0(prefix, " ", paste(..., collapse = ""))
  message(msg)
}

af2_log_cfg <- function(config) {
  af2_log("AF2_CFG:", "\n", paste(utils::capture.output(str(config)), collapse = "\n"))
}



###############################################################################
### FILE: modules/00_core/R/utils.R
###############################################################################
# v2/modules/00_core/R/utils.R

`%||%` <- function(x, y) if (!is.null(x)) x else y

af2_require <- function(pkgs) {
  pkgs <- unique(pkgs)
  missing <- pkgs[!vapply(pkgs, requireNamespace, logical(1), quietly = TRUE)]
  if (length(missing)) {
    stop("Missing packages in v2 environment: ",
         paste(missing, collapse = ", "),
         "\nInstall them explicitly to keep v2 deterministic.",
         call. = FALSE)
  }
  invisible(TRUE)
}

af2_assert_cols <- function(dt, cols, name = "object") {
  if (is.null(dt)) stop(name, " is NULL.", call. = FALSE)
  if (!is.data.frame(dt)) stop(name, " must be a data.frame/data.table.", call. = FALSE)
  miss <- setdiff(cols, names(dt))
  if (length(miss)) {
    stop(name, " missing required columns: ", paste(miss, collapse = ", "), call. = FALSE)
  }
  invisible(TRUE)
}

af2_assert_no_dupes <- function(dt, key_cols, name = "object") {
  af2_require("data.table")
  x <- data.table::as.data.table(dt)
  dup <- x[, .N, by = key_cols][N > 1L]
  if (nrow(dup)) {
    stop(name, " has duplicated keys on: ",
         paste(key_cols, collapse = ", "),
         "\nExample dup rows:\n",
         paste(utils::capture.output(print(utils::head(dup, 10))), collapse = "\n"),
         call. = FALSE)
  }
  invisible(TRUE)
}

af2_weekdays_only <- function(dates) {
  w <- weekdays(dates)
  !(w %in% c("Saturday", "Sunday", "sábado", "domingo"))
}

af2_make_bizdays_seq <- function(start_date, end_date, cal = "Brazil/B3") {
  start_date <- as.Date(start_date)
  end_date   <- as.Date(end_date)

  # Prefer the official calendar if available
  if (requireNamespace("bizdays", quietly = TRUE)) {
    out <- tryCatch(
      bizdays::bizseq(start_date, end_date, cal),
      error = function(e) NULL
    )
    if (!is.null(out) && length(out)) {
      return(as.Date(out))
    }
  }

  # Fallback: weekdays only
  d <- seq.Date(start_date, end_date, by = "day")
  d[af2_weekdays_only(d)]
}




###############################################################################
### FILE: modules/00_core/README.md
###############################################################################
# Module

Purpose:
- Define INPUT contract
- Define OUTPUT contract
- List functions
- List tests



###############################################################################
### FILE: modules/01_b3_universe/R/build_universe.R
###############################################################################
# v2/modules/01_b3_universe/R/build_universe.R

af2_b3_cache_key <- function(year, include_types) {
  paste0(
    "cotahist_yearly_",
    year, "_",
    paste(sort(include_types), collapse = "-"),
    ".rds"
  )
}

af2_b3_build_universe_year <- function(year,
                                       include_types = NULL,
                                       cfg = NULL,
                                       verbose = TRUE,
                                       use_cache = TRUE,
                                       force_download = FALSE,
                                       reprocess = FALSE) {
  cfg <- cfg %||% af2_get_config()

  include_types <- include_types %||% cfg$include_types
  include_types <- af2_b3_validate_types(include_types)

  # Cache path
  cache_dir <- file.path(cfg$cache_dir, "b3_universe")
  if (!dir.exists(cache_dir)) dir.create(cache_dir, recursive = TRUE)

  cache_file <- file.path(cache_dir, af2_b3_cache_key(year, include_types))

  if (isTRUE(use_cache) && file.exists(cache_file) && !isTRUE(force_download)) {
    if (verbose) af2_log("AF2_B3:", "Using cache: ", cache_file)
    dt_cached <- readRDS(cache_file)
    return(data.table::as.data.table(dt_cached))
  }

  # 1) Lazy fetch
  df_lazy <- af2_b3_fetch_yearly_lazy(
    year = year, cfg = cfg, verbose = verbose,
    force_download = force_download,
    reprocess = reprocess
  )

  # 2) Apply type filters lazily
  lazy_by_type <- af2_b3_apply_type_filters(df_lazy, include_types)

  # 3) Collect each type separately (bounded)
  out_list <- list()

  for (tp in names(lazy_by_type)) {
    if (verbose) af2_log("AF2_B3:", "Collecting type: ", tp, " for ", year)
    df_tp <- dplyr::collect(lazy_by_type[[tp]])
    if (!nrow(df_tp)) next

    dt_min <- af2_b3_select_min_cols(df_tp)
    dt_liq <- af2_b3_unify_liquidity(dt_min)
    dt_liq[, asset_type := tp]

    out_list[[tp]] <- dt_liq
  }

  if (!length(out_list)) {
    stop("af2_b3_build_universe_year: no data returned after filters for year ", year)
  }

  dt_year <- data.table::rbindlist(out_list, use.names = TRUE, fill = TRUE)
  data.table::setorder(dt_year, asset_type, symbol, refdate)

  # 4) Validate contract
  required <- c("symbol", "refdate", "open", "high", "low", "close", "turnover", "qty", "asset_type")
  miss <- setdiff(required, names(dt_year))
  if (length(miss)) {
    stop("Universe contract violated. Missing cols: ", paste(miss, collapse = ", "))
  }

  # 5) Drop obvious junk rows
  dt_year <- dt_year[!is.na(symbol) & symbol != "" & !is.na(refdate) & is.finite(close)]

  # 5b) Enforce unique (symbol, refdate) keys (upstream rb3 edge-case)
  # Dedupe rule (contract):
  # 1) max turnover, 2) max qty, 3) max close, 4) first deterministic row
  data.table::setorder(dt_year, asset_type, symbol, refdate)
  
  dup <- dt_year[, .N, by = .(symbol, refdate)][N > 1L]
  if (nrow(dup)) {
    if (verbose) {
      af2_log(
        "AF2_B3:",
        "WARNING: duplicated (symbol, refdate) detected in universe_raw year=", year,
        ". Applying dedupe rule. Examples:"
      )
      print(utils::head(dup[order(-N)], 10))
    }
  
    # Make ordering deterministic for tie-breaking
    if (!("turnover" %in% names(dt_year))) dt_year[, turnover := NA_real_]
    if (!("qty" %in% names(dt_year))) dt_year[, qty := NA_real_]
  
    dt_year <- dt_year[
      order(
        symbol, refdate,
        -data.table::fifelse(is.finite(turnover), turnover, -Inf),
        -data.table::fifelse(is.finite(qty), qty, -Inf),
        -data.table::fifelse(is.finite(close), close, -Inf)
      )
    ][, .SD[1L], by = .(symbol, refdate)]
  
    data.table::setorder(dt_year, asset_type, symbol, refdate)
  }

  if (verbose) {
    af2_log("AF2_B3:", "Year ", year, " rows = ", nrow(dt_year))
    af2_log("AF2_B3:", "Unique symbols = ", length(unique(dt_year$symbol)))
    af2_log("AF2_B3:", "Counts by type:")
    print(dt_year[, .N, by = asset_type][order(-N)])
  }

  # 6) Save cache
  if (isTRUE(use_cache)) {
    saveRDS(dt_year, cache_file)
    if (verbose) af2_log("AF2_B3:", "Wrote cache: ", cache_file)
  }

  dt_year
}

af2_b3_build_universe <- function(years = NULL,
                                  include_types = NULL,
                                  cfg = NULL,
                                  verbose = TRUE,
                                  use_cache = TRUE,
                                  force_download = FALSE,
                                  reprocess = FALSE) {
  cfg <- cfg %||% af2_get_config()
  years <- years %||% cfg$years
  years <- sort(unique(as.integer(years)))

  include_types <- include_types %||% cfg$include_types
  include_types <- af2_b3_validate_types(include_types)

  out <- list()
  for (y in years) {
    out[[as.character(y)]] <- af2_b3_build_universe_year(
      year = y,
      include_types = include_types,
      cfg = cfg,
      verbose = verbose,
      use_cache = use_cache,
      force_download = force_download,
      reprocess = reprocess
    )
  }

  dt_all <- data.table::rbindlist(out, use.names = TRUE, fill = TRUE)
  data.table::setorder(dt_all, asset_type, symbol, refdate)

  dt_all
}

af2_b3_cache_key_window <- function(start_date, end_date, include_types) {
  paste0(
    "cotahist_daily_",
    format(as.Date(start_date), "%Y%m%d"), "_",
    format(as.Date(end_date), "%Y%m%d"), "_",
    paste(sort(include_types), collapse = "-"),
    ".rds"
  )
}

af2_b3_build_universe_window <- function(start_date, end_date,
                                         include_types = NULL,
                                         cfg = NULL,
                                         verbose = TRUE,
                                         use_cache = TRUE,
                                         force_download = FALSE,
                                         reprocess = FALSE) {

  cfg <- cfg %||% af2_get_config()

  include_types <- include_types %||% cfg$include_types
  include_types <- af2_b3_validate_types(include_types)

  start_date <- as.Date(start_date)
  end_date   <- as.Date(end_date)

  # Cache path
  cache_dir <- file.path(cfg$cache_dir, "b3_universe")
  if (!dir.exists(cache_dir)) dir.create(cache_dir, recursive = TRUE)

  cache_file <- file.path(cache_dir, af2_b3_cache_key_window(start_date, end_date, include_types))

  if (isTRUE(use_cache) && file.exists(cache_file) && !isTRUE(force_download)) {
    if (verbose) af2_log("AF2_B3:", "Using cache: ", cache_file)
    dt_cached <- readRDS(cache_file)
    return(data.table::as.data.table(dt_cached))
  }

  # 1) Lazy fetch daily window
  df_lazy <- af2_b3_fetch_daily_lazy(
    start_date = start_date,
    end_date   = end_date,
    cfg = cfg,
    verbose = verbose,
    force_download = force_download,
    reprocess = reprocess
  )

  # 2) Apply type filters lazily
  lazy_by_type <- af2_b3_apply_type_filters(df_lazy, include_types)

  # 3) Collect each type separately (bounded)
  out_list <- list()

  for (tp in names(lazy_by_type)) {
    if (verbose) af2_log("AF2_B3:", "Collecting type: ", tp,
                         " for window ", start_date, " to ", end_date)

    df_tp <- dplyr::collect(lazy_by_type[[tp]])
    if (!nrow(df_tp)) next

    dt_min <- af2_b3_select_min_cols(df_tp)
    dt_liq <- af2_b3_unify_liquidity(dt_min)
    dt_liq[, asset_type := tp]

    out_list[[tp]] <- dt_liq
  }

  if (!length(out_list)) {
    stop("af2_b3_build_universe_window: no data returned after filters.")
  }

  dt_win <- data.table::rbindlist(out_list, use.names = TRUE, fill = TRUE)
  data.table::setorder(dt_win, asset_type, symbol, refdate)

  # 4) Validate contract
  required <- c("symbol", "refdate", "open", "high", "low", "close",
                "turnover", "qty", "asset_type")
  miss <- setdiff(required, names(dt_win))
  if (length(miss)) stop("Universe contract violated. Missing cols: ", paste(miss, collapse = ", "))

  # 5) Drop obvious junk
  dt_win <- dt_win[!is.na(symbol) & symbol != "" & !is.na(refdate) & is.finite(close)]
  
  # 5b) Enforce unique (symbol, refdate) keys (upstream rb3 edge-case)
  data.table::setorder(dt_win, asset_type, symbol, refdate)
  
  dup <- dt_win[, .N, by = .(symbol, refdate)][N > 1L]
  if (nrow(dup)) {
    if (verbose) {
      af2_log(
        "AF2_B3:",
        "WARNING: duplicated (symbol, refdate) detected in universe_raw window ",
        as.character(start_date), " to ", as.character(end_date),
        ". Applying dedupe rule. Examples:"
      )
      print(utils::head(dup[order(-N)], 10))
    }
  
    if (!("turnover" %in% names(dt_win))) dt_win[, turnover := NA_real_]
    if (!("qty" %in% names(dt_win))) dt_win[, qty := NA_real_]
  
    dt_win <- dt_win[
      order(
        symbol, refdate,
        -data.table::fifelse(is.finite(turnover), turnover, -Inf),
        -data.table::fifelse(is.finite(qty), qty, -Inf),
        -data.table::fifelse(is.finite(close), close, -Inf)
      )
    ][, .SD[1L], by = .(symbol, refdate)]
  
    data.table::setorder(dt_win, asset_type, symbol, refdate)
  }

  if (verbose) {
    af2_log("AF2_B3:", "Window rows = ", nrow(dt_win))
    af2_log("AF2_B3:", "Unique symbols = ", length(unique(dt_win$symbol)))
    af2_log("AF2_B3:", "Counts by type:")
    print(dt_win[, .N, by = asset_type][order(-N)])
  }

  if (isTRUE(use_cache)) {
    saveRDS(dt_win, cache_file)
    if (verbose) af2_log("AF2_B3:", "Wrote cache: ", cache_file)
  }

  dt_win
}



###############################################################################
### FILE: modules/01_b3_universe/R/fetch_daily.R
###############################################################################
# Fetch a daily window with rb3, then return *lazy* dataset handle

af2_b3_fetch_daily_lazy <- function(start_date, end_date,
                                    cfg = NULL, verbose = TRUE,
                                    force_download = FALSE,
                                    reprocess = FALSE,
                                    throttle = TRUE) {

  cfg <- cfg %||% af2_get_config()
  af2_b3_init_rb3(cfg, verbose = verbose)

  start_date <- as.Date(start_date)
  end_date   <- as.Date(end_date)

  # Now uses proper B3 bizdays if available
  refdates <- af2_make_bizdays_seq(start_date, end_date)

  if (!length(refdates)) {
    stop("af2_b3_fetch_daily_lazy: empty refdate sequence.")
  }

  if (verbose) {
    af2_log("AF2_B3:", "fetch_marketdata daily window: ",
            as.character(start_date), " to ", as.character(end_date),
            " (", length(refdates), " dates)")
  }

  ok <- TRUE
  tryCatch({
    rb3::fetch_marketdata(
      "b3-cotahist-daily",
      refdate = refdates,
      throttle = isTRUE(throttle),
      force_download = isTRUE(force_download),
      reprocess = isTRUE(reprocess)
    )
  }, error = function(e) {
    ok <<- FALSE
    af2_log("AF2_B3:", "fetch_marketdata daily failed: ", conditionMessage(e))
  })

  if (!ok) {
    for (d in refdates) {
      tryCatch({
        meta <- rb3::download_marketdata("b3-cotahist-daily", refdate = d)
        rb3::read_marketdata(meta)
      }, error = function(e2) {
        if (verbose) af2_log("AF2_B3:", "daily fallback failed for ", d, ": ", conditionMessage(e2))
      })
    }
  }

  df_lazy <- tryCatch({
    rb3::cotahist_get("daily")
  }, error = function(e) {
    stop("cotahist_get('daily') failed: ", conditionMessage(e))
  })

  df_lazy |>
    dplyr::filter(.data$refdate >= start_date, .data$refdate <= end_date)
}


###############################################################################
### FILE: modules/01_b3_universe/R/fetch_yearly.R
###############################################################################
# v2/modules/01_b3_universe/R/fetch_yearly.R
# Fetch one year with rb3, then return *lazy* dataset handle

af2_b3_fetch_yearly_lazy <- function(year, cfg = NULL, verbose = TRUE,
                                     force_download = FALSE,
                                     reprocess = FALSE) {
  cfg <- cfg %||% af2_get_config()
  af2_b3_init_rb3(cfg, verbose = verbose)

  year <- as.integer(year)

  if (verbose) af2_log("AF2_B3:", "fetch_marketdata yearly: ", year)

  ok <- TRUE
  tryCatch({
    rb3::fetch_marketdata(
      "b3-cotahist-yearly",
      year = year,
      throttle = TRUE,
      force_download = isTRUE(force_download),
      reprocess = isTRUE(reprocess)
    )
  }, error = function(e) {
    ok <<- FALSE
    af2_log("AF2_B3:", "fetch_marketdata failed for ", year, ": ", conditionMessage(e))
  })

  if (!ok) {
    # Fallback path
    tryCatch({
      meta <- rb3::download_marketdata("b3-cotahist-yearly", year = year)
      rb3::read_marketdata(meta)
      af2_log("AF2_B3:", "fallback download/read OK for ", year)
    }, error = function(e2) {
      stop("rb3 fallback download/read failed for ", year, ": ", conditionMessage(e2))
    })
  }

  df_lazy <- tryCatch({
    rb3::cotahist_get("yearly")
  }, error = function(e) {
    stop("cotahist_get('yearly') failed: ", conditionMessage(e))
  })

  start_y <- as.Date(paste0(year, "-01-01"))
  end_y   <- as.Date(paste0(year + 1L, "-01-01"))

  df_lazy <- df_lazy |>
    dplyr::filter(.data$refdate >= start_y, .data$refdate < end_y)

  df_lazy
}



###############################################################################
### FILE: modules/01_b3_universe/R/filter_by_type_rb3.R
###############################################################################
# v2/modules/01_b3_universe/R/filter_by_type_rb3.R
# Apply rb3 class filters BEFORE collect

af2_b3_apply_type_filters <- function(df_lazy, include_types) {
  include_types <- af2_b3_validate_types(include_types)

  # Start with empty list of lazy datasets, bind after filtering
  out_list <- list()

  if ("equity" %in% include_types) {
    out_list[["equity"]] <- rb3::cotahist_filter_equity(df_lazy)
  }
  if ("fii" %in% include_types) {
    out_list[["fii"]] <- rb3::cotahist_filter_fii(df_lazy)
  }
  if ("etf" %in% include_types) {
    out_list[["etf"]] <- rb3::cotahist_filter_etf(df_lazy)
  }
  if ("bdr" %in% include_types) {
    out_list[["bdr"]] <- rb3::cotahist_filter_bdr(df_lazy)
  }

  if (!length(out_list)) {
    stop("No include_types provided after validation.")
  }

  out_list
}



###############################################################################
### FILE: modules/01_b3_universe/R/rb3_init.R
###############################################################################
# v2/modules/01_b3_universe/R/rb3_init.R
# Deterministic rb3 cache bootstrap for v2

af2_b3_init_rb3 <- function(cfg = NULL, verbose = TRUE) {
  cfg <- cfg %||% af2_get_config()

  cache_dir <- file.path(cfg$cache_dir, "rb3")
  if (!dir.exists(cache_dir)) dir.create(cache_dir, recursive = TRUE)

  options(rb3.cachedir = normalizePath(cache_dir, winslash = "/", mustWork = FALSE))

  if (verbose) {
    af2_log("AF2_B3:", "rb3.cachedir = ", getOption("rb3.cachedir"))
  }

  # Bootstrap templates DB (safe no-op if already initialized)
  tryCatch({
    rb3::rb3_bootstrap()
    if (verbose) af2_log("AF2_B3:", "rb3_bootstrap OK.")
  }, error = function(e) {
    # We don't hard fail here because rb3 can still read cached data;
    # but we DO log clearly.
    af2_log("AF2_B3:", "rb3_bootstrap warning: ", conditionMessage(e))
  })

  invisible(TRUE)
}



###############################################################################
### FILE: modules/01_b3_universe/R/select_min_cols.R
###############################################################################
# v2/modules/01_b3_universe/R/select_min_cols.R
# Normalize column names across potential rb3 schema differences

af2_b3_pick_col <- function(dt, alternatives) {
  cand <- intersect(alternatives, names(dt))
  if (length(cand)) cand[1L] else NA_character_
}

af2_b3_select_min_cols <- function(dt) {
  # dt is a collected data.frame/data.table from rb3

  # Defensive mapping of OHLC + liquidity
  col_symbol <- af2_b3_pick_col(dt, c("symbol", "ticker"))
  col_ref    <- af2_b3_pick_col(dt, c("refdate", "date"))
  col_open   <- af2_b3_pick_col(dt, c("open", "price.open", "preco_abertura"))
  col_high   <- af2_b3_pick_col(dt, c("high", "price.high", "preco_maximo"))
  col_low    <- af2_b3_pick_col(dt, c("low", "price.low", "preco_minimo"))
  col_close  <- af2_b3_pick_col(dt, c("close", "price.close", "preco_ultimo"))

  # Liquidity candidates:
  # - financial_volume / volume in BRL
  # - trade_quantity in units
  col_volfin <- af2_b3_pick_col(dt, c("financial_volume", "volume", "vol_fin"))
  col_qty <- af2_b3_pick_col(dt, c("trade_quantity", "quantity", "qty"))

  missing_core <- c(
    symbol = col_symbol,
    refdate = col_ref,
    close = col_close
  )
  if (any(is.na(missing_core))) {
    stop(
      "COTAHIST schema missing core columns. Found names: ",
      paste(names(dt), collapse = ", ")
    )
  }

  out <- data.table::as.data.table(dt)

  out_min <- data.table::data.table(
    symbol  = trimws(as.character(out[[col_symbol]])),
    refdate = as.Date(out[[col_ref]]),
    open    = if (!is.na(col_open))  as.numeric(out[[col_open]])  else NA_real_,
    high    = if (!is.na(col_high))  as.numeric(out[[col_high]])  else NA_real_,
    low     = if (!is.na(col_low))   as.numeric(out[[col_low]])   else NA_real_,
    close   = as.numeric(out[[col_close]]),
    vol_fin = if (!is.na(col_volfin)) as.numeric(out[[col_volfin]]) else NA_real_,
    qty_raw = if (!is.na(col_qty))    as.numeric(out[[col_qty]])    else NA_real_
  )

  out_min
}



###############################################################################
### FILE: modules/01_b3_universe/R/unify_liquidity.R
###############################################################################
# v2/modules/01_b3_universe/R/unify_liquidity.R
# Convert raw liquidity into standardized 'turnover' and 'qty'

af2_b3_unify_liquidity <- function(dt_min) {
  dt <- data.table::as.data.table(dt_min)

  if (!all(c("symbol", "refdate", "close") %in% names(dt))) {
    stop("Liquidity unify requires at least symbol/refdate/close.")
  }

  # qty meaning in rb3 can be ambiguous across templates.
  # We treat 'qty_raw' as units proxy and keep it as qty.
  if (!("qty_raw" %in% names(dt))) dt[, qty_raw := NA_real_]
  if (!("vol_fin" %in% names(dt))) dt[, vol_fin := NA_real_]

  dt[, qty := qty_raw]

  # turnover in BRL:
  # Prefer provided financial volume when present, otherwise fallback to qty * close.
  dt[, turnover := data.table::fifelse(
    is.finite(vol_fin) & vol_fin > 0,
    vol_fin,
    data.table::fifelse(
      is.finite(qty) & qty > 0 & is.finite(close),
      qty * close,
      NA_real_
    )
  )]

  dt[, c("vol_fin", "qty_raw") := NULL]

  dt
}



###############################################################################
### FILE: modules/01_b3_universe/R/validate_types.R
###############################################################################
# v2/modules/01_b3_universe/R/validate_types.R

af2_b3_allowed_types <- c("equity", "fii", "etf", "bdr")

af2_b3_validate_types <- function(include_types) {
  include_types <- unique(tolower(include_types))
  bad <- setdiff(include_types, af2_b3_allowed_types)
  if (length(bad)) {
    stop(
      "Invalid include_types: ", paste(bad, collapse = ", "),
      ". Allowed: ", paste(af2_b3_allowed_types, collapse = ", ")
    )
  }
  include_types
}



###############################################################################
### FILE: modules/01_b3_universe/R/zzz_depends.R
###############################################################################
# v2/modules/01_b3_universe/R/zzz_depends.R
# Centralized dependency + core imports (NO recursion)

if (!exists("af2_get_config")) {
  stop("af2_get_config not found. Source v2/modules/00_core/R/config.R first.")
}
if (!exists("af2_log")) {
  stop("af2_log not found. Source v2/modules/00_core/R/logging.R first.")
}

# Keep it dumb and safe: no wrapper, no indirection.
af2_b3_require <- function(pkgs) {
  for (p in pkgs) {
    if (!requireNamespace(p, quietly = TRUE)) {
      stop("Missing package: ", p)
    }
  }
  invisible(TRUE)
}

af2_b3_require(c("data.table", "dplyr", "lubridate", "rb3"))

suppressPackageStartupMessages({
  library(data.table)
  library(dplyr)
  library(lubridate)
  library(rb3)
})



###############################################################################
### FILE: modules/01_b3_universe/README.md
###############################################################################
# Module

Purpose:
- Define INPUT contract
- Define OUTPUT contract
- List functions
- List tests



###############################################################################
### FILE: modules/02_diagnostics/R/diag_symbol.R
###############################################################################
# v2/modules/02_diagnostics/R/diag_symbol.R
# Deterministic per-symbol diagnostics (raw vs adjusted, events, biggest jumps)

af2_diag_symbol <- function(symbol,
                            panel_adj,
                            events = NULL,
                            corp_actions_apply = NULL,
                            split_audit = NULL,
                            show_plot = TRUE,
                            top_n_jumps = 5L) {

  af2_require("data.table")
  sym <- toupper(trimws(as.character(symbol)))

  dt <- data.table::as.data.table(panel_adj)
  dt <- dt[symbol == sym]
  if (!nrow(dt)) {
    message("AF2_DIAG: symbol not found in panel_adj: ", sym)
    return(invisible(NULL))
  }

  data.table::setorder(dt, refdate)

  # Basic summary
  cat("\n========================\n")
  cat("AF2_DIAG SYMBOL: ", sym, "\n", sep = "")
  cat("========================\n")
  cat("Date range: ", as.character(min(dt$refdate)), " -> ", as.character(max(dt$refdate)), "\n", sep = "")
  cat("Rows: ", nrow(dt), "\n", sep = "")
  if ("asset_type" %in% names(dt)) cat("Asset type: ", unique(dt$asset_type), "\n", sep = "")
  if ("adjustment_state" %in% names(dt)) cat("Adjustment state(s): ", paste(unique(dt$adjustment_state), collapse = ", "), "\n", sep = "")

  # Compute jumps
  get_jump_table <- function(x, dates) {
    x <- as.numeric(x)
    ok <- is.finite(x) & x > 0
    if (sum(ok) < 3) return(data.table::data.table())
    lr <- diff(log(x))
    d  <- dates[-1]
    out <- data.table::data.table(
      refdate = as.Date(d),
      logret  = as.numeric(lr),
      abs_logret = abs(as.numeric(lr))
    )
    out[is.finite(abs_logret)]
  }

  jt_raw   <- if ("close_raw" %in% names(dt)) get_jump_table(dt$close_raw, dt$refdate) else data.table::data.table()
  jt_split <- if ("close_adj_split" %in% names(dt)) get_jump_table(dt$close_adj_split, dt$refdate) else data.table::data.table()
  jt_final <- if ("close_adj_final" %in% names(dt)) get_jump_table(dt$close_adj_final, dt$refdate) else data.table::data.table()

  if (nrow(jt_raw)) {
    cat("\nTop raw jumps (abs logret):\n")
    print(jt_raw[order(-abs_logret)][1:top_n_jumps])
  }
  if (nrow(jt_split)) {
    cat("\nTop split-adjusted jumps (abs logret):\n")
    print(jt_split[order(-abs_logret)][1:top_n_jumps])
  }
  if (nrow(jt_final)) {
    cat("\nTop final-adjusted jumps (abs logret):\n")
    print(jt_final[order(-abs_logret)][1:top_n_jumps])
  }

  # Events slice
  if (!is.null(events)) {
    ev <- data.table::as.data.table(events)[symbol == sym]
    if (nrow(ev)) {
      data.table::setorder(ev, refdate)
      cat("\nEvents for symbol:\n")
      print(ev)
    } else {
      cat("\nEvents for symbol: (none)\n")
    }
  }

  # CA slice
  if (!is.null(corp_actions_apply)) {
    ca <- data.table::as.data.table(corp_actions_apply)[symbol == sym]
    if (nrow(ca)) {
      data.table::setorder(ca, refdate, action_type)
      cat("\ncorp_actions_apply rows:\n")
      print(ca)
    } else {
      cat("\ncorp_actions_apply: (none)\n")
    }
  }

  # Split audit slice
  if (!is.null(split_audit) && nrow(split_audit)) {
    sa <- data.table::as.data.table(split_audit)[symbol == sym]
    if (nrow(sa)) {
      data.table::setorder(sa, vendor_refdate)
      cat("\nSplit audit rows:\n")
      print(sa)
    }
  }

  # Plot
  if (isTRUE(show_plot) && interactive()) {
    op <- par(no.readonly = TRUE)
    on.exit(par(op), add = TRUE)

    par(mfrow = c(2, 1))

    if ("close_raw" %in% names(dt)) {
      plot(dt$refdate, dt$close_raw, type = "l",
           main = paste0(sym, " — close_raw"),
           xlab = "", ylab = "")
    } else {
      plot.new(); title(main = paste0(sym, " — close_raw missing"))
    }

    if ("close_adj_final" %in% names(dt)) {
      plot(dt$refdate, dt$close_adj_final, type = "l",
           main = paste0(sym, " — close_adj_final"),
           xlab = "", ylab = "")
    } else {
      plot.new(); title(main = paste0(sym, " — close_adj_final missing"))
    }
  }

  invisible(list(
    symbol = sym,
    panel = dt,
    jumps_raw = jt_raw,
    jumps_split = jt_split,
    jumps_final = jt_final
  ))
}



###############################################################################
### FILE: modules/02_diagnostics/README.md
###############################################################################
# Module

Purpose:
- Define INPUT contract
- Define OUTPUT contract
- List functions
- List tests



###############################################################################
### FILE: modules/03_corporate_actions/R/build_registry.R
###############################################################################
# v2/modules/03_corporate_actions/R/build_registry.R
source("v2/modules/03_corporate_actions/R/fetch_events_yahoo_chart.R")

af2_ca_cache_file <- function(cfg, tag = "splits_dividends") {
  cache_dir <- file.path(cfg$cache_dir, "corp_actions")
  if (!dir.exists(cache_dir)) dir.create(cache_dir, recursive = TRUE)
  file.path(cache_dir, paste0("corp_actions_", tag, ".rds"))
}

# Per-symbol cache directory
af2_ca_cache_dir_by_symbol <- function(cfg) {
  d <- file.path(cfg$cache_dir, "corp_actions", "by_symbol")
  if (!dir.exists(d)) dir.create(d, recursive = TRUE)
  d
}

af2_ca_cache_file_symbol <- function(cfg, symbol) {
  symbol <- toupper(trimws(as.character(symbol)))
  file.path(af2_ca_cache_dir_by_symbol(cfg), paste0(symbol, ".rds"))
}

af2_ca_build_registry <- function(symbols,
                                  asset_types = NULL,
                                  cfg = NULL,
                                  from = "2018-01-01",
                                  to = Sys.Date(),
                                  verbose = TRUE,
                                  use_cache = TRUE,
                                  force_refresh = FALSE,
                                  n_workers = 1L,
                                  # UPDATED: Added "none" to allowed args
                                  cache_mode = c("batch", "by_symbol", "none")) {

  cfg <- cfg %||% af2_get_config()
  symbols <- as.character(symbols)
  symbols <- toupper(trimws(symbols))
  symbols <- symbols[!is.na(symbols) & nzchar(symbols)]
  symbols <- sort(unique(symbols))

  # UPDATED: Handle argument matching
  cache_mode <- match.arg(cache_mode)

  # Implement "none": bypass read/write caching entirely
  if (cache_mode == "none") {
    use_cache <- FALSE
    force_refresh <- TRUE
  }

  if (cache_mode == "by_symbol") {
    if (!exists("af2_ca_build_registry_by_symbol")) {
      stop("by_symbol cache_mode requested but af2_ca_build_registry_by_symbol is not defined.",
           call. = FALSE)
    }
    return(
      af2_ca_build_registry_by_symbol(
        symbols = symbols,
        asset_types = asset_types,
        cfg = cfg,
        from = from,
        to = to,
        verbose = verbose,
        use_cache = use_cache,
        force_refresh = force_refresh
      )
    )
  }

  if (!length(symbols)) stop("af2_ca_build_registry: empty symbols.", call. = FALSE)

  af2_ca_require("digest")

  from <- as.Date(from)
  to   <- as.Date(to)

  # Bucket 'to' by week to avoid daily refetch storms in dev
  to_tag   <- as.Date(cut(to, breaks = "week"))
  from_tag <- from

  # symbols is already sorted+unique above
  sym_hash <- digest::digest(symbols, algo = "xxhash64")

  tag <- paste0(
    format(from_tag, "%Y%m%d"), "_",
    format(to_tag, "%Y%m%d"), "_",
    length(symbols), "_",
    sym_hash
  )

  cache_file <- af2_ca_cache_file(cfg, tag)

  if (isTRUE(use_cache) && file.exists(cache_file) && !isTRUE(force_refresh)) {
    if (verbose) af2_log("AF2_CA:", "Using cache: ", cache_file)
    return(readRDS(cache_file))
  }

  yahoo_syms <- af2_yahoo_symbol_vec(symbols, asset_types)
  map_dt <- data.table::data.table(
    symbol = symbols,
    yahoo_symbol = yahoo_syms
  )
  map_dt <- map_dt[!is.na(yahoo_symbol)]

  if (!nrow(map_dt)) {
    stop("af2_ca_build_registry: no Yahoo symbols could be mapped.", call. = FALSE)
  }

  if (verbose) {
    af2_log("AF2_CA:", "Fetching corporate actions for ", nrow(map_dt), " symbols (Yahoo).")
  }

  worker_fun <- function(i) {
    sym <- map_dt$symbol[i]
    ysym <- map_dt$yahoo_symbol[i]

    mode <- tolower(cfg$ca_fetch_mode %||% "chart")

    # IMPORTANT: match by_symbol behavior
    # If chart deps are not available, fall back to quantmod instead of returning empty.
    if (mode == "chart" &&
        (!requireNamespace("jsonlite", quietly = TRUE) ||
         !requireNamespace("curl", quietly = TRUE))) {
      mode <- "quantmod"
    }

    out <- NULL
    if (mode == "chart") {
      out <- af2_ca_fetch_events_yahoo_chart_one(ysym, from = from, to = to, verbose = FALSE)
    } else {
      # fallback legacy (2 calls)
      dt_s <- af2_ca_fetch_splits_one(ysym, from = from, to = to, verbose = FALSE)
      # UPDATED: split.adjust = TRUE
      dt_d <- af2_ca_fetch_dividends_one(ysym, from = from, to = to, verbose = FALSE, split.adjust = TRUE)
      out <- data.table::rbindlist(list(dt_s, dt_d), use.names = TRUE, fill = TRUE)
      if (!nrow(out)) out <- NULL
    }

    if (is.null(out) || !nrow(out)) return(NULL)

    out[, symbol := sym]
    out[, yahoo_symbol := ysym]
    out
  }

  res_list <- list()

  n_workers <- as.integer(n_workers)
  if (is.na(n_workers) || n_workers < 1L) n_workers <- 1L

  # Windows-safe optional parallel
  if (n_workers > 1L) {
    af2_ca_require("parallel")

    cl <- parallel::makeCluster(n_workers)
    on.exit(try(parallel::stopCluster(cl), silent = TRUE), add = TRUE)

    parallel::clusterExport(
      cl,
      varlist = c(
        "cfg",  # <--- ADDED THIS
        "map_dt",
        "from", "to",
        "af2_ca_fetch_splits_one",
        "af2_ca_fetch_dividends_one",
        "af2_ca_fetch_events_yahoo_chart_one", # <--- ADD THIS
        "af2_ca_with_retry",
        "af2_ca_is_rate_limit_error",
        "af2_ca_require", # <--- ADD THIS (needed inside the new function)
        "af2_log"
      ),
      envir = environment()
    )
    parallel::clusterEvalQ(cl, {
      library(data.table)
      library(quantmod)
      library(xts)
      library(zoo)
      # Add these for the new chart fetcher:
      if (requireNamespace("jsonlite", quietly=TRUE)) library(jsonlite) 
      if (requireNamespace("curl", quietly=TRUE)) library(curl)
    })

    idx <- seq_len(nrow(map_dt))
    res_list <- parallel::parLapply(cl, idx, worker_fun)

  } else {
    for (i in seq_len(nrow(map_dt))) {
      res_list[[i]] <- worker_fun(i)
      if (verbose && i %% 50 == 0) {
        af2_log("AF2_CA:", "Progress: ", i, "/", nrow(map_dt))
      }
    }
  }

  dt_all <- data.table::rbindlist(res_list, use.names = TRUE, fill = TRUE)

  if (!nrow(dt_all)) {
    # It is valid to have zero actions, but keep schema stable
    dt_all <- data.table::data.table(
      symbol = character(),
      yahoo_symbol = character(),
      refdate = as.Date(character()),
      action_type = character(),
      value = numeric(),
      source = character()
    )
  }

  # Normalize + order
  dt_all[, refdate := as.Date(refdate)]
  dt_all <- dt_all[order(symbol, action_type, refdate)]

  # Basic contract sanity
  req <- c("symbol", "yahoo_symbol", "refdate", "action_type", "value", "source")
  miss <- setdiff(req, names(dt_all))
  if (length(miss)) stop("Corporate actions registry missing cols: ", paste(miss, collapse = ", "))

  if (isTRUE(use_cache)) {
    saveRDS(dt_all, cache_file)
    if (verbose) af2_log("AF2_CA:", "Wrote cache: ", cache_file)
  }

  dt_all
}

af2_ca_build_registry_by_symbol <- function(symbols,
                                            asset_types = NULL,
                                            cfg = NULL,
                                            from = "2018-01-01",
                                            to = Sys.Date(),
                                            verbose = TRUE,
                                            use_cache = TRUE,
                                            force_refresh = FALSE) {

  cfg <- cfg %||% af2_get_config()

  symbols <- as.character(symbols)
  symbols <- toupper(trimws(symbols))
  symbols <- symbols[!is.na(symbols) & nzchar(symbols)]
  symbols <- sort(unique(symbols))

  if (!length(symbols)) {
    stop("af2_ca_build_registry_by_symbol: empty symbols.", call. = FALSE)
  }

  from <- as.Date(from)
  to   <- as.Date(to)

  yahoo_syms <- af2_yahoo_symbol_vec(symbols, asset_types)
  map_dt <- data.table::data.table(
    symbol = symbols,
    yahoo_symbol = yahoo_syms
  )
  map_dt <- map_dt[!is.na(yahoo_symbol)]

  if (!nrow(map_dt)) {
    stop("af2_ca_build_registry_by_symbol: no Yahoo symbols could be mapped.", call. = FALSE)
  }

  if (verbose) {
    af2_log("AF2_CA:", "by_symbol mode: candidates=", nrow(map_dt))
  }

  res_list <- vector("list", nrow(map_dt))

  for (i in seq_len(nrow(map_dt))) {

    sym  <- map_dt$symbol[i]
    ysym <- map_dt$yahoo_symbol[i]

    cache_file <- af2_ca_cache_file_symbol(cfg, sym)

    if (isTRUE(use_cache) && file.exists(cache_file) && !isTRUE(force_refresh)) {
      dt_cached <- readRDS(cache_file)
      dt_cached <- data.table::as.data.table(dt_cached)
      if (nrow(dt_cached)) {
        dt_cached[, refdate := as.Date(refdate)]
        dt_cached <- dt_cached[refdate >= from & refdate <= to]
      }
      res_list[[i]] <- dt_cached
      next
    }

    # --- LOGIC UPDATE START ---
    mode <- tolower(cfg$ca_fetch_mode %||% "chart")

    # Fallback if chart deps missing
    if (mode == "chart" &&
        (!requireNamespace("jsonlite", quietly = TRUE) ||
         !requireNamespace("curl", quietly = TRUE))) {
      if (verbose) af2_log("AF2_CA:", "chart mode requested but jsonlite/curl missing; falling back to quantmod for ", sym)
      mode <- "quantmod"
    }

    out <- NULL
    if (mode == "chart") {
      out <- af2_ca_fetch_events_yahoo_chart_one(ysym, from = from, to = to, verbose = FALSE)
    } else {
      # Legacy quantmod calls
      dt_s <- af2_ca_fetch_splits_one(ysym, from = from, to = to, verbose = FALSE)
      # UPDATED: split.adjust = TRUE
      dt_d <- af2_ca_fetch_dividends_one(ysym, from = from, to = to, verbose = FALSE, split.adjust = TRUE)
      out <- data.table::rbindlist(list(dt_s, dt_d), use.names = TRUE, fill = TRUE)
      if (!nrow(out)) out <- NULL
    }
    # --- LOGIC UPDATE END ---

    if (is.null(out) || !nrow(out)) {
      out <- data.table::data.table(
        symbol = character(),
        yahoo_symbol = character(),
        refdate = as.Date(character()),
        action_type = character(),
        value = numeric(),
        source = character()
      )[0]
    } else {
      out[, symbol := sym]
      out[, yahoo_symbol := ysym]
    }

    if (isTRUE(use_cache)) {
      # Save even empty to avoid refetch storms
      saveRDS(out, cache_file)
    }

    res_list[[i]] <- out

    if (verbose && i %% 50 == 0) {
      af2_log("AF2_CA:", "by_symbol progress: ", i, "/", nrow(map_dt))
    }
  }

  dt_all <- data.table::rbindlist(res_list, use.names = TRUE, fill = TRUE)

  if (!nrow(dt_all)) {
    dt_all <- data.table::data.table(
      symbol = character(),
      yahoo_symbol = character(),
      refdate = as.Date(character()),
      action_type = character(),
      value = numeric(),
      source = character()
    )
  }

  dt_all[, refdate := as.Date(refdate)]
  dt_all <- dt_all[order(symbol, action_type, refdate)]

  req <- c("symbol", "yahoo_symbol", "refdate", "action_type", "value", "source")
  miss <- setdiff(req, names(dt_all))
  if (length(miss)) stop("Corporate actions registry missing cols: ", paste(miss, collapse = ", "))

  dt_all
}



###############################################################################
### FILE: modules/03_corporate_actions/R/fetch_dividends_quantmod.R
###############################################################################
# v2/modules/03_corporate_actions/R/fetch_dividends_quantmod.R
source("v2/modules/03_corporate_actions/R/yahoo_retry.R")

af2_ca_fetch_dividends_one <- function(yahoo_symbol,
                                       from = "2018-01-01",
                                       to = Sys.Date(),
                                       verbose = FALSE,
                                       split.adjust = TRUE) {
  if (is.na(yahoo_symbol) || !nzchar(yahoo_symbol)) return(NULL)

  div_fun <- quantmod::getDividends
  fml <- names(formals(div_fun))

  call_args <- list(
    Symbols = yahoo_symbol,
    from = from,
    to = to,
    auto.assign = FALSE,
    verbose = verbose
  )

  if ("split.adjust" %in% fml) {
    call_args$split.adjust <- split.adjust
  }

  x <- af2_ca_with_retry(
    function() do.call(div_fun, call_args),
    max_tries = 4L,
    base_sleep = 1.5,
    verbose = verbose
  )

  if (is.null(x)) return(NULL)
  if (!inherits(x, "xts")) return(NULL)
  if (NROW(x) == 0) return(NULL)

  dt <- data.table::data.table(
    yahoo_symbol = yahoo_symbol,
    refdate = as.Date(zoo::index(x)),
    action_type = "dividend",
    value = as.numeric(zoo::coredata(x)),
    source = "yahoo"
  )

  dt[is.finite(value) & value != 0 & !is.na(refdate)]
}


###############################################################################
### FILE: modules/03_corporate_actions/R/fetch_events_yahoo_chart.R
###############################################################################
# v2/modules/03_corporate_actions/R/fetch_events_yahoo_chart.R
source("v2/modules/03_corporate_actions/R/yahoo_retry.R")

af2_ca_fetch_events_yahoo_chart_one <- function(yahoo_symbol,
                                               from = "2018-01-01",
                                               to = Sys.Date(),
                                               verbose = FALSE) {
  # Default empty table structure
  empty_dt <- data.table::data.table(
      yahoo_symbol = character(),
      refdate = as.Date(character()),
      action_type = character(),
      value = numeric(),
      source = character()
  )

  if (is.na(yahoo_symbol) || !nzchar(yahoo_symbol)) return(empty_dt)

  # Check dependencies (Crucial for parallel workers)
  if (!requireNamespace("jsonlite", quietly = TRUE) || 
      !requireNamespace("curl", quietly = TRUE)) {
      if(verbose) message("AF2_CA_ERR: jsonlite or curl missing on worker for ", yahoo_symbol)
      return(empty_dt)
  }

  af2_ca_require(c("data.table", "jsonlite", "curl"))

  from <- as.Date(from)
  to   <- as.Date(to)
  p1 <- as.integer(as.POSIXct(from, tz = "UTC"))
  p2 <- as.integer(as.POSIXct(to + 1, tz = "UTC"))

  # Corrected URL (Plural splits)
  url <- sprintf(
    "https://query1.finance.yahoo.com/v8/finance/chart/%s?period1=%d&period2=%d&interval=1d&events=div%%7Csplits",
    utils::URLencode(yahoo_symbol, reserved = TRUE),
    p1, p2
  )

  h <- curl::new_handle()
  curl::handle_setheaders(h, "User-Agent" = "Mozilla/5.0", "Accept" = "application/json")

  fetch_once <- function() {
    resp <- curl::curl_fetch_memory(url, handle = h)
    status <- resp$status_code
    txt <- rawToChar(resp$content)
    
    if (status == 429) stop("HTTP 429", call. = FALSE)
    if (status == 404) return(NULL) # Symbol not found
    if (status >= 400) stop(paste0("HTTP ", status), call. = FALSE)
    
    # Safely parse JSON
    tryCatch(jsonlite::fromJSON(txt, simplifyVector = FALSE), error=function(e) NULL)
  }

  js <- af2_ca_with_retry(fetch_once, max_tries = 4L, verbose = verbose)
  
  # Handle failures gracefully
  if (is.null(js)) {
      if(verbose) message("AF2_CA_WARN: No JSON returned for ", yahoo_symbol)
      return(empty_dt)
  }

  res <- js$chart$result[[1]]
  if (is.null(res)) return(empty_dt)
  ev <- res$events
  if (is.null(ev)) return(empty_dt)

  out_list <- list()

  # Process Dividends
  if (!is.null(ev$dividends)) {
    out_list[["dividend"]] <- data.table::rbindlist(lapply(ev$dividends, function(d) {
      if (is.null(d$date) || is.null(d$amount)) return(NULL)
      data.table::data.table(
        yahoo_symbol = yahoo_symbol,
        refdate = as.Date(as.POSIXct(as.integer(d$date), origin = "1970-01-01", tz = "UTC")),
        action_type = "dividend",
        value = as.numeric(d$amount),
        source = "yahoo"
      )
    }), fill=TRUE)
  }

  # Process Splits
  if (!is.null(ev$splits)) {
    out_list[["split"]] <- data.table::rbindlist(lapply(ev$splits, function(s) {
      if (is.null(s$date) || is.null(s$numerator) || is.null(s$denominator)) return(NULL)
      pf <- as.numeric(s$denominator) / as.numeric(s$numerator)
      data.table::data.table(
        yahoo_symbol = yahoo_symbol,
        refdate = as.Date(as.POSIXct(as.integer(s$date), origin = "1970-01-01", tz = "UTC")),
        action_type = "split",
        value = pf,
        source = "yahoo"
      )
    }), fill=TRUE)
  }

  out <- data.table::rbindlist(out_list, fill = TRUE)
  
  if (nrow(out) > 0) {
      out <- out[is.finite(value) & !is.na(refdate)]
      # REMOVED: The erroneous 100x scaling fix. 
      # BRIM11 and others need the raw value.
      return(out)
  }
  
  return(empty_dt)
}


###############################################################################
### FILE: modules/03_corporate_actions/R/fetch_splits_quantmod.R
###############################################################################
# v2/modules/03_corporate_actions/R/fetch_splits_quantmod.R
source("v2/modules/03_corporate_actions/R/yahoo_retry.R")

af2_ca_fetch_splits_one <- function(yahoo_symbol,
                                    from = "2018-01-01",
                                    to = Sys.Date(),
                                    verbose = FALSE) {
  if (is.na(yahoo_symbol) || !nzchar(yahoo_symbol)) return(NULL)

  x <- af2_ca_with_retry(
    function() {
      quantmod::getSplits(
        yahoo_symbol,
        from = from,
        to = to,
        auto.assign = FALSE,
        verbose = verbose
      )
    },
    max_tries = 4L,
    base_sleep = 1.5,
    verbose = verbose
  )

  # quantmod returns NA if no split data
  if (is.null(x)) return(NULL)
  if (!inherits(x, "xts")) return(NULL)
  if (NROW(x) == 0) return(NULL)
  if (length(x) == 1 && is.na(as.numeric(x))) return(NULL)

  # xts index = date, coredata = ratio
  dt <- data.table::data.table(
    yahoo_symbol = yahoo_symbol,
    refdate = as.Date(zoo::index(x)),
    action_type = "split",
    value = as.numeric(zoo::coredata(x)),
    source = "yahoo"
  )

  dt[is.finite(value) & !is.na(refdate)]
}


###############################################################################
### FILE: modules/03_corporate_actions/R/select_candidates.R
###############################################################################
# v2/modules/03_corporate_actions/R/select_candidates.R

af2_ca_select_candidates <- function(universe_raw, cfg = NULL, verbose = TRUE) {

  af2_require(c("data.table"))
  cfg <- cfg %||% af2_get_config()

  dt <- data.table::as.data.table(universe_raw)

  # Allow either turnover or vol_fin
  if (!"turnover" %in% names(dt) && "vol_fin" %in% names(dt)) {
    dt[, turnover := vol_fin]
  }

  af2_assert_cols(
    dt,
    c("symbol", "refdate", "close", "turnover", "asset_type"),
    name = "universe_raw(prefilter)"
  )

  dt[, symbol := toupper(trimws(as.character(symbol)))]
  dt[, asset_type := tolower(trimws(as.character(asset_type)))]
  dt[, refdate := as.Date(refdate)]
  dt[, close := as.numeric(close)]
  dt[, turnover := as.numeric(turnover)]
  
  # -------------------------------
  # 1) Define Windows
  # -------------------------------
  end_date <- max(dt$refdate, na.rm = TRUE)
  
  # Liquidity Window (Keep short to capture current active set)
  liq_window_days <- as.integer(cfg$ca_prefilter_liq_window_days %||% 63L)
  if (!is.finite(liq_window_days) || liq_window_days < 20L) liq_window_days <- 63L
  
  liq_start <- end_date - ceiling(liq_window_days * 1.6)
  
  # -------------------------------
  # 2) Set A: Dividend Candidates (The "Broad" Set)
  # -------------------------------
  # Rule: If it is liquid enough to be in the screener, we MUST fetch its dividends.
  # We do not use gaps to detect dividends.
  
  dt_liq <- dt[refdate >= liq_start & refdate <= end_date]
  dt_liq[, traded_flag := is.finite(close) & !is.na(close)]
  
  stats_liq <- dt_liq[, .(
    median_turnover = stats::median(turnover, na.rm = TRUE),
    days_traded_ratio = mean(traded_flag, na.rm = TRUE)
  ), by = .(symbol, asset_type)]
  
  stats_liq[is.na(median_turnover), median_turnover := 0]
  stats_liq[is.na(days_traded_ratio), days_traded_ratio := 0]
  
  # Filter based on config thresholds
  set_dividends <- stats_liq[
    median_turnover >= (cfg$min_turnover %||% 5e5) &
    days_traded_ratio >= (cfg$min_days_traded_ratio %||% 0.8)
  ]$symbol
  
  if (verbose) {
    af2_log("AF2_CA_PREF:", "Set A (Broad Dividend/Liquidity) count= ", length(set_dividends))
  }

  # -------------------------------
  # 3) Set B: Split Candidates (The "Gap" Set)
  # -------------------------------
  # Rule: Detect discontinuities over the FULL available history (not just recent).
  # This fixes the AURA33 issue where the split was outside the 252-day window.
  
  # We use the full 'dt' here, not a subset.
  data.table::setorder(dt, symbol, refdate)
  dt[, close_lag := data.table::shift(close, 1L), by = symbol]
  
  # Symmetric log return
  dt[, log_ret := data.table::fifelse(
    is.finite(close) & is.finite(close_lag) & close_lag > 0 & close > 0,
    log(close / close_lag),
    NA_real_
  )]
  
  # Thresholds
  gap_thr_log <- as.numeric(cfg$ca_prefilter_jump_log_thr %||% 1.0) # ~2.7x jump
  
  # Type-specific negative drops (Reverse Logic: these catch normal splits)
  thr_map <- data.table::data.table(
    asset_type = c("equity", "fii", "etf", "bdr"),
    thr = c(
      cfg$ca_prefilter_gap_equity %||% -0.20,
      cfg$ca_prefilter_gap_fii    %||% -0.12,
      cfg$ca_prefilter_gap_etf    %||% -0.15,
      cfg$ca_prefilter_gap_bdr    %||% -0.20
    )
  )
  
  # Join thresholds to full data
  # Note: This is memory intensive on full history. 
  # Optimization: Only check rows where abs(log_ret) > 0.10 first to save merge cost?
  # For now, simplistic merge is fine for < 1M rows.
  dt <- merge(dt, thr_map, by = "asset_type", all.x = TRUE)
  
  # Flag B1: Huge Jumps (Reverse Splits)
  jump_pos_syms <- dt[is.finite(log_ret) & log_ret >= gap_thr_log, unique(symbol)]
  
  # Flag B2: Deep Drops (Forward Splits) - using simple ret approx for config compatibility
  dt[, ret_1d := (close/close_lag) - 1]
  gap_neg_syms <- dt[is.finite(ret_1d) & is.finite(thr) & ret_1d <= thr, unique(symbol)]
  
  set_splits <- unique(c(jump_pos_syms, gap_neg_syms))

  if (verbose) {
    af2_log("AF2_CA_PREF:", "Set B (Gap/Split Suspects) count= ", length(set_splits))
  }

  # -------------------------------
  # 4) Union and Return
  # -------------------------------
  cand_final <- unique(c(set_dividends, set_splits))
  
  # Clean up NAs
  cand_final <- cand_final[!is.na(cand_final) & nzchar(cand_final)]
  
  if (verbose) {
    af2_log("AF2_CA_PREF:", "Candidates Final (Union) = ", length(cand_final))
  }
  
  cand_final
}


###############################################################################
### FILE: modules/03_corporate_actions/R/yahoo_retry.R
###############################################################################
# v2/modules/03_corporate_actions/R/yahoo_retry.R

af2_ca_is_rate_limit_error <- function(msg) {
  if (is.null(msg) || !nzchar(msg)) return(FALSE)
  grepl("429|Too Many Requests|rate limit", msg, ignore.case = TRUE)
}

af2_ca_with_retry <- function(fun,
                              max_tries = 4L,
                              base_sleep = 1.5,
                              jitter = 0.2,
                              verbose = FALSE) {

  max_tries <- as.integer(max_tries)
  if (is.na(max_tries) || max_tries < 1L) max_tries <- 1L

  for (k in seq_len(max_tries)) {
    out <- tryCatch(fun(), error = function(e) e)

    if (!inherits(out, "error")) return(out)

    msg <- conditionMessage(out)

    # Only backoff if it looks like rate limiting
    if (!af2_ca_is_rate_limit_error(msg)) {
      if (verbose) af2_log("AF2_CA:", "Non-429 error: ", msg)
      return(NULL)
    }

    # Backoff
    if (k < max_tries) {
      sleep_s <- base_sleep * (2^(k - 1))
      sleep_s <- sleep_s * runif(1, 1 - jitter, 1 + jitter)
      if (verbose) {
        af2_log("AF2_CA:", "429 detected. Retry ", k, "/", max_tries,
                " sleeping ~", round(sleep_s, 2), "s")
      }
      Sys.sleep(sleep_s)
    } else {
      if (verbose) af2_log("AF2_CA:", "429 persisted after retries.")
    }
  }

  NULL
}



###############################################################################
### FILE: modules/03_corporate_actions/R/yahoo_symbol_map.R
###############################################################################
# v2/modules/03_corporate_actions/R/yahoo_symbol_map.R

af2_yahoo_symbol <- function(symbol, asset_type = NULL) {
  s <- toupper(trimws(as.character(symbol)))
  if (is.na(s) || !nzchar(s)) return(NA_character_)

  # If user already passed a Yahoo-style symbol, respect it
  if (grepl("\\.", s)) return(s)

  # Most B3 assets on Yahoo use .SA
  # This covers equities, FIIs, ETFs, many BDRs.
  paste0(s, ".SA")
}

af2_yahoo_symbol_vec <- function(symbols, asset_types = NULL) {
  if (is.null(asset_types)) {
    vapply(symbols, af2_yahoo_symbol, character(1))
  } else {
    mapply(af2_yahoo_symbol, symbols, asset_types, USE.NAMES = FALSE)
  }
}


###############################################################################
### FILE: modules/03_corporate_actions/R/zzz_depends.R
###############################################################################
# v2/modules/03_corporate_actions/R/zzz_depends.R

if (!exists("af2_get_config")) {
  stop("af2_get_config not found. Source v2/modules/00_core/R/config.R first.")
}
if (!exists("af2_log")) {
  stop("af2_log not found. Source v2/modules/00_core/R/logging.R first.")
}
if (!exists("%||%")) {
  stop("%||% not found. Source v2/modules/00_core/R/utils.R first.")
}

af2_ca_require <- function(pkgs) {
  for (p in pkgs) {
    if (!requireNamespace(p, quietly = TRUE)) {
      stop("Missing package for corporate actions module: ", p, call. = FALSE)
    }
  }
  invisible(TRUE)
}

# quantmod is the key dependency here
af2_ca_require(c("data.table", "quantmod", "xts"))

suppressPackageStartupMessages({
  library(data.table)
  library(quantmod)
  library(xts)
})



###############################################################################
### FILE: modules/03_corporate_actions/README.md
###############################################################################
# Module

Purpose:
- Define INPUT contract
- Define OUTPUT contract
- List functions
- List tests



###############################################################################
### FILE: modules/03_corporate_actions/codebase_dump_03_corporate_actions.txt
###############################################################################
Project structure for '/c/Users/Galaxy/LEVI/Projetos R/autofinance_R/v2/modules/03_corporate_actions':
===============================================================================
  R/build_registry.R
  R/fetch_dividends_quantmod.R
  R/fetch_splits_quantmod.R
  R/yahoo_symbol_map.R
  R/zzz_depends.R
  README.md



###############################################################################
### FILE: R/build_registry.R
###############################################################################
# v2/modules/03_corporate_actions/R/build_registry.R

af2_ca_cache_file <- function(cfg, tag = "splits_dividends") {
  cache_dir <- file.path(cfg$cache_dir, "corp_actions")
  if (!dir.exists(cache_dir)) dir.create(cache_dir, recursive = TRUE)
  file.path(cache_dir, paste0("corp_actions_", tag, ".rds"))
}

af2_ca_build_registry <- function(symbols,
                                  asset_types = NULL,
                                  cfg = NULL,
                                  from = "2018-01-01",
                                  to = Sys.Date(),
                                  verbose = TRUE,
                                  use_cache = TRUE,
                                  force_refresh = FALSE,
                                  n_workers = 1L) {

  cfg <- cfg %||% af2_get_config()
  symbols <- unique(toupper(trimws(as.character(symbols))))
  symbols <- symbols[!is.na(symbols) & nzchar(symbols)]
  if (!length(symbols)) stop("af2_ca_build_registry: empty symbols.", call. = FALSE)

  tag <- paste0(
    format(as.Date(from), "%Y%m%d"), "_",
    format(as.Date(to), "%Y%m%d"), "_",
    length(symbols)
  )
  cache_file <- af2_ca_cache_file(cfg, tag)

  if (isTRUE(use_cache) && file.exists(cache_file) && !isTRUE(force_refresh)) {
    if (verbose) af2_log("AF2_CA:", "Using cache: ", cache_file)
    return(readRDS(cache_file))
  }

  yahoo_syms <- af2_yahoo_symbol_vec(symbols, asset_types)
  map_dt <- data.table::data.table(
    symbol = symbols,
    yahoo_symbol = yahoo_syms
  )
  map_dt <- map_dt[!is.na(yahoo_symbol)]

  if (!nrow(map_dt)) {
    stop("af2_ca_build_registry: no Yahoo symbols could be mapped.", call. = FALSE)
  }

  if (verbose) {
    af2_log("AF2_CA:", "Fetching corporate actions for ", nrow(map_dt), " symbols (Yahoo).")
  }

  worker_fun <- function(i) {
    sym <- map_dt$symbol[i]
    ysym <- map_dt$yahoo_symbol[i]

    dt_s <- af2_ca_fetch_splits_one(ysym, from = from, to = to, verbose = FALSE)
    dt_d <- af2_ca_fetch_dividends_one(ysym, from = from, to = to, verbose = FALSE)

    out <- data.table::rbindlist(list(dt_s, dt_d), use.names = TRUE, fill = TRUE)
    if (!nrow(out)) return(NULL)

    out[, symbol := sym]
    out[, yahoo_symbol := ysym]

    out
  }

  res_list <- list()

  n_workers <- as.integer(n_workers)
  if (is.na(n_workers) || n_workers < 1L) n_workers <- 1L

  # Windows-safe optional parallel
  if (n_workers > 1L) {
    af2_ca_require("parallel")

    cl <- parallel::makeCluster(n_workers)
    on.exit(try(parallel::stopCluster(cl), silent = TRUE), add = TRUE)

    parallel::clusterExport(
      cl,
      varlist = c(
        "map_dt",
        "from", "to",
        "af2_ca_fetch_splits_one",
        "af2_ca_fetch_dividends_one"
      ),
      envir = environment()
    )
    parallel::clusterEvalQ(cl, {
      library(data.table)
      library(quantmod)
      library(xts)
      library(zoo)
    })

    idx <- seq_len(nrow(map_dt))
    res_list <- parallel::parLapply(cl, idx, worker_fun)

  } else {
    for (i in seq_len(nrow(map_dt))) {
      res_list[[i]] <- worker_fun(i)
      if (verbose && i %% 50 == 0) {
        af2_log("AF2_CA:", "Progress: ", i, "/", nrow(map_dt))
      }
    }
  }

  dt_all <- data.table::rbindlist(res_list, use.names = TRUE, fill = TRUE)

  if (!nrow(dt_all)) {
    # It is valid to have zero actions, but keep schema stable
    dt_all <- data.table::data.table(
      symbol = character(),
      yahoo_symbol = character(),
      refdate = as.Date(character()),
      action_type = character(),
      value = numeric(),
      source = character()
    )
  }

  # Normalize + order
  dt_all[, refdate := as.Date(refdate)]
  dt_all <- dt_all[order(symbol, action_type, refdate)]

  # Basic contract sanity
  req <- c("symbol", "yahoo_symbol", "refdate", "action_type", "value", "source")
  miss <- setdiff(req, names(dt_all))
  if (length(miss)) stop("Corporate actions registry missing cols: ", paste(miss, collapse = ", "))

  if (isTRUE(use_cache)) {
    saveRDS(dt_all, cache_file)
    if (verbose) af2_log("AF2_CA:", "Wrote cache: ", cache_file)
  }

  dt_all
}



###############################################################################
### FILE: R/fetch_dividends_quantmod.R
###############################################################################
# v2/modules/03_corporate_actions/R/fetch_dividends_quantmod.R

af2_ca_fetch_dividends_one <- function(yahoo_symbol,
                                       from = "2018-01-01",
                                       to = Sys.Date(),
                                       verbose = FALSE,
                                       split.adjust = TRUE) {
  if (is.na(yahoo_symbol) || !nzchar(yahoo_symbol)) return(NULL)

  x <- tryCatch(
    quantmod::getDividends(
      yahoo_symbol,
      from = from,
      to = to,
      auto.assign = FALSE,
      verbose = verbose,
      split.adjust = split.adjust
    ),
    error = function(e) {
      if (verbose) af2_log("AF2_CA:", "getDividends failed for ", yahoo_symbol, ": ", conditionMessage(e))
      NULL
    }
  )

  if (is.null(x)) return(NULL)
  if (!inherits(x, "xts")) return(NULL)
  if (NROW(x) == 0) return(NULL)

  dt <- data.table::data.table(
    yahoo_symbol = yahoo_symbol,
    refdate = as.Date(zoo::index(x)),
    action_type = "dividend",
    value = as.numeric(zoo::coredata(x)),
    source = "yahoo"
  )

  dt[is.finite(value) & value != 0 & !is.na(refdate)]
}


###############################################################################
### FILE: R/fetch_splits_quantmod.R
###############################################################################
# v2/modules/03_corporate_actions/R/fetch_splits_quantmod.R

af2_ca_fetch_splits_one <- function(yahoo_symbol,
                                    from = "2018-01-01",
                                    to = Sys.Date(),
                                    verbose = FALSE) {
  if (is.na(yahoo_symbol) || !nzchar(yahoo_symbol)) return(NULL)

  x <- tryCatch(
    quantmod::getSplits(
      yahoo_symbol,
      from = from,
      to = to,
      auto.assign = FALSE,
      verbose = verbose
    ),
    error = function(e) {
      if (verbose) af2_log("AF2_CA:", "getSplits failed for ", yahoo_symbol, ": ", conditionMessage(e))
      NULL
    }
  )

  # quantmod returns NA if no split data
  if (is.null(x)) return(NULL)
  if (length(x) == 1 && is.na(as.numeric(x))) return(NULL)
  if (!inherits(x, "xts")) return(NULL)

  # xts index = date, coredata = ratio
  dt <- data.table::data.table(
    yahoo_symbol = yahoo_symbol,
    refdate = as.Date(zoo::index(x)),
    action_type = "split",
    value = as.numeric(zoo::coredata(x)),
    source = "yahoo"
  )

  dt[is.finite(value) & !is.na(refdate)]
}


###############################################################################
### FILE: R/yahoo_symbol_map.R
###############################################################################
# v2/modules/03_corporate_actions/R/yahoo_symbol_map.R

af2_yahoo_symbol <- function(symbol, asset_type = NULL) {
  s <- toupper(trimws(as.character(symbol)))
  if (is.na(s) || !nzchar(s)) return(NA_character_)

  # If user already passed a Yahoo-style symbol, respect it
  if (grepl("\\.", s)) return(s)

  # Most B3 assets on Yahoo use .SA
  # This covers equities, FIIs, ETFs, many BDRs.
  paste0(s, ".SA")
}

af2_yahoo_symbol_vec <- function(symbols, asset_types = NULL) {
  if (is.null(asset_types)) {
    vapply(symbols, af2_yahoo_symbol, character(1))
  } else {
    mapply(af2_yahoo_symbol, symbols, asset_types, USE.NAMES = FALSE)
  }
}


###############################################################################
### FILE: R/zzz_depends.R
###############################################################################
# v2/modules/03_corporate_actions/R/zzz_depends.R

if (!exists("af2_get_config")) {
  stop("af2_get_config not found. Source v2/modules/00_core/R/config.R first.")
}
if (!exists("af2_log")) {
  stop("af2_log not found. Source v2/modules/00_core/R/logging.R first.")
}
if (!exists("%||%")) {
  stop("%||% not found. Source v2/modules/00_core/R/utils.R first.")
}

af2_ca_require <- function(pkgs) {
  for (p in pkgs) {
    if (!requireNamespace(p, quietly = TRUE)) {
      stop("Missing package for corporate actions module: ", p, call. = FALSE)
    }
  }
  invisible(TRUE)
}

# quantmod is the key dependency here
af2_ca_require(c("data.table", "quantmod", "xts"))

suppressPackageStartupMessages({
  library(data.table)
  library(quantmod)
  library(xts)
})



###############################################################################
### FILE: README.md
###############################################################################
# Module

Purpose:
- Define INPUT contract
- Define OUTPUT contract
- List functions
- List tests






###############################################################################
### FILE: modules/04_adjuster/R/apply_adjustments.R
###############################################################################
# v2/modules/04_adjuster/R/apply_adjustments.R

# Helper: reverse cumulative product excluding same-day event.
# Optimized to handle vector input but respect grouping via by=.
af2_adj_rev_cumprod_exclusive <- function(x) {
  if (!length(x)) return(x)
  # rev(cumprod(rev(x))) matches the logic: factor applies to all PREVIOUS dates
  v <- rev(cumprod(rev(x)))
  # shift lead fill=1 shifts it so factor(t) = product(events > t)
  data.table::shift(v, 1L, type = "lead", fill = 1)
}

# Apply adjustments to full universe_raw (VECTORIZED)
# Returns:
#   list(panel_adj = ..., adjustments = ...)
af2_adj_apply_adjustments <- function(universe_raw,
                                      events,
                                      verbose = TRUE) {

  dt <- data.table::as.data.table(universe_raw)
  ev <- data.table::as.data.table(events)

  # 1) Join events onto market days
  data.table::setkey(dt, symbol, refdate)
  if (nrow(ev) > 0) data.table::setkey(ev, symbol, refdate)

  if (nrow(ev) == 0) {
    dt[, `:=`(split_value = 1, div_cash = 0, source_mask = "none", has_manual = FALSE)]
  } else {
    dt <- merge(dt, ev, by = c("symbol", "refdate"), all.x = TRUE)

    dt[is.na(split_value), split_value := 1]
    dt[is.na(div_cash), div_cash := 0]
    dt[is.na(source_mask), source_mask := "none"]
    dt[is.na(has_manual), has_manual := FALSE]
  }

  data.table::setorder(dt, symbol, refdate)

  # 2) Split cumulative factor (exclusive)
  dt[, split_factor_cum := af2_adj_rev_cumprod_exclusive(split_value), by = symbol]

  # Split-adjusted OHLC
  dt[, `:=`(
    open_adj_split  = open  * split_factor_cum,
    high_adj_split  = high  * split_factor_cum,
    low_adj_split   = low   * split_factor_cum,
    close_adj_split = close * split_factor_cum
  )]

  # 3) Dividend factor (with basis-mismatch rescue)
  dt[, close_prev := data.table::shift(close_adj_split, 1L, type = "lag"), by = symbol]

  dt[, `:=`(
    div_factor_event = 1,
    issue_div = FALSE,
    # NEW (audit): effective dividend used in the formula
    div_cash_eff = div_cash,
    div_scaled = FALSE
  )]

  is_div <- dt$div_cash > 0

  # If dividend looks impossible on split-adjusted basis, try scaling it by split_factor_cum
  # This ONLY helps for forward splits (factor < 1).
  need_scale <- is_div &
    is.finite(dt$close_prev) & dt$close_prev > 0 &
    is.finite(dt$split_factor_cum) & dt$split_factor_cum > 0 & dt$split_factor_cum < 1 &
    is.finite(dt$div_cash) & dt$div_cash >= dt$close_prev

  if (any(need_scale)) {
    idx_need <- which(need_scale)
    scaled <- dt$div_cash[idx_need] * dt$split_factor_cum[idx_need]

    ok_scaled <- is.finite(scaled) & scaled >= 0 & scaled < dt$close_prev[idx_need]
    if (any(ok_scaled)) {
      idx_ok <- idx_need[ok_scaled]
      dt[idx_ok, `:=`(div_cash_eff = scaled[ok_scaled], div_scaled = TRUE)]
    }
  }

  # Bad dividends (after rescue attempt)
  bad_div <- is_div & (
    is.na(dt$close_prev) | dt$close_prev <= 0 |
      is.na(dt$div_cash_eff) | dt$div_cash_eff < 0 |
      dt$div_cash_eff >= dt$close_prev
  )

  if (any(bad_div)) dt[bad_div, issue_div := TRUE]

  good_div <- is_div & !bad_div
  if (any(good_div)) {
    dt[good_div, div_factor_event := (close_prev - div_cash_eff) / close_prev]
  }

  # Dividend cumulative factor (exclusive)
  dt[, div_factor_cum := af2_adj_rev_cumprod_exclusive(div_factor_event), by = symbol]

  # 4) Final factor + final adjusted OHLC
  dt[, adj_factor_final := split_factor_cum * div_factor_cum]

  dt[, `:=`(
    open_adj_final  = open  * adj_factor_final,
    high_adj_final  = high  * adj_factor_final,
    low_adj_final   = low   * adj_factor_final,
    close_adj_final = close * adj_factor_final
  )]

  # 5) Outputs
  adjustments <- dt[, .(
    symbol, refdate,
    split_value, div_cash,
    div_cash_eff, div_scaled,
    split_factor_cum, div_factor_event, div_factor_cum,
    adj_factor_final,
    source_mask, has_manual, issue_div
  )]

  dt[, c("split_value", "div_cash", "source_mask", "has_manual",
         "split_factor_cum", "div_factor_event", "div_factor_cum",
         "adj_factor_final", "close_prev", "issue_div",
         "div_cash_eff", "div_scaled") := NULL]

  list(panel_adj = dt, adjustments = adjustments)
}


###############################################################################
### FILE: modules/04_adjuster/R/build_adjustments.R
###############################################################################
# v2/modules/04_adjuster/R/build_adjustments.R

# Build normalized event table for the adjuster.
# Input corp_actions contract (from Module 03):
#   symbol, yahoo_symbol, refdate, action_type, value, source
#
# Output event table:
#   symbol, refdate, split_value, div_cash, source_mask, has_manual

af2_adj_normalize_corp_actions <- function(corp_actions, cfg = NULL) {
  cfg <- cfg %||% af2_get_config()
  if (is.null(corp_actions)) {
    return(data.table(
      symbol = character(),
      refdate = as.Date(character()),
      action_type = character(),
      value = numeric(),
      source = character()
    ))
  }

  dt <- data.table::as.data.table(corp_actions)

  # Allow either registry schema with yahoo_symbol or not
  if ("yahoo_symbol" %in% names(dt)) dt[, yahoo_symbol := NULL]

  # Basic required
  af2_assert_cols(dt, c("symbol", "refdate", "action_type", "value", "source"),
                  name = "corp_actions")

  dt[, symbol := toupper(trimws(as.character(symbol)))]
  dt[, action_type := tolower(trimws(as.character(action_type)))]
  dt[, refdate := as.Date(refdate)]
  dt[, value := as.numeric(value)]
  dt[, source := tolower(trimws(as.character(source)))]

  dt <- dt[!is.na(symbol) & nzchar(symbol) & !is.na(refdate)]
  dt <- dt[action_type %in% c("split", "dividend")]
  # Yahoo/quantmod getSplits() appears to return
  # PRICE FACTORS already (1/ratio).
  # We keep values as-is and only validate positivity.
  # --------------------------------------------
  # Yahoo/quantmod getSplits() appears to already
  # return PRICE FACTORS (1/ratio).
  # So we do NOT invert here.
  # --------------------------------------------
  # getSplits() may return ratio OR price factor depending on the symbol/market feed.
  # We keep values as-is here.
  # Orientation is validated later by split-gap logic when enabled.

  # Keep only valid positive numeric values.
  dt[action_type == "split" & (!is.finite(value) | value <= 0),
     value := NA_real_]

  dt <- dt[is.na(value) == FALSE]

  dt
}

af2_adj_normalize_manual_events <- function(manual_events, cfg = NULL) {
  cfg <- cfg %||% af2_get_config()
  if (is.null(manual_events)) {
    return(data.table(
      symbol = character(),
      refdate = as.Date(character()),
      action_type = character(),
      value = numeric(),
      source = character()
    ))
  }

  dt <- data.table::as.data.table(manual_events)

  af2_assert_cols(dt, c("symbol", "refdate", "action_type", "value"),
                  name = "manual_events")

  if (!"source" %in% names(dt)) dt[, source := "manual"]

  dt[, symbol := toupper(trimws(as.character(symbol)))]
  dt[, action_type := tolower(trimws(as.character(action_type)))]
  dt[, refdate := as.Date(refdate)]
  dt[, value := as.numeric(value)]
  dt[, source := "manual"]

  dt <- dt[!is.na(symbol) & nzchar(symbol) & !is.na(refdate)]
  dt <- dt[action_type %in% c("split", "dividend")]
  # Manual convention in v2:
  # store split values as PRICE FACTORS
  # consistent with Yahoo (1/ratio).
  dt[action_type == "split" & (!is.finite(value) | value <= 0),
     value := NA_real_]

  dt <- dt[is.na(value) == FALSE]

  dt
}

af2_adj_build_events <- function(corp_actions,
                                 manual_events = NULL,
                                 cfg = NULL,
                                 verbose = TRUE) {

  cfg <- cfg %||% af2_get_config()

  ca <- af2_adj_normalize_corp_actions(corp_actions, cfg = cfg)
  me <- af2_adj_normalize_manual_events(manual_events, cfg = cfg)

  dt_all <- data.table::rbindlist(list(ca, me), use.names = TRUE, fill = TRUE)
  if (!nrow(dt_all)) {
    return(data.table(
      symbol = character(),
      refdate = as.Date(character()),
      split_value = numeric(),
      div_cash = numeric(),
      source_mask = character(),
      has_manual = logical()
    ))
  }

  # ------------------------------------------------------------
  # CRITICAL: remove exact duplicates before split multiplication.
  # Otherwise vendor artifacts can multiply factors (v^2, v^3, ...)
  # ------------------------------------------------------------
  dt_all <- unique(dt_all, by = c("symbol", "refdate", "action_type", "value", "source"))

  # Aggregate same-day events:
  # - splits: multiply price factors
  # - dividends: sum cash amounts
  splits <- dt_all[action_type == "split",
                   .(split_value = prod(value, na.rm = TRUE),
                     source_mask = paste(sort(unique(source)), collapse = "+")),
                   by = .(symbol, refdate)]

  divs <- dt_all[action_type == "dividend",
                 .(div_cash = sum(value, na.rm = TRUE),
                   source_mask_div = paste(sort(unique(source)), collapse = "+")),
                 by = .(symbol, refdate)]

  # Merge into unified event table
  ev <- merge(
    splits, divs,
    by = c("symbol", "refdate"),
    all = TRUE
  )

  ev[is.na(split_value), split_value := 1]
  ev[is.na(div_cash), div_cash := 0]

  # Compose source mask
  ev[, source_mask := data.table::fifelse(
    !is.na(source_mask) & !is.na(source_mask_div),
    paste0(source_mask, "+", source_mask_div),
    data.table::fifelse(!is.na(source_mask), source_mask, source_mask_div)
  )]
  ev[is.na(source_mask), source_mask := "unknown"]

  ev[, c("source_mask_div") := NULL]

  ev[, has_manual := grepl("manual", source_mask)]

  # Clean obvious nonsense
  ev <- ev[!is.na(symbol) & nzchar(symbol) & !is.na(refdate)]
  ev <- ev[is.finite(split_value) & split_value > 0]
  ev <- ev[is.finite(div_cash) & div_cash >= 0]

  if (verbose) {
    af2_log("AF2_ADJ:", "Built events: ", nrow(ev), " rows for ",
            length(unique(ev$symbol)), " symbols.")
  }

  data.table::setorder(ev, symbol, refdate)
  ev
}


###############################################################################
### FILE: modules/04_adjuster/R/build_panel_adj.R
###############################################################################
# v2/modules/04_adjuster/R/build_panel_adj.R

af2_build_panel_adj <- function(universe_raw,
                                corp_actions = NULL,
                                manual_events = NULL,
                                cfg = NULL,
                                verbose = TRUE) {

  cfg <- cfg %||% af2_get_config()

  dt <- data.table::as.data.table(universe_raw)

  # Strict universe column expectations for v2
  af2_assert_cols(
    dt,
    c("symbol", "refdate", "open", "high", "low", "close",
      "turnover", "qty", "asset_type"),
    name = "universe_raw"
  )

  dt[, symbol := toupper(trimws(as.character(symbol)))]
  dt[, refdate := as.Date(refdate)]

  # Defensive dedupe
  data.table::setorder(dt, asset_type, symbol, refdate)
  dup_check <- dt[, .N, by = .(symbol, refdate)][N > 1L]
  if (nrow(dup_check)) {
    af2_log("AF2_ADJ:", "WARNING: universe_raw had duplicated symbol/refdate rows. Keeping first row per key.")
    dt <- dt[, .SD[1L], by = .(symbol, refdate)]
  }
  af2_assert_no_dupes(dt, c("symbol", "refdate"), name = "universe_raw")

  # 1) Build event table
  events <- af2_adj_build_events(
    corp_actions = if (isTRUE(cfg$enable_splits)) corp_actions else NULL,
    manual_events = if (isTRUE(cfg$enable_manual_events)) manual_events else NULL,
    cfg = cfg,
    verbose = verbose
  )

  # 2) Apply adjustments (Vectorized)
  out <- af2_adj_apply_adjustments(
    universe_raw = dt,
    events = events,
    verbose = verbose
  )

  panel <- out$panel_adj
  adj_tl <- out$adjustments

  # 3) Add raw aliases
  panel[, `:=`(
    open_raw = open, high_raw = high, low_raw = low, close_raw = close
  )]

  # 4) Compute adjustment_state per symbol
  
  # Aggregate flags from adjustments timeline
  issue_flags <- adj_tl[, .(
    issue_div_any = any(issue_div %in% TRUE)
  ), by = symbol]

  # Aggregate flags from events
  panel_min <- min(panel$refdate, na.rm = TRUE)
  panel_max <- max(panel$refdate, na.rm = TRUE)
  
  ev_in_window <- events[refdate >= panel_min & refdate <= panel_max]
  
  if (nrow(ev_in_window) > 0) {
    ev_flags <- ev_in_window[, .(
      has_split = any(is.finite(split_value) & split_value != 1),
      has_div   = any(is.finite(div_cash) & div_cash > 0),
      has_manual = any(has_manual %in% TRUE)
    ), by = symbol]
  } else {
    ev_flags <- data.table::data.table(symbol = character(), has_split=logical(), has_div=logical(), has_manual=logical())
  }

  # Merge metadata
  state_dt <- data.table::data.table(symbol = unique(panel$symbol))
  state_dt <- merge(state_dt, ev_flags, by = "symbol", all.x = TRUE)
  state_dt <- merge(state_dt, issue_flags, by = "symbol", all.x = TRUE)
  
  state_dt[is.na(has_split), has_split := FALSE]
  state_dt[is.na(has_div), has_div := FALSE]
  state_dt[is.na(has_manual), has_manual := FALSE]
  state_dt[is.na(issue_div_any), issue_div_any := FALSE]

  # Determine State (Robust Syntax)
  # UPDATED: Default is no longer "ok", but "no_actions"
  state_dt[, adjustment_state := "no_actions"]
  
  # Logic hierarchy
  state_dt[has_div & !has_split, adjustment_state := "dividend_only"]
  state_dt[has_split & !has_div, adjustment_state := "split_only"]
  state_dt[has_split & has_div, adjustment_state := "split_dividend"]
  
  # "ok" is now a computed concept? Or do we stick to specific states?
  # Let's keep specific states. If user wants "ok", they check adjustment_state != "suspect".
  
  state_dt[has_manual == TRUE, adjustment_state := "manual_override"]
  state_dt[issue_div_any == TRUE, adjustment_state := "suspect_unresolved"]

  # ------------------------------------------------------------
  # 4b) Residual jump safety net
  # ------------------------------------------------------------
  jump_tol <- as.numeric(cfg$adj_residual_jump_tol_log %||% 1.0)
  if (!is.finite(jump_tol) || jump_tol <= 0) jump_tol <- 1.0

  jump_audit <- panel[
    is.finite(close_adj_final) & close_adj_final > 0,
    {
      v <- abs(diff(log(close_adj_final)))
      if (!length(v) || all(!is.finite(v))) {
        .(residual_max_abs_logret = 0, residual_jump_date = as.Date(NA))
      } else {
        k <- which.max(v)
        .(
          residual_max_abs_logret = as.numeric(v[k]),
          residual_jump_date = refdate[k + 1L]
        )
      }
    },
    by = symbol
  ]

  jump_audit[, residual_jump_flag := is.finite(residual_max_abs_logret) & residual_max_abs_logret >= jump_tol]

  # Merge jump info and OVERRIDE state if needed
  state_dt <- merge(state_dt, jump_audit, by = "symbol", all.x = TRUE)
  
  # FIX: Explicit boolean comparison
  state_dt[residual_jump_flag == TRUE, adjustment_state := "suspect_unresolved"]

  panel[state_dt, on = "symbol", adjustment_state := i.adjustment_state]

  # 5) Cleanup
  keep_cols <- c(
    "symbol", "refdate", "asset_type",
    "open_raw", "high_raw", "low_raw", "close_raw",
    "open_adj_split", "high_adj_split", "low_adj_split", "close_adj_split",
    "open_adj_final", "high_adj_final", "low_adj_final", "close_adj_final",
    "turnover", "qty", "adjustment_state"
  )
  present_keep <- intersect(keep_cols, names(panel))
  other_cols <- setdiff(names(panel), present_keep)
  data.table::setcolorder(panel, c(present_keep, other_cols))

  if (verbose) {
    af2_log("AF2_ADJ:", "panel_adj rows = ", nrow(panel))
    af2_log("AF2_ADJ:", "symbols = ", length(unique(panel$symbol)))
    af2_log("AF2_ADJ:", "states:")
    print(panel[, .N, by = adjustment_state][order(-N)])
  }

  list(
    panel_adj = panel,
    adjustments = adj_tl,
    events = events,
    residual_jump_audit = jump_audit
  )
}


###############################################################################
### FILE: modules/04_adjuster/R/build_panel_adj_selective.R
###############################################################################
# v2/modules/04_adjuster/R/build_panel_adj_selective.R
# High-level wrapper implementing the selective Yahoo "trick".

# ------------------------------------------------------------
# Split-gap validator + snapper for Yahoo splits
# - snaps split refdate forward to next trading day (<= max_fwd_days)
# - normalizes Yahoo split "value" orientation (ratio vs price-factor)
# - rejects splits that do not match raw jump (within tol_log)
# - returns BOTH: cleaned corp_actions + split_audit table
# ------------------------------------------------------------
af2_ca_fix_yahoo_splits_by_raw_gap <- function(corp_actions,
                                               universe_raw,
                                               cfg = NULL,
                                               verbose = TRUE,
                                               tol_log = NULL,
                                               max_fwd_days = NULL,
                                               max_back_days = NULL,
                                               use_open = NULL) {

  cfg <- cfg %||% af2_get_config()
  af2_require("data.table")

  tol_log <- as.numeric(tol_log %||% cfg$split_gap_tol_log %||% 0.35)
  if (!is.finite(tol_log) || tol_log <= 0) tol_log <- 0.35

  max_fwd_days <- as.integer(max_fwd_days %||% cfg$split_gap_max_forward_days %||% 5L)
  if (!is.finite(max_fwd_days) || max_fwd_days < 0L) max_fwd_days <- 5L

  max_back_days <- as.integer(max_back_days %||% cfg$split_gap_max_back_days %||% 3L)
  if (!is.finite(max_back_days) || max_back_days < 0L) max_back_days <- 3L

  use_open <- isTRUE(use_open %||% cfg$split_gap_use_open %||% TRUE)

  # 1) Normalize Inputs
  dt <- data.table::as.data.table(universe_raw)
  sp <- data.table::as.data.table(corp_actions)

  dt[, symbol := toupper(trimws(as.character(symbol)))]
  dt[, refdate := as.Date(refdate)]
  dt[, `:=`(open = as.numeric(open), close = as.numeric(close))]

  sp[, symbol := toupper(trimws(as.character(symbol)))]
  sp[, refdate := as.Date(refdate)]
  sp[, action_type := tolower(trimws(as.character(action_type)))]
  sp[, source := tolower(trimws(as.character(source)))]
  sp[, value := as.numeric(value)]
  if (!"yahoo_symbol" %in% names(sp)) sp[, yahoo_symbol := NA_character_]

  # 2) Filter target splits
  sp0 <- data.table::copy(sp) 
  if (!"row_id" %in% names(sp0)) sp0[, row_id := .I] 

  to_validate <- sp0[action_type == "split" & source == "yahoo" & is.finite(value) & value > 0]

  # Empty return structure
  empty_audit <- data.table::data.table(
      row_id=integer(), symbol=character(), yahoo_symbol=character(),
      vendor_refdate=as.Date(character()), eff_refdate=as.Date(character()), 
      lag_days=integer(), yahoo_value=numeric(), chosen_value=numeric(), 
      chosen_err=numeric(), status=character()
  )

  if (!nrow(to_validate)) {
    return(list(
      corp_actions = sp0,
      fixed_kept = sp[0], 
      quarantine = data.table::copy(empty_audit),
      audit = empty_audit
    ))
  }

  # 3) Prepare Universe for Keyed Lookup
  # Enforce unique keys for validation logic
  data.table::setorder(dt, symbol, refdate)
  dt <- dt[, .SD[1L], by = .(symbol, refdate)]
  
  # Set Key for fast lookups
  data.table::setkey(dt, symbol, refdate)
  
  # Compute lag (requires stable ordering, which we just did)
  dt[, close_lag := data.table::shift(close, 1L), by = symbol]

  # 4) Validation Logic
  offs <- seq.int(-max_back_days, max_fwd_days)

  eval_one <- function(sym, vdate, vval) {
    best <- list(err = Inf, eff = as.Date(NA), chosen = NA_real_)
    for (o in offs) {
      d <- vdate + o
      
      row <- dt[.(sym, d), nomatch = 0L]
      if (nrow(row) != 1L) next
      
      cl <- row$close[[1]]
      op <- row$open[[1]]
      lag <- row$close_lag[[1]]
      
      # Need lag and either open or close
      if (!is.finite(lag) || lag <= 0) next
      
      if (use_open && is.finite(op) && op > 0) {
        obs <- op / lag
      } else if (is.finite(cl) && cl > 0) {
        obs <- cl / lag
      } else {
        next
      }

      # observed ratio
      if (use_open && is.finite(row$open) && is.finite(row$close_lag) && row$open > 0 && row$close_lag > 0) {
        obs <- row$open / row$close_lag
      } else if (is.finite(row$close) && is.finite(row$close_lag) && row$close > 0 && row$close_lag > 0) {
        obs <- row$close / row$close_lag
      } else {
        next
      }

      cand_vals <- c(vval, 1 / vval)
      for (cv in cand_vals) {
        if (!is.finite(cv) || cv <= 0) next
        e <- abs(log(obs) - log(cv))
        if (is.finite(e) && e < best$err) {
          best$err <- e
          best$eff <- d
          best$chosen <- cv
        }
      }
    }
    best
  }

  out <- to_validate[, {
    b <- eval_one(symbol, vendor_refdate, value)
    lag_days <- as.integer(b$eff - vendor_refdate)
    status <- if (!is.finite(b$err) || is.infinite(b$err) || is.na(b$eff)) "unverified" else if (b$err <= tol_log) "kept" else "rejected"
    .(
      eff_refdate = as.Date(b$eff),
      chosen_value = as.numeric(b$chosen),
      chosen_err = as.numeric(b$err),
      lag_days = as.integer(ifelse(is.na(lag_days), NA_integer_, lag_days)),
      status = status
    )
  }, by = .(row_id, symbol, yahoo_symbol, vendor_refdate = as.Date(refdate), action_type, value, source)]

  # Dedup: if multiple rows collapse to same (symbol, eff_refdate, chosen_value), keep best err
  data.table::setorder(out, symbol, eff_refdate, chosen_value, chosen_err)
  out[, dup_rank := seq_len(.N), by = .(symbol, eff_refdate, chosen_value)]
  
  if (nrow(out[dup_rank > 1L & status == "kept"])) {
    out[dup_rank > 1L & status == "kept", status := "dup"]
  }
  out[, dup_rank := NULL]

  fixed_kept <- out[status == "kept",
                    .(yahoo_symbol, refdate = eff_refdate, action_type = "split", value = chosen_value, source, symbol)]

  quarantine <- out[status != "kept",
                    .(row_id, symbol, yahoo_symbol, refdate = vendor_refdate, action_type = "split", value, source,
                      status, eff_refdate, chosen_value, chosen_err, lag_days, vendor_refdate)]

  audit <- out[, .(row_id, symbol, yahoo_symbol,
                   vendor_refdate, eff_refdate, lag_days,
                   yahoo_value = value,
                   chosen_value, chosen_err,
                   status)]

  list(
    corp_actions = sp0,
    fixed_kept = fixed_kept,
    quarantine = quarantine,
    audit = audit
  )
}

af2_build_panel_adj_selective <- function(universe_raw,
                                          manual_events = NULL,
                                          cfg = NULL,
                                          from_ca = NULL,
                                          to_ca = NULL,
                                          verbose = TRUE,
                                          use_cache = TRUE,
                                          force_refresh = FALSE,
                                          n_workers = 1L,
                                          force_symbols = NULL) {

  cfg <- cfg %||% af2_get_config()

  dt <- data.table::as.data.table(universe_raw)
  
  # 1) Assert columns FIRST
  af2_assert_cols(
    dt,
    c("symbol", "refdate", "open", "high", "low", "close", "turnover", "qty", "asset_type"),
    name = "universe_raw"
  )

  # 2) Normalize keys & Dedupe (CRITICAL FIX)
  dt[, symbol := toupper(trimws(as.character(symbol)))]
  dt[, asset_type := tolower(trimws(as.character(asset_type)))]
  dt[, refdate := as.Date(refdate)]
  dt[, `:=`(
      open = as.numeric(open),
      high = as.numeric(high),
      low  = as.numeric(low),
      close = as.numeric(close),
      turnover = as.numeric(turnover),
      qty = as.numeric(qty)
  )]

  # Defensive dedupe
  data.table::setorder(dt, asset_type, symbol, refdate)
  dup_check <- dt[, .N, by = .(symbol, refdate)][N > 1L]
  if (nrow(dup_check)) {
    if (verbose) af2_log("AF2_ADJ:", "WARNING: universe_raw had duplicates. Keeping first row per key.")
    dt <- dt[, .SD[1L], by = .(symbol, refdate)]
  }
  af2_assert_no_dupes(dt, c("symbol", "refdate"), name = "universe_raw(selective)")

  # 3) Dynamic Date Defaults
  if (is.null(from_ca) || is.na(from_ca)) {
    from_ca <- min(dt$refdate, na.rm = TRUE) - 10
  }
  if (is.null(to_ca) || is.na(to_ca)) {
    to_ca <- max(dt$refdate, na.rm = TRUE) + 10
  }
  from_ca <- as.Date(from_ca)
  to_ca <- as.Date(to_ca)

  # 4) Decide candidate symbols
  if (isTRUE(cfg$enable_selective_actions)) {
    cand <- af2_ca_select_candidates(universe_raw = dt, cfg = cfg, verbose = verbose)
  } else {
    cand <- sort(unique(toupper(dt$symbol)))
  }

  if (!is.null(force_symbols)) {
    force_symbols <- toupper(trimws(as.character(force_symbols)))
    force_symbols <- force_symbols[!is.na(force_symbols) & nzchar(force_symbols)]
    cand <- sort(unique(c(cand, force_symbols)))
  }

  if (verbose) {
    af2_log("AF2_CA_PREF:", "Selective actions enabled=", isTRUE(cfg$enable_selective_actions))
    af2_log("AF2_CA_PREF:", "Yahoo candidate symbols=", length(cand))
  }

  # 5) Fetch registry
  ca <- NULL
  if (length(cand)) {
    ca <- af2_ca_build_registry(
      symbols = cand,
      asset_types = NULL,
      cfg = cfg,
      from = from_ca,
      to = to_ca,
      verbose = verbose,
      use_cache = use_cache,
      force_refresh = force_refresh,
      n_workers = n_workers,
      cache_mode = cfg$ca_cache_mode %||% "batch"
    )
  }

  # 6) Reconcile/Fix Splits
  split_audit <- data.table::data.table()
  yahoo_splits_fixed <- data.table::data.table()
  yahoo_splits_quarantine <- data.table::data.table()

  if (!is.null(ca) && nrow(ca) && isTRUE(cfg$enable_split_gap_validation)) {
    fix <- af2_ca_fix_yahoo_splits_by_raw_gap(
      corp_actions = ca,
      universe_raw = dt,
      cfg = cfg,
      verbose = verbose
    )
    ca <- fix$corp_actions
    split_audit <- fix$audit
    yahoo_splits_fixed <- fix$fixed_kept
    yahoo_splits_quarantine <- fix$quarantine
  }

  # 7) Apply Policy (Fail-Soft)
  ca_apply <- if (!is.null(ca) && nrow(ca)) data.table::copy(ca) else data.table::data.table()
  ca_quarantine <- data.table::data.table()

  if (nrow(ca_apply)) {
    # Normalize CA fields
    ca_apply[, symbol := toupper(trimws(as.character(symbol)))]
    ca_apply[, refdate := as.Date(refdate)]
    ca_apply[, action_type := tolower(trimws(as.character(action_type)))]
    ca_apply[, source := tolower(trimws(as.character(source)))]
    ca_apply[, value := as.numeric(value)]

    # Separate non-yahoo-splits
    base_no_vendor <- ca_apply[!(action_type == "split" & source == "yahoo")]

    # Build Fail-Soft Splits from Audit
    splits_apply <- data.table::data.table()
    
    if (nrow(split_audit)) {
        # Use KEPT or UNVERIFIED (Fail Soft)
        sa <- data.table::as.data.table(split_audit)
        sa_apply <- sa[status %in% c("kept", "unverified")]
        
        if (nrow(sa_apply)) {
            sa_apply[, refdate_apply := data.table::fifelse(!is.na(eff_refdate), eff_refdate, vendor_refdate)]
            sa_apply[, value_apply := data.table::fifelse(status == "kept" & is.finite(chosen_value), chosen_value, yahoo_value)]
            
            splits_apply <- sa_apply[
                !is.na(refdate_apply) & is.finite(value_apply) & value_apply > 0,
                .(symbol, yahoo_symbol, refdate = as.Date(refdate_apply), action_type = "split", value = as.numeric(value_apply), source = "yahoo")
            ]
            splits_apply <- unique(splits_apply, by = c("symbol", "refdate", "action_type", "value", "source"))
        }
    } else {
        # No audit? Keep original vendor splits as last resort
        splits_apply <- ca_apply[action_type == "split" & source == "yahoo"]
    }

    # Recombine
    ca_apply <- data.table::rbindlist(list(base_no_vendor, splits_apply), use.names = TRUE, fill = TRUE)
    ca_apply <- unique(ca_apply, by = c("symbol", "refdate", "action_type", "value", "source"))
    if ("row_id" %in% names(ca_apply)) ca_apply[, row_id := NULL]
    if (!is.null(ca) && "row_id" %in% names(ca)) ca[, row_id := NULL]

    if (nrow(yahoo_splits_quarantine)) ca_quarantine <- yahoo_splits_quarantine
    
    if (verbose) {
      af2_log("AF2_CA_PREF:", "Applied splits count=", nrow(splits_apply), " Quarantine=", nrow(ca_quarantine))
    }
  }

  # 8) Run Adjuster
  out <- af2_build_panel_adj(
    universe_raw = dt,
    corp_actions = ca_apply,
    manual_events = manual_events,
    cfg = cfg,
    verbose = verbose
  )

  out$split_audit <- split_audit
  out$corp_actions_apply <- ca_apply
  out$corp_actions_quarantine <- ca_quarantine
  out
}


###############################################################################
### FILE: modules/04_adjuster/R/validate_panel_adj.R
###############################################################################
# v2/modules/04_adjuster/R/validate_panel_adj.R

af2_validate_panel_adj <- function(panel_adj) {

  af2_require(c("data.table"))

  af2_assert_cols(
    panel_adj,
    c("symbol", "refdate", "close_adj_final", "asset_type", "adjustment_state"),
    name = "panel_adj"
  )

  dt <- data.table::as.data.table(panel_adj)
  dt[, refdate := as.Date(refdate)]

  # Must have liquidity column for screener use
  has_turnover <- "turnover" %in% names(dt)
  has_vol_fin  <- "vol_fin" %in% names(dt)
  if (!has_turnover && !has_vol_fin) {
    stop("panel_adj must contain 'turnover' or 'vol_fin'.", call. = FALSE)
  }

  # No duplicate symbol-date
  af2_assert_no_dupes(dt, c("symbol", "refdate"), name = "panel_adj")

  invisible(TRUE)
}



###############################################################################
### FILE: modules/04_adjuster/R/zzz_depends.R
###############################################################################
# v2/modules/04_adjuster/R/zzz_depends.R
# Dependencies + guardrails for Module 04 (Adjuster)

# Must have core loaded first
if (!exists("af2_get_config")) {
  stop("af2_get_config not found. Source v2/modules/00_core/R/config.R first.")
}
if (!exists("af2_log")) {
  stop("af2_log not found. Source v2/modules/00_core/R/logging.R first.")
}
if (!exists("%||%")) {
  stop("%||% not found. Source v2/modules/00_core/R/utils.R first.")
}
if (!exists("af2_require")) {
  stop("af2_require not found. Source v2/modules/00_core/R/utils.R first.")
}
if (!exists("af2_assert_cols")) {
  stop("af2_assert_cols not found. Source v2/modules/00_core/R/utils.R first.")
}
if (!exists("af2_assert_no_dupes")) {
  stop("af2_assert_no_dupes not found. Source v2/modules/00_core/R/utils.R first.")
}

af2_adj_require <- function(pkgs) {
  for (p in pkgs) {
    if (!requireNamespace(p, quietly = TRUE)) {
      stop("Missing package for adjuster module: ", p, call. = FALSE)
    }
  }
  invisible(TRUE)
}

af2_adj_require(c("data.table"))

suppressPackageStartupMessages({
  library(data.table)
})



###############################################################################
### FILE: modules/04_adjuster/README.md
###############################################################################
# Module

Purpose:
- Define INPUT contract
- Define OUTPUT contract
- List functions
- List tests



###############################################################################
### FILE: modules/05_screener/R/compute_metrics.R
###############################################################################
# v2/modules/05_screener/R/compute_metrics.R
# Feature engineering for one symbol (feature-vector output).
# Uses adjusted FINAL OHLC whenever available.

af2_compute_symbol_features <- function(dt_sym, horizons_days) {
  af2_require(c("data.table"))

  dt <- data.table::as.data.table(dt_sym)
  data.table::setorder(dt, refdate)

  n_obs <- nrow(dt)
  if (n_obs < 30L) return(NULL)

  # Ensure required columns exist
  af2_assert_cols(dt, c("symbol", "refdate", "close_adj_final"), name = "panel_adj(symbol)")

  # Normalize liquidity column name
  if (!"turnover" %in% names(dt) && "vol_fin" %in% names(dt)) {
    dt[, turnover := vol_fin]
  }
  if (!"turnover" %in% names(dt)) dt[, turnover := NA_real_]

  # Try to use OHLC adjusted final; fall back to close-only where needed
  if (!"open_adj_final" %in% names(dt)) dt[, open_adj_final := NA_real_]
  if (!"high_adj_final" %in% names(dt)) dt[, high_adj_final := NA_real_]
  if (!"low_adj_final"  %in% names(dt)) dt[, low_adj_final  := NA_real_]

  # Coverage
  n_valid <- sum(is.finite(dt$close_adj_final) & !is.na(dt$close_adj_final))
  coverage <- if (n_obs > 0) n_valid / n_obs else NA_real_

  # Daily returns (close-close)
  dt[, close_prev := data.table::shift(close_adj_final, 1L)]
  dt[, ret_cc_log := data.table::fifelse(
    is.finite(close_adj_final) & is.finite(close_prev) & close_adj_final > 0 & close_prev > 0,
    log(close_adj_final / close_prev),
    NA_real_
  )]
  dt[, ret_cc_simple := data.table::fifelse(
    is.finite(close_adj_final) & is.finite(close_prev) & close_prev != 0,
    (close_adj_final / close_prev) - 1,
    NA_real_
  )]

  # Open gap (open vs prev close)
  dt[, gap_oc := data.table::fifelse(
    is.finite(open_adj_final) & is.finite(close_prev) & open_adj_final > 0 & close_prev > 0,
    (open_adj_final / close_prev) - 1,
    NA_real_
  )]

  # Intraday range (high-low)
  dt[, range_hl_log := data.table::fifelse(
    is.finite(high_adj_final) & is.finite(low_adj_final) &
      high_adj_final > 0 & low_adj_final > 0 & high_adj_final >= low_adj_final,
    log(high_adj_final / low_adj_final),
    NA_real_
  )]
  dt[, range_hl_pct := data.table::fifelse(
    is.finite(high_adj_final) & is.finite(low_adj_final) & is.finite(close_adj_final) &
      close_adj_final > 0 & high_adj_final >= low_adj_final,
    (high_adj_final - low_adj_final) / close_adj_final,
    NA_real_
  )]

  # Candle body (|close-open| / open)
  dt[, body_pct := data.table::fifelse(
    is.finite(open_adj_final) & is.finite(close_adj_final) & open_adj_final > 0,
    abs(close_adj_final - open_adj_final) / open_adj_final,
    NA_real_
  )]

  # True range % (ATR-like)
  dt[, tr := NA_real_]
  dt[is.finite(high_adj_final) & is.finite(low_adj_final),
     tr := high_adj_final - low_adj_final]
  dt[is.finite(tr) & is.finite(close_prev),
     tr := pmax(
       tr,
       abs(high_adj_final - close_prev),
       abs(low_adj_final - close_prev),
       na.rm = TRUE
     )]
  dt[, tr_pct := data.table::fifelse(
    is.finite(tr) & is.finite(close_prev) & close_prev > 0,
    tr / close_prev,
    NA_real_
  )]

  out <- list(
    symbol = dt$symbol[1],
    end_date = dt$refdate[n_obs],
    end_refdate = dt$refdate[n_obs],
    n_obs = as.integer(n_obs),
    n_valid = as.integer(n_valid),
    coverage = as.numeric(coverage)
  )

  # Helper: safe horizon return using row index (business-day count proxy)
  safe_price_ret <- function(p0, p1) {
    if (!is.finite(p0) || !is.finite(p1)) return(NA_real_)
    if (p0 == 0) return(NA_real_)
    (p1 / p0) - 1
  }

  safe_finite <- function(x) x[is.finite(x)]

  safe_mean <- function(x) {
    x <- safe_finite(x)
    if (!length(x)) return(NA_real_)
    mean(x)
  }
  
  safe_median <- function(x) {
    x <- safe_finite(x)
    if (!length(x)) return(NA_real_)
    stats::median(x)
  }
  
  safe_min <- function(x) {
    x <- safe_finite(x)
    if (!length(x)) return(NA_real_)
    min(x)
  }
  
  safe_max <- function(x) {
    x <- safe_finite(x)
    if (!length(x)) return(NA_real_)
    max(x)
  }
  
  safe_sd <- function(x) {
    x <- safe_finite(x)
    if (length(x) < 2L) return(NA_real_)
    stats::sd(x)
  }

  # Multi-horizon features
  last_idx <- n_obs
  for (h in horizons_days) {
    h <- as.integer(h)

    # Return over horizon (close->close)
    if (h > 1L && (last_idx - h) >= 1L) {
      p0 <- dt$close_adj_final[last_idx - h]
      p1 <- dt$close_adj_final[last_idx]
      out[[paste0("ret_", h, "d")]] <- safe_price_ret(p0, p1)

      # Close-close vol (annualized)
      idx_start <- max(1L, last_idx - h + 1L)
      rwin <- dt$ret_cc_log[idx_start:last_idx]
      out[[paste0("vol_cc_", h, "d")]] <- safe_sd(rwin) * sqrt(252)
      out[[paste0("vol_", h, "d")]] <- out[[paste0("vol_cc_", h, "d")]]
      
      # Parkinson volatility from HL range (annualized)
      x <- dt$range_hl_log[idx_start:last_idx]
      if (sum(is.finite(x)) >= 5L) {
        out[[paste0("vol_pk_", h, "d")]] <- sqrt(mean(x^2, na.rm = TRUE) / (4 * log(2))) * sqrt(252)
      } else {
        out[[paste0("vol_pk_", h, "d")]] <- NA_real_
      }

      # Garman–Klass volatility (annualized) - requires O,H,L,C
      o <- dt$open_adj_final[idx_start:last_idx]
      hi <- dt$high_adj_final[idx_start:last_idx]
      lo <- dt$low_adj_final[idx_start:last_idx]
      c <- dt$close_adj_final[idx_start:last_idx]
      ok <- is.finite(o) & is.finite(hi) & is.finite(lo) & is.finite(c) &
        o > 0 & hi > 0 & lo > 0 & c > 0 & hi >= lo
      if (sum(ok) >= 5L) {
        log_hl <- log(hi[ok] / lo[ok])
        log_co <- log(c[ok] / o[ok])
        sig2 <- mean(0.5 * (log_hl^2) - (2 * log(2) - 1) * (log_co^2), na.rm = TRUE)
        out[[paste0("vol_gk_", h, "d")]] <- sqrt(pmax(sig2, 0)) * sqrt(252)
      } else {
        out[[paste0("vol_gk_", h, "d")]] <- NA_real_
      }

      # Intraday range stats
      rp <- dt$range_hl_pct[idx_start:last_idx]
      out[[paste0("range_mean_", h, "d")]] <- safe_mean(rp)
      out[[paste0("range_max_", h, "d")]]  <- safe_max(rp)

      # Gap stats
      gp <- dt$gap_oc[idx_start:last_idx]
      out[[paste0("gap_min_", h, "d")]] <- safe_min(gp)
      out[[paste0("gap_max_", h, "d")]] <- safe_max(gp)
      out[[paste0("gap_abs_med_", h, "d")]] <- safe_median(abs(gp))

      # ATR-like stats
      trp <- dt$tr_pct[idx_start:last_idx]
      out[[paste0("tr_mean_", h, "d")]] <- safe_mean(trp)

      # Body stats
      bp <- dt$body_pct[idx_start:last_idx]
      out[[paste0("body_mean_", h, "d")]] <- safe_mean(bp)

    } else {
      # Populate missing horizons to keep schema stable
      out[[paste0("ret_", h, "d")]] <- NA_real_
      out[[paste0("vol_cc_", h, "d")]] <- NA_real_
      out[[paste0("vol_", h, "d")]] <- NA_real_
      out[[paste0("vol_pk_", h, "d")]] <- NA_real_
      out[[paste0("vol_gk_", h, "d")]] <- NA_real_
      out[[paste0("range_mean_", h, "d")]] <- NA_real_
      out[[paste0("range_max_", h, "d")]] <- NA_real_
      out[[paste0("gap_min_", h, "d")]] <- NA_real_
      out[[paste0("gap_max_", h, "d")]] <- NA_real_
      out[[paste0("gap_abs_med_", h, "d")]] <- NA_real_
      out[[paste0("tr_mean_", h, "d")]] <- NA_real_
      out[[paste0("body_mean_", h, "d")]] <- NA_real_
    }
  }

  # Drawdown + ulcer (NA-robust)
  prices <- dt$close_adj_final
  idx <- which(is.finite(prices) & !is.na(prices) & prices > 0)
  
  if (length(idx) >= 2L) {
    p <- prices[idx]
    cm <- cummax(p)
    dd <- p / cm - 1
  
    out$max_dd <- min(dd)  # dd is finite here
    out$ulcer_index <- sqrt(mean((dd * 100)^2))
  } else {
    out$max_dd <- NA_real_
    out$ulcer_index <- NA_real_
  }

  # Liquidity features
  traded_flag <- is.finite(dt$close_adj_final) & !is.na(dt$close_adj_final)
  out$median_turnover <- stats::median(dt$turnover, na.rm = TRUE)
  out$days_traded_ratio <- mean(traded_flag, na.rm = TRUE)

  # Amihud-like illiquidity
  valid <- is.finite(dt$ret_cc_simple) & is.finite(dt$turnover) & dt$turnover > 0
  out$amihud <- if (any(valid)) {
    mean(abs(dt$ret_cc_simple[valid]) / dt$turnover[valid], na.rm = TRUE)
  } else NA_real_

  data.table::as.data.table(out)
}

# -------------------------------------------------------------------
# Compatibility alias (Module 05 expects this name)
# -------------------------------------------------------------------
af2_compute_symbol_metrics <- function(dt_sym, horizons_days) {
  af2_compute_symbol_features(dt_sym, horizons_days)
}



###############################################################################
### FILE: modules/05_screener/R/liquidity_filter.R
###############################################################################
# v2/modules/05_screener/R/liquidity_filter.R

af2_compute_liquidity_from_panel <- function(panel_adj,
                                             min_turnover,
                                             min_days_traded_ratio) {
  af2_require("data.table")
  dt <- data.table::as.data.table(panel_adj)

  # unify turnover column name
  if (!"turnover" %in% names(dt) && "vol_fin" %in% names(dt)) {
    dt[, turnover := vol_fin]
  }

  dt[, traded_flag := is.finite(close_adj_final) & !is.na(close_adj_final)]

  liq <- dt[, .(
    median_turnover = stats::median(turnover, na.rm = TRUE),
    days_traded_ratio = mean(traded_flag, na.rm = TRUE)
  ), by = symbol]

  liq[is.na(median_turnover), median_turnover := 0]
  liq[is.na(days_traded_ratio), days_traded_ratio := 0]

  liq[
    median_turnover >= min_turnover &
      days_traded_ratio >= min_days_traded_ratio
  ]
}



###############################################################################
### FILE: modules/05_screener/R/run_screener.R
###############################################################################
# v2/modules/05_screener/R/run_screener.R

# Return modes:
#   return="ranked"   -> current behavior (score + ranks)
#   return="features" -> ONLY the feature table (per-symbol metrics), no scoring

af2_run_screener <- function(panel_adj,
                             config = NULL,
                             allow_unresolved = NULL,
                             return = c("ranked", "features")) {

  af2_require("data.table")
  return <- match.arg(return)

  # If caller didn't specify, default to core config policy
  if (is.null(allow_unresolved)) {
    cfg_core <- af2_get_config()
    allow_unresolved <- isTRUE(cfg_core$allow_unresolved_in_screener)
  }

  cfg <- af2_get_screener_config(config)

  # 0) Validate input contract hard
  af2_validate_screener_input(panel_adj, allow_unresolved = allow_unresolved)

  dt <- data.table::as.data.table(panel_adj)
  dt[, refdate := as.Date(refdate)]

  # unify turnover name
  if (!"turnover" %in% names(dt) && "vol_fin" %in% names(dt)) {
    dt[, turnover := vol_fin]
  }

  # 1) Liquidity filter
  liq <- af2_compute_liquidity_from_panel(
    dt,
    min_turnover = cfg$min_turnover,
    min_days_traded_ratio = cfg$min_days_traded_ratio
  )
  if (!nrow(liq)) stop("af2_run_screener: no symbols pass liquidity filter.", call. = FALSE)

  dt <- dt[symbol %in% liq$symbol]
  data.table::setorder(dt, symbol, refdate)

  # 2) Compute metrics per symbol on last lookback window
  metrics_list <- list()
  syms <- unique(dt$symbol)

  for (sym in syms) {
    sdt <- dt[symbol == sym]

    # Ensure we keep enough rows to compute the longest horizon return.
    need_n <- max(
      as.integer(cfg$lookback_days),
      as.integer(max(cfg$horizons_days)) + 1L
    )

    if (nrow(sdt) > need_n) {
      sdt <- sdt[(.N - need_n + 1):.N]
    }

    m <- af2_compute_symbol_metrics(sdt, cfg$horizons_days)
    if (!is.null(m)) {
      # attach asset_type
      m[, asset_type := unique(sdt$asset_type)[1]]
      metrics_list[[sym]] <- m
    }
  }

  metrics <- data.table::rbindlist(metrics_list, fill = TRUE)
  if (!nrow(metrics)) stop("af2_run_screener: metrics computation yielded zero rows.", call. = FALSE)

  # -------------------------------------------------------------------
  # 2.95) Sanitize: replace Inf/-Inf/NaN with NA (score should handle NA)
  # -------------------------------------------------------------------
  for (j in names(metrics)) {
    if (is.numeric(metrics[[j]])) {
      bad <- !is.finite(metrics[[j]])
      if (any(bad, na.rm = TRUE)) metrics[[j]][bad] <- NA_real_
    }
  }


  # If requested: return ONLY features (no scoring/ranking)
  if (return == "features") {
    return(list(
      features = metrics[order(symbol)],
      liquidity = liq[order(symbol)],
      config = cfg
    ))
  }

  # -------------------------------------------------------------------
  # 2.9) Guard: score_weights must match available feature columns
  # -------------------------------------------------------------------
  w <- cfg$score_weights
  if (is.null(w) || !length(w)) {
    stop("af2_run_screener: cfg$score_weights is empty.", call. = FALSE)
  }
  
  w_names <- names(w)
  if (is.null(w_names) || any(!nzchar(w_names))) {
    stop("af2_run_screener: cfg$score_weights must be a *named* numeric vector/list.", call. = FALSE)
  }
  
  missing_feat <- setdiff(w_names, names(metrics))
  if (length(missing_feat)) {
    stop(
      paste0(
        "af2_run_screener: score_weights reference missing feature columns:\n  - ",
        paste(missing_feat, collapse = "\n  - "),
        "\n\nFix: rename weights to match compute_metrics output, or add those features."
      ),
      call. = FALSE
    )
  }

  # 3) Score + rank (default behavior)
  out <- af2_score_and_rank(metrics, cfg$score_weights)

  by_type <- split(out, out$asset_type)
  by_type <- lapply(by_type, function(x) x[order(x$rank_type)])

  list(
    full = out[order(rank_overall)],
    by_type = by_type,
    features = metrics[order(symbol)],
    liquidity = liq[order(symbol)],
    config = cfg
  )
}




###############################################################################
### FILE: modules/05_screener/R/score_rank.R
###############################################################################
# v2/modules/05_screener/R/score_rank.R

af2_score_and_rank <- function(metrics, score_weights) {
  af2_require("data.table")
  dt <- data.table::as.data.table(metrics)

  dt[, score := 0]

  for (nm in names(score_weights)) {
    if (!nm %in% names(dt)) next
    x <- dt[[nm]]
    if (all(is.na(x))) next
    mu <- mean(x, na.rm = TRUE)
    s  <- stats::sd(x, na.rm = TRUE)
    if (!is.finite(s) || s == 0) next

    z <- (x - mu) / s
    z[!is.finite(z) | is.na(z)] <- 0
    dt[, score := score + score_weights[[nm]] * z]
  }

  dt[, rank_overall := rank(-score, ties.method = "first")]
  if ("asset_type" %in% names(dt)) {
    dt[, rank_type := rank(-score, ties.method = "first"), by = asset_type]
  } else {
    dt[, rank_type := NA_integer_]
  }

  dt[order(rank_overall)]
}



###############################################################################
### FILE: modules/05_screener/R/screener_config.R
###############################################################################
# v2/modules/05_screener/R/screener_config.R

af2_screener_config_default <- list(
  lookback_days   = 252L,
  horizons_days   = c(21L, 63L, 126L, 252L),

  # Liquidity
  min_turnover = 5e5,
  min_days_traded_ratio = 0.8,

  # Scoring weights (z-score aggregation)
  score_weights = list(
    # Momentum
    ret_21d  = +0.3,
    ret_63d  = +0.6,
    ret_126d = +0.9,
    ret_252d = +1.0,

    # Risk / stability penalties
    vol_21d  = -0.4,
    vol_252d = -0.7,
    max_dd   = -0.8,
    ulcer_index = -0.8,

    # Liquidity penalty
    amihud = -0.5
  )
)

af2_get_screener_config <- function(config = NULL) {
  cfg <- af2_screener_config_default

  if (!is.null(config)) {
    for (nm in names(config)) cfg[[nm]] <- config[[nm]]
  }

  # Defensive normalization
  if (is.null(cfg$horizons_days)) cfg$horizons_days <- integer()
  cfg$horizons_days <- as.integer(cfg$horizons_days)
  cfg$lookback_days <- as.integer(cfg$lookback_days)

  if (length(cfg$horizons_days)) {
    max_h <- max(cfg$horizons_days, na.rm = TRUE)
    if (is.finite(max_h) && cfg$lookback_days < (max_h + 1L)) {
      cfg$lookback_days <- max_h + 1L
    }
  }

  cfg
}



###############################################################################
### FILE: modules/05_screener/R/validate_screener_input.R
###############################################################################
# v2/modules/05_screener/R/validate_screener_input.R

af2_validate_screener_input <- function(panel_adj, allow_unresolved = FALSE) {
  af2_require(c("data.table"))
  af2_assert_cols(
    panel_adj,
    c("symbol", "refdate", "close_adj_final", "asset_type", "adjustment_state"),
    name = "panel_adj"
  )

  dt <- data.table::as.data.table(panel_adj)
  dt[, refdate := as.Date(refdate)]

  # Basic type sanity
  if (!is.character(dt$symbol)) stop("panel_adj$symbol must be character.", call. = FALSE)
  if (!is.character(dt$asset_type)) stop("panel_adj$asset_type must be character.", call. = FALSE)
  if (!is.character(dt$adjustment_state)) stop("panel_adj$adjustment_state must be character.", call. = FALSE)

  # Must have at least one liquidity column
  has_turnover <- "turnover" %in% names(dt)
  has_vol_fin  <- "vol_fin" %in% names(dt)
  if (!has_turnover && !has_vol_fin) {
    stop("panel_adj must contain either 'turnover' or 'vol_fin' for liquidity logic.", call. = FALSE)
  }

  # No duplicate rows per symbol-date
  af2_assert_no_dupes(dt, c("symbol", "refdate"), name = "panel_adj")

  # Adjustment state policy
  bad <- dt[adjustment_state == "suspect_unresolved"]
  if (nrow(bad) && !isTRUE(allow_unresolved)) {
    stop(
      "Screener input contains unresolved suspects.\n",
      "You must fix upstream adjuster/manual registry OR set allow_unresolved=TRUE.\n",
      "Example symbols: ", paste(unique(utils::head(bad$symbol, 10)), collapse = ", "),
      call. = FALSE
    )
  }

  invisible(TRUE)
}



###############################################################################
### FILE: modules/05_screener/README.md
###############################################################################
# Module

Purpose:
- Define INPUT contract
- Define OUTPUT contract
- List functions
- List tests



###############################################################################
### FILE: tests/diagnose_adjuster.R
###############################################################################
# ======================================================================
# diagnose_adjuster.R
# Build panel_adj_result (best-effort) and run split/adjustment diagnostics
# ======================================================================

options(stringsAsFactors = FALSE)

cat("\n=============================\n")
cat(" Autofinance v2 diagnostics\n")
cat("=============================\n\n")

# ----------------------------
# 0) Small helpers
# ----------------------------
`%||%` <- function(a, b) if (!is.null(a)) a else b

stopf <- function(fmt, ...) stop(sprintf(fmt, ...), call. = FALSE)
msg  <- function(fmt, ...) cat(sprintf(fmt, ...), "\n")

need_pkg <- function(pkg) {
    if (!requireNamespace(pkg, quietly = TRUE)) {
        stopf("Missing package '%s'. Install it first: install.packages('%s')", pkg, pkg)
    }
}

need_pkg("data.table")
DT <- data.table::as.data.table

has_cols <- function(dt, cols, name = "object") {
    miss <- setdiff(cols, names(dt))
    if (length(miss)) stopf("%s is missing columns: %s", name, paste(miss, collapse = ", "))
    invisible(TRUE)
}

as_idate <- function(x) {
    if (inherits(x, "IDate")) return(x)
    if (inherits(x, "Date")) return(data.table::as.IDate(x))
    if (inherits(x, "POSIXct") || inherits(x, "POSIXt")) return(data.table::as.IDate(as.Date(x)))
    if (is.character(x)) return(data.table::as.IDate(as.Date(x)))
    return(data.table::as.IDate(as.Date(x)))
}

maybe_find_first <- function(paths) {
    for (p in paths) if (file.exists(p)) return(p)
    return(NULL)
}

# ----------------------------
# 1) Locate project root / source v2 code
# ----------------------------
root <- getwd()

if (!dir.exists(file.path(root, "v2"))) {
    msg("Working directory: %s", root)
    stopf("I don't see a ./v2 directory here. Setwd() to your project root, then re-run.")
}

source_dir <- function(path) {
  if (!dir.exists(path)) return(invisible(FALSE))

  files <- list.files(path, pattern = "\\.R$", full.names = TRUE, recursive = FALSE)
  files <- sort(files)

  # Always source zzz_depends.R first (if present)
  zzz <- files[grepl("zzz_depends\\.R$", files)]
  rest <- files[!grepl("zzz_depends\\.R$", files)]

  files2 <- c(zzz, rest)

  for (f in files2) source(f, local = FALSE)
  invisible(TRUE)
}

source_v2_modules <- function() {
    modules_root <- file.path(root, "v2", "modules")
    if (!dir.exists(modules_root)) stopf("Expected directory not found: %s", modules_root)
    mods <- list.dirs(modules_root, full.names = TRUE, recursive = FALSE)
    mods <- sort(mods)
    for (m in mods) {
        rdir <- file.path(m, "R")
        if (dir.exists(rdir)) {
            msg("Sourcing module: %s", basename(m))
            source_dir(rdir)
        }
    }
    invisible(TRUE)
}

source_v2_modules()

# ----------------------------
# 2) Acquire inputs (universe_raw, corp_actions)
# ----------------------------
load_or_build_inputs <- function() {
    universe_raw <- NULL
    corp_actions <- NULL
    
    if (exists("universe_raw", envir = .GlobalEnv, inherits = TRUE)) {
        universe_raw <- get("universe_raw", envir = .GlobalEnv, inherits = TRUE)
        msg("\nUsing existing object: universe_raw")
    }
    
    if (exists("corp_actions", envir = .GlobalEnv, inherits = TRUE)) {
        corp_actions <- get("corp_actions", envir = .GlobalEnv, inherits = TRUE)
        msg("Using existing object: corp_actions")
    }
    
    u_guess <- maybe_find_first(c(
        file.path(root, "v2/data/cache/universe_raw_latest.rds"),
        file.path(root, "v2/data/cache/universe_raw.rds")
    ))
    if (is.null(universe_raw) && !is.null(u_guess)) {
        universe_raw <- readRDS(u_guess)
        msg("Loaded universe_raw from: %s", u_guess)
    }
    
    # Check if selective builder exists (to skip global fetch)
    has_selective <- exists("af2_build_panel_adj_selective", envir = .GlobalEnv)
    
    if (is.null(corp_actions) && !has_selective) {
        c_guess <- maybe_find_first(file.path(root, "v2/data/cache/corp_actions.rds"))
        if (!is.null(c_guess)) corp_actions <- readRDS(c_guess)
    } else if (has_selective) {
        msg("Skipping global corp_actions fetch because Selective Builder is available.")
    }
    
    if (is.null(universe_raw)) stopf("Couldn't obtain universe_raw.")
    
    list(universe_raw = universe_raw, corp_actions = corp_actions)
}

inp <- load_or_build_inputs()
universe_raw <- inp$universe_raw
corp_actions <- inp$corp_actions

# ----------------------------
# 3) Build panel_adj_result
# ----------------------------
build_panel_adj_result <- function(universe_raw, corp_actions) {
    if (exists("af2_get_config", envir = .GlobalEnv)) {
        cfg <- tryCatch(af2_get_config(), error = function(e) NULL)
    } else { cfg <- NULL }
    
    if (exists("af2_build_panel_adj_selective", envir = .GlobalEnv)) {
        msg("\nBuilding panel_adj_result with af2_build_panel_adj_selective() ...")
        # Selective builder does its own fetching
        return(af2_build_panel_adj_selective(
            universe_raw = universe_raw,
            manual_events = NULL,
            cfg = cfg,
            verbose = TRUE
        ))
    }
    
    if (exists("af2_build_panel_adj", envir = .GlobalEnv)) {
        if (is.null(corp_actions)) stopf("af2_build_panel_adj requires corp_actions")
        return(af2_build_panel_adj(
            universe_raw = universe_raw,
            corp_actions = corp_actions,
            manual_events = NULL,
            cfg = cfg,
            verbose = TRUE
        ))
    }
    stopf("No builder found.")
}

panel_adj_result <- build_panel_adj_result(universe_raw, corp_actions)

# ----------------------------
# 4) Extract
# ----------------------------
panel_adj <- DT(panel_adj_result$panel_adj)
panel_adj[, refdate := as_idate(refdate)]
corp_actions_apply <- if(!is.null(panel_adj_result$corp_actions_apply)) DT(panel_adj_result$corp_actions_apply) else NULL

if (!is.null(corp_actions_apply)) {
    corp_actions_apply[, refdate := as_idate(refdate)]
}

# ----------------------------
# 5) Jump Diagnostics (Fixed)
# ----------------------------
msg("\n--- JUMP REDUCTION AROUND SPLITS ---")

# Find adj close col
cols <- names(panel_adj)
adj_close_col <- if("close_adj_final" %in% cols) "close_adj_final" else grep("close_adj", cols, value=TRUE)[1]

if (!is.null(adj_close_col) && !is.null(corp_actions_apply)) {
    splits <- corp_actions_apply[action_type == "split"]
    if (nrow(splits) > 0) {
        
        data.table::setkey(panel_adj, symbol, refdate)
        panel_adj[, `:=`(
            close_raw = as.numeric(close),
            close_adj = as.numeric(get(adj_close_col))
        )]
        
        panel_adj[, lr_raw := log(close_raw / data.table::shift(close_raw)), by = symbol]
        panel_adj[, lr_adj := log(close_adj / data.table::shift(close_adj)), by = symbol]
        
        split_keys <- unique(splits[, .(symbol, refdate)])
        jump_at_split <- panel_adj[split_keys, on = .(symbol, refdate), nomatch = 0L]
        jump_at_split <- jump_at_split[!is.na(lr_raw) & !is.na(lr_adj)]
        
        if (nrow(jump_at_split) > 0) {
            # FIX: Two-step calculation to avoid "object not found"
            jump_at_split[, abs_raw := abs(lr_raw)]
            jump_at_split[, abs_adj := abs(lr_adj)]
            
            jump_at_split[, `:=`(
                improve = abs_raw - abs_adj,
                ratio   = fifelse(abs_raw > 0, abs_adj / abs_raw, NA_real_)
            )]
            
            bad <- jump_at_split[abs_raw >= 0.15 & abs_adj >= 0.10]
            msg("BAD split-days (raw big, adj still big): %d", nrow(bad))
            
            if (nrow(bad) > 0) print(head(bad[, .(symbol, refdate, abs_raw, abs_adj)]))
        }
    }
}

msg("\nDone.")


###############################################################################
### FILE: tests/investigate_corrections.R
###############################################################################
# v2/tests/investigate_corrections.R

# Ensure we have the objects from the build run
if (!exists("panel_adj_result")) {
  stop("Please run the build script first so 'panel_adj_result' exists in memory.")
}

library(data.table)

# Extract tables
events <- panel_adj_result$events
adj_tl <- panel_adj_result$adjustments
panel  <- panel_adj_result$panel_adj
audit  <- panel_adj_result$split_audit
jump   <- panel_adj_result$residual_jump_audit

# ==============================================================================
# 1. DEEP DIVE: Why is ITUB4 "suspect_unresolved"?
# ==============================================================================
target <- "ITUB4"
message("\n=== INVESTIGATION: ", target, " ===")

# A) Check Dividend Safety Logic (issue_div)
# Logic: Bad if (Div >= PrevClose) OR (PrevClose is NA/Zero)

# 1. Reconstruct the decision data
# We need 'close_adj_split' from the panel to see what the adjuster saw.
cols_needed <- c("symbol", "refdate", "close_raw", "close_adj_split", "close_adj_final")
p_target <- panel[symbol == target, ..cols_needed]

# 2. Join with the specific event parameters that triggered the flag
a_target <- adj_tl[symbol == target & issue_div == TRUE]

if (nrow(a_target) > 0) {
  message("Found ", nrow(a_target), " UNSAFE dividend events for ", target, ".")
  
  # Join to see prices at that moment
  # Note: The adjuster compares div_cash vs lag(close_adj_split)
  check <- merge(a_target, p_target, by = c("symbol", "refdate"), all.x = TRUE)
  
  # Fetch previous day's price (the denominator)
  check[, prev_date := refdate - 1] # Approximation for display
  # Get actual lag from panel
  p_target[, close_prev := shift(close_adj_split, 1, type = "lag")]
  
  check_final <- merge(check, p_target[, .(symbol, refdate, close_prev)], by = c("symbol", "refdate"))
  
  print(check_final[, .(
    refdate, 
    div_cash, 
    close_prev_adj = round(close_prev, 4), 
    ratio = round(div_cash / close_prev, 2),
    verdict = fifelse(is.na(close_prev), "PrevClose NA",
              fifelse(close_prev <= 0, "PrevClose <= 0",
              fifelse(div_cash >= close_prev, "Div >= Price", "Unknown")))
  )])
} else {
  message("No 'issue_div' flags found for ", target, ". Checking Safety Net...")
}

# B) Check Residual Jump (Safety Net)
j_target <- jump[symbol == target]
if (isTRUE(j_target$residual_jump_flag)) {
  message("\n", target, " also failed the RESIDUAL JUMP check.")
  print(j_target)
} else {
  message("\n", target, " PASSED the residual jump check.")
}


# ==============================================================================
# 2. SYSTEM-WIDE: Who else had "Corrections"?
# ==============================================================================

message("\n=== GLOBAL CORRECTION REPORT ===")

# A) Rejected Splits (The "Snapper" doing its job)
if (!is.null(audit)) {
  rejected <- audit[status == "rejected"]
  if (nrow(rejected) > 0) {
    message("\n[REJECTED SPLITS] Vendor data didn't match price gaps (Top 10):")
    # Calculate the gap it SHOULD have seen
    print(head(rejected[, .(symbol, vendor_refdate, yahoo_value, chosen_err, status)], 10))
  }
}

# B) Unsafe Dividends (The "Dividend Ghost" trap)
unsafe_divs <- adj_tl[issue_div == TRUE]
if (nrow(unsafe_divs) > 0) {
  message("\n[UNSAFE DIVIDENDS] Ignored to prevent negative prices (Top 10):")
  print(head(unsafe_divs[, .(symbol, refdate, div_cash, issue_div)], 10))
  
  message("Total unsafe dividend events: ", nrow(unsafe_divs))
  message("Unique symbols affected: ", length(unique(unsafe_divs$symbol)))
}

# C) Safety Net Kills (The "Bombs")
killed <- jump[residual_jump_flag == TRUE]
if (nrow(killed) > 0) {
  message("\n[SAFETY NET KILLS] Symbols dropped due to unresolvable jumps (Top 10):")
  print(head(killed[order(-residual_max_abs_logret), .(symbol, residual_max_abs_logret, residual_jump_date)], 10))
}


###############################################################################
### FILE: tests/test_data_layer_v2.R
###############################################################################
# v2/tests/test_data_layer_v2.R
# Smoke + deep diagnostics for v2 data layer (candidates -> CA fetch -> events -> adjustments -> features)

# =========================
# 1) HARD RESET (MUST BE FIRST)
# =========================
rm(list = ls(all.names = TRUE))
gc()

options(stringsAsFactors = FALSE)
Sys.setenv(TZ = "UTC")

# =========================
# 2) USER KNOBS
# =========================
# NOTE:
# - This block is intentionally written so it NEVER errors if you refactor/reset.
# - Edit the *defaults* here when you want to change behavior.

WATCH <- get0(
  "WATCH",
  ifnotfound = c("SEQL3", "IFCM3", "GOLD11", "GOGL34", "PETR4", "VALE3", "ITUB4")
)
WATCH <- unique(toupper(trimws(as.character(WATCH))))
WATCH <- WATCH[nzchar(WATCH)]

FORCE_REFRESH_CA_BATCH_CACHE <- isTRUE(get0("FORCE_REFRESH_CA_BATCH_CACHE", ifnotfound = FALSE))
RUN_PARALLEL_MINITEST        <- isTRUE(get0("RUN_PARALLEL_MINITEST", ifnotfound = TRUE))
HARD_FAIL_IF_NO_DIVIDENDS    <- isTRUE(get0("HARD_FAIL_IF_NO_DIVIDENDS", ifnotfound = TRUE))

# Optional: override candidate cap for faster tests (set NULL to keep cfg)
OVERRIDE_MAX_CANDIDATES <- get0("OVERRIDE_MAX_CANDIDATES", ifnotfound = NULL)

# If you already have universe_raw saved, set this path; otherwise script tries to build/load automatically.
UNIVERSE_RAW_RDS <- get0("UNIVERSE_RAW_RDS", ifnotfound = NULL)
if (!is.null(UNIVERSE_RAW_RDS)) UNIVERSE_RAW_RDS <- as.character(UNIVERSE_RAW_RDS)

# =========================
# 3) ASSERT PROJECT ROOT
# =========================
if (!dir.exists("v2/modules")) {
  stop("Run this from the project root (the folder that contains v2/modules).", call. = FALSE)
}

# =========================
# 4) HELPERS
# =========================
.msg <- function(...) cat(paste0(..., collapse = ""), "\n")

source_all_v2_modules <- function(mod_root = "v2/modules") {
  files <- list.files(mod_root, pattern = "\\.R$", recursive = TRUE, full.names = TRUE)
  if (!length(files)) stop("No R files found under v2/modules.", call. = FALSE)

  # Deterministic order; numeric module dirs should already sort correctly
  files <- sort(normalizePath(files, winslash = "/", mustWork = TRUE))

  # Prefer 00_core first if present
  core_first <- grepl("/00_", files) | grepl("/00core", files, ignore.case = TRUE)
  files <- c(files[core_first], files[!core_first])

  .msg("Sourcing ", length(files), " files under ", mod_root, " ...")
  for (f in files) {
    tryCatch(
      source(f, local = FALSE),
      error = function(e) {
        stop("Failed sourcing: ", f, "\n", conditionMessage(e), call. = FALSE)
      }
    )
  }
  invisible(files)
}

assert_has <- function(fn) {
  if (!exists(fn, mode = "function")) stop("Missing required function: ", fn, call. = FALSE)
}

as_dt <- function(x) {
  if (!requireNamespace("data.table", quietly = TRUE)) stop("data.table not installed.", call. = FALSE)
  data.table::as.data.table(x)
}

# Safely delete only batch corp_actions caches (not by_symbol)
delete_batch_ca_caches <- function(cache_dir = "v2/data/cache/corp_actions") {
  if (!dir.exists(cache_dir)) return(invisible(FALSE))
  files <- list.files(cache_dir, pattern = "^corp_actions_.*\\.rds$", full.names = TRUE)
  if (!length(files)) return(invisible(FALSE))
  ok <- file.remove(files)
  .msg("Deleted ", sum(ok), "/", length(files), " batch corp_actions cache files.")
  invisible(TRUE)
}

# Try to obtain universe_raw in a robust way
get_or_build_universe_raw <- function() {
  
  # 1. Try explicit user path
  if (!is.null(UNIVERSE_RAW_RDS) && file.exists(UNIVERSE_RAW_RDS)) {
    .msg("Loading universe_raw from: ", UNIVERSE_RAW_RDS)
    return(readRDS(UNIVERSE_RAW_RDS))
  }

  # 2. Try default cache location
  default_cache <- "v2/data/cache/universe_raw_latest.rds"
  if (file.exists(default_cache)) {
    .msg("Loading universe_raw from: ", default_cache)
    return(readRDS(default_cache))
  }

  # 3. Try to build it (PATCHED: Added af2_b3_build_universe)
  candidates <- c(
    "af2_b3_build_universe",       # <--- The correct v2 function
    "af2_build_universe",          # Legacy alias
    "af2_cotahist_build_universe"  # Legacy alias
  )

  for (fn in candidates) {
    if (exists(fn, mode = "function")) {
      .msg("Building universe_raw via ", fn, "() ...")
      
      # Default to last 2 years + current year to be safe and fast
      y_end <- as.integer(format(Sys.Date(), "%Y"))
      y_start <- y_end - 1L
      
      # Call builder
      res <- get(fn)(years = y_start:y_end)
      
      # Auto-save to cache for next time
      .msg("Saving universe_raw to ", default_cache, " for future runs...")
      dir.create(dirname(default_cache), recursive = TRUE, showWarnings = FALSE)
      saveRDS(res, default_cache)
      
      return(res)
    }
  }

  stop(
    "Could not load/build universe_raw.\n",
    "Function 'af2_b3_build_universe' was not found after sourcing modules.\n",
    "Check if v2/modules/01_b3_universe/R/build_universe.R exists.",
    call. = FALSE
  )
}

# Fallback features (only used if your screener entrypoint is unavailable)
compute_fallback_features <- function(panel_adj_dt, lookback = 253L) {
  dt <- as_dt(panel_adj_dt)
  data.table::setorder(dt, symbol, refdate)

  out <- dt[, {
    x <- close_adj_final
    x <- x[is.finite(x) & x > 0]
    if (length(x) < 30) {
      .(end_refdate = max(refdate), n_obs = .N,
        ret_21d = NA_real_, vol_21d = NA_real_, max_dd = NA_real_,
        median_turnover = stats::median(turnover, na.rm = TRUE),
        asset_type = asset_type[.N])
    } else {
      # last lookback rows by date
      idx <- tail(seq_len(.N), lookback)
      p <- close_adj_final[idx]
      d <- refdate[idx]

      # returns
      r <- diff(p) / data.table::shift(p, 1L, type = "lag")[idx][-1]
      # safer: log returns
      lr <- diff(log(p))

      # 21d total return
      ret_21d <- if (length(p) >= 22) (p[length(p)] / p[length(p) - 21] - 1) else NA_real_

      # 21d vol annualized (sqrt(252))
      vol_21d <- {
        lr21 <- tail(lr, 21)
        if (length(lr21) >= 10) stats::sd(lr21, na.rm = TRUE) * sqrt(252) else NA_real_
      }

      # max drawdown inside window
      cm <- cummax(p)
      dd <- p / cm - 1
      max_dd <- min(dd, na.rm = TRUE)

      .(end_refdate = max(d), n_obs = length(p),
        ret_21d = ret_21d, vol_21d = vol_21d, max_dd = max_dd,
        median_turnover = stats::median(turnover, na.rm = TRUE),
        asset_type = asset_type[.N])
    }
  }, by = symbol]

  out[]
}

# =========================
# 5) SOURCE MODULES + LOAD CFG
# =========================
source_all_v2_modules("v2/modules")

assert_has("af2_get_config")
assert_has("af2_ca_select_candidates")
assert_has("af2_build_panel_adj_selective")

cfg <- af2_get_config()

# Optional cap override for faster runs
if (!is.null(OVERRIDE_MAX_CANDIDATES)) {
  cfg$ca_prefilter_max_candidates <- as.integer(OVERRIDE_MAX_CANDIDATES)
  .msg("OVERRIDE: cfg$ca_prefilter_max_candidates = ", cfg$ca_prefilter_max_candidates)
}

# Make sure new knobs exist (won't fail if absent; just informative)
.msg("CFG snapshot (relevant):")
flat <- unlist(cfg, recursive = TRUE)
print(flat[grep("ca_|corp|split|div|prefilter|gap|jump|max_candidates|cache_mode|fetch_mode",
                names(flat), ignore.case = TRUE)])

# =========================
# 6) GET universe_raw
# =========================
universe_raw <- get_or_build_universe_raw()
universe_raw <- as_dt(universe_raw)

.msg("universe_raw: rows=", nrow(universe_raw), " syms=", length(unique(universe_raw$symbol)),
     " date_range=", min(universe_raw$refdate), " -> ", max(universe_raw$refdate))

# =========================
# 7) CANDIDATE SELECTION DIAGNOSTICS
# =========================
cand <- af2_ca_select_candidates(universe_raw, cfg = cfg, verbose = TRUE)
cand <- unique(toupper(cand))

.msg("Candidate set: n=", length(cand))
cand_hit <- setNames(WATCH %in% cand, WATCH)
print(cand_hit)

# Require SEQL3/IFCM3 in candidates (your must-have regression test)
if (!("SEQL3" %in% cand && "IFCM3" %in% cand)) {
  stop("Candidate regression: SEQL3/IFCM3 not in candidates. Fix select_candidates.R.", call. = FALSE)
}

# =========================
# 8) OPTIONAL: FORCE REFRESH CA BATCH CACHE
# =========================
if (isTRUE(FORCE_REFRESH_CA_BATCH_CACHE)) {
  delete_batch_ca_caches("v2/data/cache/corp_actions")
}

# =========================
# 9) OPTIONAL: PARALLEL MINITEST (registry only)
# =========================
if (isTRUE(RUN_PARALLEL_MINITEST) && exists("af2_ca_build_registry", mode = "function")) {

  .msg("\n--- Parallel mini-test (af2_ca_build_registry, n_workers=2) ---")
  mini_syms <- unique(c("PETR4", "VALE3", "ITUB4", "TAEE11", "HGLG11", "BBAS3"))
  mini_syms <- mini_syms[mini_syms %in% unique(toupper(universe_raw$symbol))]

  if (length(mini_syms) >= 2) {
    mini <- tryCatch(
      af2_ca_build_registry(
        symbols = mini_syms,
        cfg = cfg,
        from = "2022-01-01",
        to = Sys.Date(),
        verbose = TRUE,
        use_cache = FALSE,
        force_refresh = TRUE,
        n_workers = 2L,
        cache_mode = "batch"
      ),
      error = function(e) e
    )

    if (inherits(mini, "error")) {
      stop("Parallel registry mini-test FAILED:\n", conditionMessage(mini), call. = FALSE)
    } else {
      mini <- as_dt(mini)
      .msg("Parallel registry mini-test OK. action_type counts:")
      print(mini[, .N, by = action_type][order(-N)])
    }
  } else {
    .msg("Skipping parallel mini-test: not enough mini_syms present in universe_raw.")
  }
}

# =========================
# 10) BUILD PANEL (SELECTIVE CA + ADJUSTER)
# =========================
.msg("\n--- Building panel_adj_result (selective) ---")
panel_adj_result <- af2_build_panel_adj_selective(universe_raw = universe_raw)

# Contract checks
needed <- c("panel_adj", "events", "corp_actions_apply", "corp_actions_quarantine", "split_audit")
miss <- setdiff(needed, names(panel_adj_result))
if (length(miss)) {
  stop("panel_adj_result missing fields: ", paste(miss, collapse = ", "), call. = FALSE)
}

panel_adj_dt <- as_dt(panel_adj_result$panel_adj)
events <- as_dt(panel_adj_result$events)
ca_apply <- as_dt(panel_adj_result$corp_actions_apply)
ca_quar <- as_dt(panel_adj_result$corp_actions_quarantine)
audit <- as_dt(panel_adj_result$split_audit)

.msg("panel_adj: rows=", nrow(panel_adj_dt), " syms=", length(unique(panel_adj_dt$symbol)))
.msg("events:    rows=", nrow(events), " syms=", length(unique(events$symbol)))
.msg("ca_apply:  rows=", nrow(ca_apply), " types=", paste(unique(ca_apply$action_type), collapse = ", "))
.msg("ca_quar:   rows=", nrow(ca_quar))

# =========================
# 10.5) AURA33 TRACE (PIPELINE BREAK LOCATOR)
# =========================
trace_symbol <- function(sym, universe_raw, cand, ca_apply, ca_quar, events, audit) {
  sym <- toupper(sym)

  cat("\n====================\n")
  cat("TRACE SYMBOL:", sym, "\n")
  cat("====================\n")

  u_sym <- universe_raw[symbol == sym]
  cat("universe_raw rows:", nrow(u_sym), "\n")
  if (nrow(u_sym)) {
    cat("universe_raw date range:", as.character(min(u_sym$refdate)), "->", as.character(max(u_sym$refdate)), "\n")
  }

  in_cand <- sym %in% cand
  cat("in candidate set:", in_cand, "\n")

  caA <- ca_apply[symbol == sym]
  caQ <- ca_quar[symbol == sym]
  ev  <- events[symbol == sym]
  au  <- audit[symbol == sym]

  cat("ca_apply rows:", nrow(caA), "\n")
  if (nrow(caA)) print(caA[order(refdate, action_type)])

  cat("ca_quarantine rows:", nrow(caQ), "\n")
  if (nrow(caQ)) print(caQ[order(refdate, action_type)])

  cat("events rows:", nrow(ev), "\n")
  if (nrow(ev)) print(ev[order(refdate)])

  cat("split_audit rows:", nrow(au), "\n")
  if (nrow(au)) print(au[order(refdate)])

  # Quick check: are there any dividend-positive days for this symbol?
  if ("div_cash" %in% names(events)) {
    cat("events div_cash>0 rows:", nrow(events[symbol == sym & div_cash > 0]), "\n")
  }

  invisible(list(
    in_cand = in_cand,
    u_rows = nrow(u_sym),
    ca_apply = caA,
    ca_quar = caQ,
    events = ev,
    audit = au
  ))
}

# Make sure cand is defined; if you suspect builder uses a different cfg, still run it —
# it will at least show where AURA33 is missing.
if (!exists("cand")) cand <- character()

aura_trace <- trace_symbol(
  "AURA33",
  universe_raw = universe_raw,
  cand = cand,
  ca_apply = ca_apply,
  ca_quar = ca_quar,
  events = events,
  audit = audit
)

# =========================
# 11) DIVIDEND ASSERTIONS
# =========================
ca_counts <- ca_apply[, .N, by = action_type][order(-N)]
.msg("\nCorporate actions APPLY counts:")
print(ca_counts)

n_div_apply <- if ("dividend" %in% ca_apply$action_type) nrow(ca_apply[action_type == "dividend"]) else 0L
n_div_ev <- nrow(events[div_cash > 0])

.msg("Dividend rows in ca_apply: ", n_div_apply)
.msg("Dividend-positive event days (events$div_cash>0): ", n_div_ev)

if (HARD_FAIL_IF_NO_DIVIDENDS && (n_div_apply == 0L || n_div_ev == 0L)) {
  stop(
    "Dividend ghost still present: no dividends made it into ca_apply/events.\n",
    "Fix fetcher wiring (chart events) OR confirm Yahoo returns dividends in your environment.\n",
    "Tip: inspect ca_apply[action_type=='dividend'] and the registry cache file created this run.",
    call. = FALSE
  )
}

# =========================
# 12) SPLIT VALIDATION SUMMARY (KEPT/REJECTED/UNVERIFIED)
# =========================
if ("status" %in% names(audit)) {
  .msg("\nSplit audit status counts:")
  print(audit[, .N, by = status][order(-N)])
}

# Check watch symbols CA rows
.msg("\nCA rows for WATCH:")
print(ca_apply[symbol %chin% WATCH][order(symbol, action_type, refdate)][1:200])

# =========================
# 13) RESIDUAL JUMP SAFETY NET CHECK
# =========================
if ("residual_jump_audit" %in% names(panel_adj_result)) {
  rj <- as_dt(panel_adj_result$residual_jump_audit)
  .msg("\nResidual jump audit: top offenders:")
  print(rj[order(-residual_max_abs_logret)][1:30])
} else {
  .msg("\nNOTE: residual_jump_audit not present in panel_adj_result; skipping this check.")
}

# =========================
# 14) PER-SYMBOL DIAGNOSTICS
# =========================
if (exists("af2_diag_symbol", mode = "function")) {
  .msg("\n--- af2_diag_symbol(WATCH) ---")
  for (s in WATCH) {
    if (s %in% unique(panel_adj_dt$symbol)) {
      af2_diag_symbol(
        symbol = s,
        panel_adj = panel_adj_dt,
        events = events,
        corp_actions_apply = ca_apply,
        split_audit = audit,
        show_plot = TRUE
      )
    }
  }
} else {
  .msg("\nNOTE: af2_diag_symbol() not found; skipping per-symbol diag.")
}

# =========================
# 15) REBUILD RES / FEATURES (Screener if available; fallback otherwise)
# =========================
res <- NULL
if (exists("af2_run_screener", mode = "function")) {
  .msg("\n--- Running af2_run_screener(panel_adj_dt) ---")
  
  # NOTE: We pass allow_unresolved = TRUE because we KNOW 'panel_adj_dt' contains
  # suspects (like TCIN15, AMER3) flagged by the safety net. 
  # The screener will automatically drop them unless configured otherwise, 
  # but the validator won't throw a hard stop.
  res <- af2_run_screener(panel_adj_dt, allow_unresolved = TRUE)
  
} else if (exists("af2_run_screener_v2", mode = "function")) {
  .msg("\n--- Running af2_run_screener_v2(panel_adj_dt) ---")
  res <- af2_run_screener_v2(panel_adj_dt, allow_unresolved = TRUE)
}

if (!is.null(res) && is.list(res) && "features" %in% names(res)) {
  feats <- as_dt(res$features)
  
  # If the screener drops unresolved symbols, they won't be in 'feats'.
  # So we check WATCH items only if they survived.
  survivors <- intersect(WATCH, feats$symbol)
  
  .msg("\nScreener features present. WATCH rows (survivors):")
  print(feats[symbol %chin% survivors, .(symbol, end_refdate, n_obs, ret_21d, vol_21d, max_dd, median_turnover, asset_type)][order(symbol)])

  .msg("\nTop 30 by abs(ret_21d):")
  top <- feats[is.finite(ret_21d)][order(-abs(ret_21d))][1:30]
  print(top[, .(symbol, ret_21d, vol_21d, max_dd, median_turnover, asset_type)])

} else {
  .msg("\nNOTE: Screener entrypoint not found or did not return $features. Using fallback feature computation.")
  feats <- compute_fallback_features(panel_adj_dt, lookback = 253L)

  .msg("\nFallback features (WATCH):")
  print(feats[symbol %chin% WATCH][order(symbol)])

  .msg("\nFallback top 30 by abs(ret_21d):")
  top <- feats[is.finite(ret_21d)][order(-abs(ret_21d))][1:30]
  print(top[, .(symbol, ret_21d, vol_21d, max_dd, median_turnover, asset_type)])
}
# =========================
# 16) FINAL SUCCESS MESSAGE
# =========================
.msg("\n✅ v2 data-layer test completed.")
.msg("If HARD_FAIL_IF_NO_DIVIDENDS=TRUE, then dividends are confirmed present end-to-end.")


###############################################################################
### FILE: tests/vis_check.R
###############################################################################
# v2/tests/vis_check.R
# Visual confirmation of Adjustments

# 1. Load data
if (!exists("panel_adj_dt")) {
  panel_adj_dt <- readRDS("v2/data/cache/universe_raw_latest.rds") # Or whatever your output cache is named
  # Actually, the test script leaves 'panel_adj_dt' in memory. 
  # If you restarted R, re-run the build or load the object.
}

# 2. Define Plotter
plot_adjustment <- function(sym) {
  dt <- panel_adj_dt[symbol == sym][order(refdate)]
  
  if (nrow(dt) == 0) return(message("Symbol not found: ", sym))
  
  # Normalize to start at 100 for comparison
  start_p <- dt$close_raw[1]
  dt[, norm_raw := close_raw / start_p * 100]
  dt[, norm_adj := close_adj_final / close_adj_final[1] * 100]
  
  # Plot
  plot(dt$refdate, dt$norm_raw, type = "l", col = "grey", lwd = 1,
       main = paste("Adjustment Impact:", sym), ylab = "Normalized Price", xlab = "Date")
  lines(dt$refdate, dt$norm_adj, col = "blue", lwd = 2)
  
  # Add Events
  events <- panel_adj_result$events[symbol == sym]
  if (nrow(events) > 0) {
    abline(v = events$refdate, col = "red", lty = 2)
    text(events$refdate, par("usr")[3], labels = ifelse(events$split_value != 1, "S", "D"), 
         col = "red", pos = 3, cex = 0.8)
  }
  
  legend("topleft", legend = c("Raw", "Adjusted"), col = c("grey", "blue"), lwd = c(1, 2))
}

# 3. Check specific cases
# PETR4: Should see a massive difference due to huge dividends
plot_adjustment("PETR4")

# SEQL3: Should see the raw price jump (reverse split) smoothed out
plot_adjustment("SEQL3")

# IFCM3: Should see the raw price jump smoothed out
plot_adjustment("IFCM3")


